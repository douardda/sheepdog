Description: Upstream changes introduced in version 0.3.0-1
 This patch has been created by dpkg-source during the package build.
 Here's the last changelog entry, hopefully it gives details on why
 those changes were made:
 .
 sheepdog (0.3.0-1) experimental; urgency=low
 .
   * New upstream version
 .
 The person named in the Author field signed this changelog entry.
Author: David Douard <david.douard@logilab.fr>

---
The information above should follow the Patch Tagging Guidelines, please
checkout http://dep.debian.net/deps/dep3/ to learn about the format. Here
are templates for supplementary fields that you might want to add:

Origin: <vendor|upstream|other>, <url of original patch>
Bug: <url in upstream bugtracker>
Bug-Debian: http://bugs.debian.org/<bugnumber>
Bug-Ubuntu: https://launchpad.net/bugs/<bugnumber>
Forwarded: <no|not-needed|url proving that it has been forwarded>
Reviewed-By: <name and email of someone who approved the patch>
Last-Update: <YYYY-MM-DD>

--- sheepdog-0.3.0.orig/Makefile.am
+++ sheepdog-0.3.0/Makefile.am
@@ -17,7 +17,7 @@ sheepdogsysconfdir	= ${SHEEPDOGCONFDIR}
 
 sheepdogsysconf_DATA	= 
 
-SUBDIRS			= lib collie sheep include script man tests
+SUBDIRS			= lib collie sheep include script man
 
 install-exec-local:
 	$(INSTALL) -d $(DESTDIR)/${localstatedir}/lib/sheepdog
@@ -29,12 +29,7 @@ dist-clean-local:
 	rm -f autoconf automake autoheader
 
 clean-generic:
-	rm -rf $(SPEC) $(TARFILE) cscope*
-
-cscope:
-	@echo create cscope.out
-	@find -name '*.[ch]' > cscope.files
-	@cscope -bq
+	rm -rf $(SPEC) $(TARFILE)
 
 $(SPEC): $(SPEC).in
 	rm -f $@-t $@
--- /dev/null
+++ sheepdog-0.3.0/.emacs.desktop
@@ -0,0 +1,62 @@
+;; -*- mode: emacs-lisp; coding: emacs-mule; -*-
+;; --------------------------------------------------------------------------
+;; Desktop File for Emacs
+;; --------------------------------------------------------------------------
+;; Created Tue May 15 01:33:47 2012
+;; Desktop file format version 206
+;; Emacs version 23.2.1
+
+;; Global section:
+(setq desktop-missing-file-warning nil)
+(setq tags-file-name nil)
+(setq tags-table-list nil)
+(setq search-ring nil)
+(setq regexp-search-ring nil)
+(setq register-alist nil)
+(setq file-name-history '("~/local/debian/corosync/debian/rules" "~/local/debian/sheepdog/script/bash_completion_collie" "~/local/debian/sheepdog/script/start-sheepdog" "~/local/debian/sheepdog/debian/patches/series" "~/local/debian/sheepdog/debian/source/format" "~/local/debian/sheepdog/debian/patches/debian-changes-0.3.0-1" "~/local/debian/sheepdog/autogen.sh" "~/local/debian/sheepdog/Makefile.am" "~/local/debian/sheepdog/autogen.sh" "~/local/debian/sheepdog/debian/control" "~/local/debian/sheepdog/debian/rules"))
+
+;; Buffer section -- buffers listed in same order as in buffer list:
+(desktop-create-buffer 206
+  "/home/david/local/debian/sheepdog/debian/rules"
+  "rules"
+  'makefile-mode
+  nil
+  196
+  '(290 nil)
+  nil
+  nil
+  '((indent-tabs-mode . t) (buffer-file-coding-system . undecided-unix)))
+
+(desktop-create-buffer 206
+  "/home/david/local/debian/sheepdog/debian/control"
+  "control"
+  'text-mode
+  nil
+  217
+  '(205 nil)
+  nil
+  nil
+  '((buffer-file-coding-system . utf-8-unix)))
+
+(desktop-create-buffer 206
+  "/home/david/local/debian/corosync/debian/rules"
+  "rules"
+  'makefile-gmake-mode
+  nil
+  487
+  '(408 nil)
+  nil
+  nil
+  '((indent-tabs-mode . t) (buffer-file-coding-system . undecided-unix)))
+
+(desktop-create-buffer 206
+  "/home/david/local/debian/sheepdog/Makefile.am"
+  "Makefile.am"
+  'makefile-automake-mode
+  nil
+  400
+  '(nil nil)
+  nil
+  nil
+  '((indent-tabs-mode . t) (buffer-file-coding-system . undecided-unix)))
+
--- sheepdog-0.3.0.orig/configure.ac
+++ sheepdog-0.3.0/configure.ac
@@ -66,7 +66,6 @@ if ! ${MAKE-make} --version /cannot/make
 fi
 
 AC_PROG_CC
-AM_PROG_AS
 AC_PROG_INSTALL
 AC_PROG_LN_S
 AC_PROG_MAKE_SET
@@ -198,16 +197,6 @@ AC_ARG_WITH([initddir],
 	[ INITDDIR="$withval" ],
 	[ INITDDIR="$sysconfdir/init.d" ])
 
-AC_ARG_ENABLE([farm],
-	[  --enable-farm           : build farm store driver ],,
-	[ enable_farm="yes" ],)
-AM_CONDITIONAL(BUILD_FARM, test x$enable_farm = xyes)
-
-AC_ARG_ENABLE([trace],
-	[  --enable-trace           : enable trace],,
-	[ enable_trace="no" ],)
-AM_CONDITIONAL(BUILD_TRACE, test x$enable_trace = xyes)
-
 CP=cp
 OS_LDL="-ldl"
 case "$host_os" in
@@ -269,22 +258,6 @@ if test "x${enable_accord}" = xyes; then
 	PACKAGE_FEATURES="$PACKAGE_FEATURES accord"
 fi
 
-if test "x${enable_farm}" = xyes; then
-	AC_CHECK_LIB([crypto], [SHA1_Init],,
-		AC_MSG_ERROR(libcrypto not found))
-	AC_CHECK_HEADERS([openssl/sha.h],,
-		AC_MSG_ERROR(sha.h header missing))
-	AC_DEFINE_UNQUOTED([HAVE_FARM], 1, [have farm])
-	PACKAGE_FEATURES="$PACKAGE_FEATURES farm"
-fi
-
-if test "x${enable_trace}" = xyes; then
-	AC_CHECK_LIB([rt], [clock_gettime],,
-		AC_MSG_ERROR(librt not found))
-	AC_DEFINE_UNQUOTED([HAVE_TRACE], 1, [have trace])
-	PACKAGE_FEATURES="$PACKAGE_FEATURES trace"
-fi
-
 # extra warnings
 EXTRA_WARNINGS=""
 
@@ -338,23 +311,11 @@ else
 	WERROR_CFLAGS=""
 fi
 
-if test "x${enable_trace}" = xyes && \
-		cc_supports_flag -pg && \
-		cc_supports_flag -gstabs ; then
-	AC_MSG_NOTICE([Enabling trace (-pg -gstabs)])
-	TRACE_CFLAGS="-pg -gstabs -DENABLE_TRACE"
-	TRACE_LDFLAGS="-T$(pwd)/sheep/trace/trace.ld"
-	PACKAGE_FEATURES="$PACKAGE_FEATURES trace"
-else
-	TRACE_CFLAGS=""
-fi
-
 # final build of *FLAGS
 CFLAGS="$ENV_CFLAGS $OPT_CFLAGS $GDB_FLAGS $OS_CFLAGS \
-	$TRACE_CFLAGS $COVERAGE_CFLAGS $EXTRA_WARNINGS $WERROR_CFLAGS $NSS_CFLAGS \
-	-D_GNU_SOURCE"
+	$COVERAGE_CFLAGS $EXTRA_WARNINGS $WERROR_CFLAGS $NSS_CFLAGS -D_GNU_SOURCE"
 CPPFLAGS="$ENV_CPPFLAGS $ANSI_CPPFLAGS $OS_CPPFLAGS"
-LDFLAGS="$ENV_LDFLAGS $COVERAGE_LDFLAGS $OS_LDFLAGS $TRACE_LDFLAGS"
+LDFLAGS="$ENV_LDFLAGS $COVERAGE_LDFLAGS $OS_LDFLAGS"
 
 # substitute what we need:
 AC_SUBST([OS_DYFLAGS])
@@ -408,7 +369,6 @@ AC_MSG_RESULT([  ANSI defined CPPFLAGS
 AC_MSG_RESULT([  Coverage     CFLAGS      = ${COVERAGE_CFLAGS}])
 AC_MSG_RESULT([  Coverage     LDFLAGS     = ${COVERAGE_LDFLAGS}])
 AC_MSG_RESULT([  Fatal War.   CFLAGS      = ${WERROR_CFLAGS}])
-AC_MSG_RESULT([  Trace        CFLAGS      = ${TRACE_CFLAGS}])
 AC_MSG_RESULT([  Final        CFLAGS      = ${CFLAGS}])
 AC_MSG_RESULT([  Final        CPPFLAGS    = ${CPPFLAGS}])
 AC_MSG_RESULT([  Final        LDFLAGS     = ${LDFLAGS}])
--- sheepdog-0.3.0.orig/include/sheepdog_proto.h
+++ sheepdog-0.3.0/include/sheepdog_proto.h
@@ -22,18 +22,15 @@
 #define SD_OP_CREATE_AND_WRITE_OBJ  0x01
 #define SD_OP_READ_OBJ       0x02
 #define SD_OP_WRITE_OBJ      0x03
-#define SD_OP_REMOVE_OBJ     0x04
 
 #define SD_OP_NEW_VDI        0x11
 #define SD_OP_LOCK_VDI       0x12
 #define SD_OP_RELEASE_VDI    0x13
 #define SD_OP_GET_VDI_INFO   0x14
 #define SD_OP_READ_VDIS      0x15
-#define SD_OP_FLUSH_VDI      0x16
 
 #define SD_FLAG_CMD_WRITE    0x01
 #define SD_FLAG_CMD_COW      0x02
-#define SD_FLAG_CMD_CACHE    0x04
 
 #define SD_RES_SUCCESS       0x00 /* Success */
 #define SD_RES_UNKNOWN       0x01 /* Unknown error */
@@ -62,9 +59,6 @@
 #define SD_RES_JOIN_FAILED   0x18 /* Target node had failed to join sheepdog */
 #define SD_RES_HALT 0x19 /* Sheepdog is stopped doing IO */
 #define SD_RES_MANUAL_RECOVER   0x1A /* Users should not manually recover this cluster */
-#define SD_RES_NO_STORE         0x20 /* No targeted backend store */
-#define SD_RES_NO_SUPPORT       0x21 /* Operation is not supported by backend store */
-#define SD_RES_CLUSTER_RECOVERING 0x22 /* Cluster is recovering. */
 
 /*
  * Object ID rules
@@ -97,8 +91,6 @@
 #define SD_ATTR_OBJ_SIZE (sizeof(struct sheepdog_vdi_attr))
 #define CURRENT_VDI_ID 0
 
-#define STORE_LEN 16
-
 struct sd_req {
 	uint8_t		proto_ver;
 	uint8_t		opcode;
@@ -203,14 +195,6 @@ struct sheepdog_vdi_attr {
 	char value[SD_MAX_VDI_ATTR_VALUE_LEN];
 };
 
-#define SHA1_LEN        20
-
-struct snap_log {
-	uint32_t epoch;
-	uint64_t time;
-	unsigned char sha1[SHA1_LEN];
-};
-
 /*
  * 64 bit FNV-1a non-zero initial basis
  */
--- sheepdog-0.3.0.orig/include/net.h
+++ sheepdog-0.3.0/include/net.h
@@ -2,7 +2,6 @@
 #define __NET_H__
 
 #include <sys/socket.h>
-#include <arpa/inet.h>
 
 #define DEFAULT_SOCKET_TIMEOUT 5 /* seconds */
 
@@ -18,9 +17,6 @@ struct connection {
 	int fd;
 	unsigned int events;
 
-	uint16_t port;
-	char ipstr[INET6_ADDRSTRLEN];
-
 	enum conn_state c_rx_state;
 	int rx_length;
 	void *rx_buf;
@@ -49,7 +45,6 @@ int exec_req(int sockfd, struct sd_req *
 int create_listen_ports(int port, int (*callback)(int fd, void *), void *data);
 
 char *addr_to_str(char *str, int size, uint8_t *addr, uint16_t port);
-uint8_t *str_to_addr(int af, const char *ipstr, uint8_t *addr);
 int set_nonblocking(int fd);
 int set_nodelay(int fd);
 int set_timeout(int fd);
--- sheepdog-0.3.0.orig/include/sheep.h
+++ sheepdog-0.3.0/include/sheep.h
@@ -17,7 +17,7 @@
 #include "net.h"
 #include "logger.h"
 
-#define SD_SHEEP_PROTO_VER 0x04
+#define SD_SHEEP_PROTO_VER 0x03
 
 #define SD_DEFAULT_REDUNDANCY 3
 #define SD_MAX_REDUNDANCY 8
@@ -27,7 +27,7 @@
 #define SD_MAX_VNODES 65536
 #define SD_MAX_VMS   4096 /* FIXME: should be removed */
 
-#define SD_OP_SHEEP          0x80
+#define SD_OP_SHEEP         0x80
 #define SD_OP_DEL_VDI        0x81
 #define SD_OP_GET_NODE_LIST  0x82
 #define SD_OP_GET_VM_LIST    0x83
@@ -37,15 +37,7 @@
 #define SD_OP_STAT_CLUSTER   0x87
 #define SD_OP_KILL_NODE      0x88
 #define SD_OP_GET_VDI_ATTR   0x89
-#define SD_OP_RECOVER        0x8a
-#define SD_OP_GET_STORE_LIST 0x90
-#define SD_OP_SNAPSHOT       0x91
-#define SD_OP_RESTORE        0x92
-#define SD_OP_GET_SNAP_FILE  0x93
-#define SD_OP_CLEANUP        0x94
-#define SD_OP_TRACE          0x95
-#define SD_OP_TRACE_CAT      0x96
-#define SD_OP_STAT_RECOVERY  0x97
+#define SD_OP_RECOVER	     0x8A
 
 #define SD_FLAG_CMD_IO_LOCAL   0x0010
 #define SD_FLAG_CMD_RECOVERY 0x0020
@@ -67,7 +59,7 @@
 #define SD_RES_INVALID_CTIME 0x44 /* Creation time of sheepdog is different */
 #define SD_RES_INVALID_EPOCH 0x45 /* Invalid epoch */
 
-#define SD_FLAG_NOHALT       0x0004 /* Serve the IO rquest even lack of nodes */
+#define SD_FLAG_NOHALT       0x0001 /* Server the IO rquest even lack of nodes */
 
 struct sd_so_req {
 	uint8_t		proto_ver;
@@ -145,14 +137,14 @@ struct sd_node_rsp {
 	uint64_t	store_free;
 };
 
-struct sd_node {
+struct sheepdog_node_list_entry {
 	uint8_t         addr[16];
 	uint16_t        port;
 	uint16_t	nr_vnodes;
 	uint32_t	zone;
 };
 
-struct sd_vnode {
+struct sheepdog_vnode_list_entry {
 	uint64_t        id;
 	uint8_t         addr[16];
 	uint16_t        port;
@@ -165,25 +157,10 @@ struct epoch_log {
 	uint64_t time;
 	uint32_t epoch;
 	uint32_t nr_nodes;
-	uint32_t nr_copies;
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 };
 
-#define TRACE_GRAPH_ENTRY  0x01
-#define TRACE_GRAPH_RETURN 0x02
-
-#define TRACE_BUF_LEN      (1024 * 1024 * 8)
-#define TRACE_FNAME_LEN    36
-
-struct trace_graph_item {
-	int type;
-	char fname[TRACE_FNAME_LEN];
-	int depth;
-	unsigned long long entry_time;
-	unsigned long long return_time;
-};
-
-static inline int same_node(struct sd_vnode *e, int n1, int n2)
+static inline int same_node(struct sheepdog_vnode_list_entry *e, int n1, int n2)
 {
 	if (memcmp(e[n1].addr, e[n2].addr, sizeof(e->addr)) == 0 &&
 	    e[n1].port == e[n2].port)
@@ -192,13 +169,13 @@ static inline int same_node(struct sd_vn
 	return 0;
 }
 
-static inline int same_zone(struct sd_vnode *e, int n1, int n2)
+static inline int same_zone(struct sheepdog_vnode_list_entry *e, int n1, int n2)
 {
 	return e[n1].zone != 0 && e[n1].zone == e[n2].zone;
 }
 
 /* traverse the virtual node list and return the n'th one */
-static inline int get_nth_node(struct sd_vnode *entries,
+static inline int get_nth_node(struct sheepdog_vnode_list_entry *entries,
 			       int nr_entries, int base, int n)
 {
 	int nodes[SD_MAX_REDUNDANCY];
@@ -224,11 +201,11 @@ next:
 	return idx;
 }
 
-static inline int hval_to_sheep(struct sd_vnode *entries,
+static inline int hval_to_sheep(struct sheepdog_vnode_list_entry *entries,
 				int nr_entries, uint64_t id, int idx)
 {
 	int i;
-	struct sd_vnode *e = entries, *n;
+	struct sheepdog_vnode_list_entry *e = entries, *n;
 
 	for (i = 0; i < nr_entries - 1; i++, e++) {
 		n = e + 1;
@@ -238,7 +215,7 @@ static inline int hval_to_sheep(struct s
 	return get_nth_node(entries, nr_entries, (i + 1) % nr_entries, idx);
 }
 
-static inline int obj_to_sheep(struct sd_vnode *entries,
+static inline int obj_to_sheep(struct sheepdog_vnode_list_entry *entries,
 			       int nr_entries, uint64_t oid, int idx)
 {
 	uint64_t id = fnv_64a_buf(&oid, sizeof(oid), FNV1A_64_INIT);
@@ -286,9 +263,6 @@ static inline const char *sd_strerror(in
 		{SD_RES_JOIN_FAILED, "Node has failed to join cluster"},
 		{SD_RES_HALT, "IO has halted as there are too few living nodes"},
 		{SD_RES_MANUAL_RECOVER, "Cluster is running/halted and cannot be manually recovered"},
-		{SD_RES_NO_STORE, "Targeted backend store is not found"},
-		{SD_RES_NO_SUPPORT, "Operation is not supported"},
-		{SD_RES_CLUSTER_RECOVERING, "Cluster is recovering"},
 
 		{SD_RES_OLD_NODE_VER, "Remote node has an old epoch"},
 		{SD_RES_NEW_NODE_VER, "Remote node has a new epoch"},
@@ -306,8 +280,8 @@ static inline const char *sd_strerror(in
 
 static inline int node_cmp(const void *a, const void *b)
 {
-	const struct sd_node *node1 = a;
-	const struct sd_node *node2 = b;
+	const struct sheepdog_node_list_entry *node1 = a;
+	const struct sheepdog_node_list_entry *node2 = b;
 	int cmp;
 
 	cmp = memcmp(node1->addr, node2->addr, sizeof(node1->addr));
@@ -323,8 +297,8 @@ static inline int node_cmp(const void *a
 
 static inline int vnode_cmp(const void *a, const void *b)
 {
-	const struct sd_vnode *node1 = a;
-	const struct sd_vnode *node2 = b;
+	const struct sheepdog_vnode_list_entry *node1 = a;
+	const struct sheepdog_vnode_list_entry *node2 = b;
 
 	if (node1->id < node2->id)
 		return -1;
@@ -333,10 +307,10 @@ static inline int vnode_cmp(const void *
 	return 0;
 }
 
-static inline int nodes_to_vnodes(struct sd_node *nodes, int nr,
-				  struct sd_vnode *vnodes)
+static inline int nodes_to_vnodes(struct sheepdog_node_list_entry *nodes, int nr,
+				  struct sheepdog_vnode_list_entry *vnodes)
 {
-	struct sd_node *n = nodes;
+	struct sheepdog_node_list_entry *n = nodes;
 	int i, j, nr_vnodes = 0;
 	uint64_t hval;
 
--- sheepdog-0.3.0.orig/include/logger.h
+++ sheepdog-0.3.0/include/logger.h
@@ -46,8 +46,7 @@ struct logarea {
 	int fd;
 };
 
-extern int log_init(char *progname, int size, int to_stdout, int level,
-		char *outfile);
+extern int log_init(char * progname, int size, int daemon, int level, char *outfile);
 extern void log_close(void);
 extern void dump_logmsg(void *);
 extern void log_write(int prio, const char *func, int line, const char *fmt, ...)
@@ -72,7 +71,7 @@ do {									\
 
 #define panic(fmt, args...)			\
 ({						\
-	vprintf(SDOG_EMERG, "PANIC: " fmt, ##args);	\
+	vprintf(SDOG_EMERG, fmt, ##args);	\
 	abort();				\
 })
 
--- sheepdog-0.3.0.orig/include/list.h
+++ sheepdog-0.3.0/include/list.h
@@ -142,7 +142,6 @@ static inline int hlist_unhashed(const s
 	return !h->pprev;
 }
 
-__attribute__((always_inline))
 static inline int hlist_empty(const struct hlist_head *h)
 {
 	return !h->first;
--- /dev/null
+++ sheepdog-0.3.0/include/coroutine.h
@@ -0,0 +1,20 @@
+#ifndef __COROUTINE__
+#define __COROUTINE__
+
+#include <stdio.h>
+#include <stdarg.h>
+#include <unistd.h>
+
+#include "list.h"
+
+struct coroutine;
+
+typedef void coroutine_entry_func_t(void *opaque);
+
+struct coroutine *coroutine_create(coroutine_entry_func_t *entry);
+void coroutine_enter(struct coroutine *coroutine, void *opaque);
+void coroutine_yield(void);
+struct coroutine *coroutine_self(void);
+int in_coroutine(void);
+
+#endif
--- sheepdog-0.3.0.orig/include/util.h
+++ sheepdog-0.3.0/include/util.h
@@ -6,7 +6,6 @@
 #include <stdint.h>
 
 #include "bitops.h"
-#include "list.h"
 
 #define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))
 #define roundup(x, y) ((((x) + ((y) - 1)) / (y)) * (y))
@@ -29,8 +28,6 @@
 #define __cpu_to_le32(x) bswap_32(x)
 #endif
 
-#define notrace __attribute__((no_instrument_function))
-
 static inline int before(uint32_t seq1, uint32_t seq2)
 {
         return (int32_t)(seq1 - seq2) < 0;
@@ -70,27 +67,4 @@ extern ssize_t xwrite(int fd, const void
 extern ssize_t xpread(int fd, void *buf, size_t count, off_t offset);
 extern ssize_t xpwrite(int fd, const void *buf, size_t count, off_t offset);
 
-/* ring_buffer.c */
-struct rbuffer {
-	struct list_head list;
-	char *buffer;           /* data buffer */
-	char *buffer_end;
-	size_t capacity;        /* initial maximum number of items in the buffer */
-	size_t count;           /* number of items in the buffer */
-	size_t sz;              /* size of each item in the buffer */
-	char *head;
-	char *tail;
-};
-
-static inline size_t rbuffer_size(struct rbuffer *rbuf)
-{
-	return rbuf->count * rbuf->sz;
-}
-
-void rbuffer_push(struct rbuffer *rbuf, const void *item);
-void rbuffer_pop(struct rbuffer *rbuf, void *item);
-void rbuffer_destroy(struct rbuffer *rbuf);
-void rbuffer_create(struct rbuffer *rbuf, size_t capacity, size_t item_size);
-void rbuffer_reset(struct rbuffer *rbuf);
-
 #endif
--- sheepdog-0.3.0.orig/collie/cluster.c
+++ sheepdog-0.3.0/collie/cluster.c
@@ -17,61 +17,17 @@
 #include "collie.h"
 
 struct cluster_cmd_data {
-	uint32_t epoch;
-	int list;
 	int copies;
 	int nohalt;
 	int force;
-	char name[STORE_LEN];
 } cluster_cmd_data;
 
-#define DEFAULT_STORE	"simple"
-
 static void set_nohalt(uint16_t *p)
 {
 	if (p)
 		*p |= SD_FLAG_NOHALT;
 }
 
-static int list_store(void)
-{
-	int fd, ret;
-	struct sd_req hdr;
-	struct sd_rsp *rsp = (struct sd_rsp *)&hdr;
-	unsigned rlen, wlen;
-	char buf[512] = { 0 };
-
-	fd = connect_to(sdhost, sdport);
-	if (fd < 0)
-		return EXIT_SYSFAIL;
-
-	memset(&hdr, 0, sizeof(hdr));
-
-	wlen = 0;
-	rlen = 512;
-	hdr.opcode = SD_OP_GET_STORE_LIST;
-	hdr.data_length = rlen;
-
-	ret = exec_req(fd, &hdr, buf, &wlen, &rlen);
-	close(fd);
-
-	if (ret) {
-		fprintf(stderr, "Failed to connect\n");
-		return EXIT_SYSFAIL;
-	}
-
-	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Restore failed: %s\n",
-				sd_strerror(rsp->result));
-		return EXIT_FAILURE;
-	}
-
-	printf("Available stores:\n");
-	printf("---------------------------------------\n");
-	printf("%s\n", buf);
-	return EXIT_SYSFAIL;
-}
-
 static int cluster_format(int argc, char **argv)
 {
 	int fd, ret;
@@ -79,7 +35,6 @@ static int cluster_format(int argc, char
 	struct sd_so_rsp *rsp = (struct sd_so_rsp *)&hdr;
 	unsigned rlen, wlen;
 	struct timeval tv;
-	char store_name[STORE_LEN];
 
 	fd = connect_to(sdhost, sdport);
 	if (fd < 0)
@@ -96,15 +51,9 @@ static int cluster_format(int argc, char
 	hdr.epoch = node_list_version;
 	hdr.ctime = (uint64_t) tv.tv_sec << 32 | tv.tv_usec * 1000;
 
-	if (strlen(cluster_cmd_data.name))
-		strncpy(store_name, cluster_cmd_data.name, STORE_LEN);
-	else
-		strcpy(store_name, DEFAULT_STORE);
-	hdr.data_length = wlen = strlen(store_name) + 1;
-	hdr.flags |= SD_FLAG_CMD_WRITE;
-
-	printf("using backend %s store\n", store_name);
-	ret = exec_req(fd, (struct sd_req *)&hdr, store_name, &wlen, &rlen);
+	rlen = 0;
+	wlen = 0;
+	ret = exec_req(fd, (struct sd_req *)&hdr, NULL, &wlen, &rlen);
 	close(fd);
 
 	if (ret) {
@@ -115,7 +64,7 @@ static int cluster_format(int argc, char
 	if (rsp->result != SD_RES_SUCCESS) {
 		fprintf(stderr, "Format failed: %s\n",
 				sd_strerror(rsp->result));
-		return list_store();
+		return EXIT_FAILURE;
 	}
 
 	return EXIT_SUCCESS;
@@ -127,33 +76,21 @@ static int cluster_info(int argc, char *
 	struct sd_vdi_req hdr;
 	struct sd_vdi_rsp *rsp = (struct sd_vdi_rsp *)&hdr;
 	unsigned rlen, wlen;
-	struct epoch_log *logs;
-	int nr_logs, log_length;
+	struct epoch_log logs[8];
+	int nr_logs;
 	time_t ti, ct;
 	struct tm tm;
 	char time_str[128];
 
-	log_length = node_list_version * sizeof(struct epoch_log);
-again:
-	logs = malloc(log_length);
-	if (!logs) {
-		if (log_length < 10) {
-			fprintf(stderr, "No memory to allocate.\n");
-			return EXIT_SYSFAIL;
-		}
-		log_length /= 2;
-		goto again;
-	}
-
 	fd = connect_to(sdhost, sdport);
 	if (fd < 0)
-		goto error;
+		return EXIT_SYSFAIL;
 
 	memset(&hdr, 0, sizeof(hdr));
 
 	hdr.opcode = SD_OP_STAT_CLUSTER;
 	hdr.epoch = node_list_version;
-	hdr.data_length = log_length;
+	hdr.data_length = sizeof(logs);
 
 	rlen = hdr.data_length;
 	wlen = 0;
@@ -161,7 +98,7 @@ again:
 	close(fd);
 
 	if (ret != 0)
-		goto error;
+		return EXIT_SYSFAIL;
 
 	if (!raw_output)
 		printf("Cluster status: ");
@@ -180,7 +117,7 @@ again:
 	for (i = 0; i < nr_logs; i++) {
 		int j;
 		char name[128];
-		struct sd_node *entry;
+		struct sheepdog_node_list_entry *entry;
 
 		ti = logs[i].time;
 		if (raw_output) {
@@ -202,11 +139,7 @@ again:
 		printf("]\n");
 	}
 
-	free(logs);
 	return EXIT_SUCCESS;
-error:
-	free(logs);
-	return EXIT_SYSFAIL;
 }
 
 static int cluster_shutdown(int argc, char **argv)
@@ -244,179 +177,6 @@ static int cluster_shutdown(int argc, ch
 	return EXIT_SUCCESS;
 }
 
-static int restore_snap(uint32_t epoch)
-{
-	int fd, ret;
-	struct sd_obj_req hdr;
-	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
-	unsigned rlen, wlen;
-
-	fd = connect_to(sdhost, sdport);
-	if (fd < 0)
-		return EXIT_SYSFAIL;
-
-	memset(&hdr, 0, sizeof(hdr));
-
-	hdr.opcode = SD_OP_RESTORE;
-	hdr.tgt_epoch = epoch;
-
-	rlen = 0;
-	wlen = 0;
-	ret = exec_req(fd, (struct sd_req *)&hdr, NULL, &wlen, &rlen);
-	close(fd);
-
-	if (ret) {
-		fprintf(stderr, "Failed to connect\n");
-		return EXIT_SYSFAIL;
-	}
-
-	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Restore failed: %s\n",
-				sd_strerror(rsp->result));
-		return EXIT_FAILURE;
-	}
-
-	printf("Cluster restore to the snapshot %d\n", epoch);
-	return EXIT_SUCCESS;
-}
-
-static void print_list(void *buf, unsigned len)
-{
-	struct snap_log *log_buf = (struct snap_log *)buf;
-	unsigned nr = len / sizeof(struct snap_log), i;
-
-	printf("Index\t\tSnapshot Time\n");
-	for (i = 0; i < nr; i++, log_buf++) {
-		time_t *t = (time_t *)&log_buf->time;
-		printf("%d\t\t", log_buf->epoch);
-		printf("%s", ctime(t));
-	}
-}
-
-static int list_snap(void)
-{
-	int fd, ret = EXIT_SYSFAIL;
-	struct sd_req hdr;
-	struct sd_rsp *rsp = (struct sd_rsp *)&hdr;
-	unsigned rlen, wlen;
-	void *buf;
-
-	buf = malloc(SD_DATA_OBJ_SIZE);
-	if (!buf)
-		return EXIT_SYSFAIL;
-
-	fd = connect_to(sdhost, sdport);
-	if (fd < 0)
-		goto out;
-
-	memset(&hdr, 0, sizeof(hdr));
-
-	wlen = 0;
-	rlen = SD_DATA_OBJ_SIZE;
-	hdr.opcode = SD_OP_GET_SNAP_FILE;
-	hdr.data_length = rlen;
-
-	ret = exec_req(fd, &hdr, buf, &wlen, &rlen);
-	close(fd);
-
-	if (ret) {
-		fprintf(stderr, "Failed to connect\n");
-		goto out;
-	}
-
-	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Listing snapshots failed: %s\n",
-				sd_strerror(rsp->result));
-		ret = EXIT_FAILURE;
-		goto out;
-	}
-
-	print_list(buf, rlen);
-out:
-	free(buf);
-	return EXIT_SUCCESS;
-}
-
-static int do_snapshot(void)
-{
-	int fd, ret;
-	struct sd_req hdr;
-	struct sd_rsp *rsp = (struct sd_rsp *)&hdr;
-	unsigned rlen, wlen;
-
-	fd = connect_to(sdhost, sdport);
-	if (fd < 0)
-		return EXIT_SYSFAIL;
-
-	memset(&hdr, 0, sizeof(hdr));
-
-	hdr.opcode = SD_OP_SNAPSHOT;
-
-	rlen = 0;
-	wlen = 0;
-	ret = exec_req(fd, &hdr, NULL, &wlen, &rlen);
-	close(fd);
-
-	if (ret) {
-		fprintf(stderr, "Failed to connect\n");
-		return EXIT_SYSFAIL;
-	}
-
-	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Snapshot failed: %s\n",
-				sd_strerror(rsp->result));
-		return EXIT_FAILURE;
-	}
-
-	return EXIT_SUCCESS;
-}
-
-static int cluster_snapshot(int argc, char **argv)
-{
-	int ret, epoch = cluster_cmd_data.epoch;
-	if (epoch)
-		ret = restore_snap(epoch);
-	else if (cluster_cmd_data.list)
-		ret = list_snap();
-	else
-		ret = do_snapshot();
-	return ret;
-}
-
-static int cluster_cleanup(int argc, char **argv)
-{
-	int fd, ret;
-	struct sd_req hdr;
-	struct sd_rsp *rsp = (struct sd_rsp *)&hdr;
-	unsigned rlen, wlen;
-
-	fd = connect_to(sdhost, sdport);
-	if (fd < 0)
-		return EXIT_SYSFAIL;
-
-	memset(&hdr, 0, sizeof(hdr));
-
-	hdr.opcode = SD_OP_CLEANUP;
-
-	rlen = 0;
-	wlen = 0;
-	ret = exec_req(fd, &hdr, NULL, &wlen, &rlen);
-	close(fd);
-
-	if (ret) {
-		fprintf(stderr, "Failed to connect\n");
-		return EXIT_SYSFAIL;
-	}
-
-	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Cleanup failed: %s\n",
-				sd_strerror(rsp->result));
-		return EXIT_FAILURE;
-	}
-
-	return EXIT_SUCCESS;
-}
-
 #define RECOVER_PRINT \
 "Caution! Please try starting all the cluster nodes normally before\n\
 running this command.\n\n\
@@ -476,17 +236,13 @@ static int cluster_recover(int argc, cha
 
 static struct subcommand cluster_cmd[] = {
 	{"info", NULL, "aprh", "show cluster information",
-	 SUBCMD_FLAG_NEED_NODELIST, cluster_info},
-	{"format", NULL, "bcHaph", "create a Sheepdog store",
+	 0, cluster_info},
+	{"format", NULL, "cHaph", "create a Sheepdog store",
 	 0, cluster_format},
 	{"shutdown", NULL, "aph", "stop Sheepdog",
 	 SUBCMD_FLAG_NEED_NODELIST, cluster_shutdown},
 	{"recover", NULL, "afph", "manually recover the cluster",
 	0, cluster_recover},
-	{"snapshot", NULL, "aRlph", "snapshot/restore the cluster",
-	0, cluster_snapshot},
-	{"cleanup", NULL, "aph", "cleanup the useless snapshot data from recovery",
-	0, cluster_cleanup},
 	{NULL,},
 };
 
@@ -496,9 +252,6 @@ static int cluster_parser(int ch, char *
 	char *p;
 
 	switch (ch) {
-	case 'b':
-		strncpy(cluster_cmd_data.name, opt, 10);
-		break;
 	case 'c':
 		copies = strtol(opt, &p, 10);
 		if (opt == p || copies < 1) {
@@ -517,20 +270,6 @@ static int cluster_parser(int ch, char *
 	case 'f':
 		cluster_cmd_data.force = 1;
 		break;
-	case 'R':
-		cluster_cmd_data.epoch = strtol(opt, &p, 10);
-		if (opt == p) {
-			fprintf(stderr, "The epoch must be an integer\n");
-			exit(EXIT_FAILURE);
-		}
-		if (cluster_cmd_data.epoch < 1) {
-			fprintf(stderr, "The epoch must be greater than 0\n");
-			exit(EXIT_FAILURE);
-		}
-		break;
-	case 'l':
-		cluster_cmd_data.list = 1;
-		break;
 	}
 
 	return 0;
--- sheepdog-0.3.0.orig/collie/collie.h
+++ sheepdog-0.3.0/collie/collie.h
@@ -53,9 +53,9 @@ extern int sdport;
 extern int highlight;
 extern int raw_output;
 
-extern uint32_t node_list_version;
-extern struct sd_node node_list_entries[SD_MAX_NODES];
-extern struct sd_vnode vnode_list_entries[SD_MAX_VNODES];
+extern uint64_t node_list_version;
+extern struct sheepdog_node_list_entry node_list_entries[SD_MAX_NODES];
+extern struct sheepdog_vnode_list_entry vnode_list_entries[SD_MAX_VNODES];
 extern int nr_nodes, nr_vnodes;
 extern unsigned master_idx;
 
@@ -74,10 +74,4 @@ extern struct command vdi_command;
 extern struct command node_command;
 extern struct command cluster_command;
 
-#ifdef ENABLE_TRACE
-  extern struct command debug_command;
-#else
-  #define debug_command {}
-#endif /* ENABLE_TRACE */
-
 #endif
--- sheepdog-0.3.0.orig/collie/node.c
+++ sheepdog-0.3.0/collie/node.c
@@ -102,9 +102,7 @@ static int node_info(int argc, char **ar
 		return EXIT_SYSFAIL;
 	}
 
-	if (parse_vdi(cal_total_vdi_size, SD_INODE_HEADER_SIZE,
-			&total_vdi_size) < 0)
-		return EXIT_SYSFAIL;
+	parse_vdi(cal_total_vdi_size, SD_INODE_HEADER_SIZE, &total_vdi_size);
 
 	size_to_str(total_size, total_str, sizeof(total_str));
 	size_to_str(total_size - total_avail, avail_str, sizeof(avail_str));
@@ -118,56 +116,11 @@ static int node_info(int argc, char **ar
 	return EXIT_SUCCESS;
 }
 
-static int node_recovery(int argc, char **argv)
-{
-	int i, ret;
-
-	if (!raw_output) {
-		printf("Nodes In Recovery:\n");
-		printf("  Id   Host:Port         V-Nodes       Zone\n");
-	}
-
-	for (i = 0; i < nr_nodes; i++) {
-		char host[128];
-		int fd;
-		unsigned wlen, rlen;
-		struct sd_node_req req;
-		struct sd_node_rsp *rsp = (struct sd_node_rsp *)&req;
-
-		addr_to_str(host, sizeof(host), node_list_entries[i].addr, 0);
-
-		fd = connect_to(host, node_list_entries[i].port);
-		if (fd < 0)
-			return EXIT_FAILURE;
-
-		memset(&req, 0, sizeof(req));
-
-		req.opcode = SD_OP_STAT_RECOVERY;
-
-		wlen = 0;
-		rlen = 0;
-		ret = exec_req(fd, (struct sd_req *)&req, NULL, &wlen, &rlen);
-		close(fd);
-
-		if (!ret && rsp->result == SD_RES_SUCCESS) {
-			addr_to_str(host, sizeof(host),
-					node_list_entries[i].addr, node_list_entries[i].port);
-			printf(raw_output ? "%d %s %d %d\n" : "%4d   %-20s%5d%11d\n",
-				   i, host, node_list_entries[i].nr_vnodes,
-				   node_list_entries[i].zone);
-		}
-	}
-
-	return EXIT_SUCCESS;
-}
-
 static struct subcommand node_cmd[] = {
 	{"list", NULL, "aprh", "list nodes",
 	 SUBCMD_FLAG_NEED_NODELIST, node_list},
 	{"info", NULL, "aprh", "show information about each node",
 	 SUBCMD_FLAG_NEED_NODELIST, node_info},
-	{"recovery", NULL, "aprh", "show nodes in recovery",
-	 SUBCMD_FLAG_NEED_NODELIST, node_recovery},
 	{NULL,},
 };
 
--- sheepdog-0.3.0.orig/collie/Makefile.am
+++ sheepdog-0.3.0/collie/Makefile.am
@@ -24,12 +24,6 @@ INCLUDES		= -I$(top_builddir)/include -I
 sbin_PROGRAMS		= collie
 
 collie_SOURCES		= collie.c common.c treeview.c vdi.c node.c cluster.c
-
-if BUILD_TRACE
-collie_SOURCES          += debug.c
-override CFLAGS         := $(subst -pg -gstabs,,$(CFLAGS))
-endif
-
 collie_LDADD	  	= ../lib/libsheepdog.a
 collie_DEPENDENCIES	= ../lib/libsheepdog.a
 
--- sheepdog-0.3.0.orig/collie/vdi.c
+++ sheepdog-0.3.0/collie/vdi.c
@@ -32,9 +32,6 @@ struct get_vdi_info {
 	uint32_t snapid;
 };
 
-struct sd_node latest_node_list[SD_MAX_NODES];
-int nr_latest_node_list;
-
 static int parse_option_size(const char *value, uint64_t *ret)
 {
 	char *postfix;
@@ -68,7 +65,7 @@ static int parse_option_size(const char
 static void print_vdi_list(uint32_t vid, char *name, char *tag, uint32_t snapid,
 			   uint32_t flags, struct sheepdog_inode *i, void *data)
 {
-	int idx, is_clone = 0;
+	int idx;
 	uint64_t my_objs, cow_objs;
 	char vdi_size_str[16], my_objs_str[16], cow_objs_str[16];
 	time_t ti;
@@ -103,24 +100,19 @@ static void print_vdi_list(uint32_t vid,
 	size_to_str(my_objs * SD_DATA_OBJ_SIZE, my_objs_str, sizeof(my_objs_str));
 	size_to_str(cow_objs * SD_DATA_OBJ_SIZE, cow_objs_str, sizeof(cow_objs_str));
 
-	if (i->snap_id == 1 && i->parent_vdi_id != 0)
-		is_clone = 1;
-
 	if (raw_output) {
-		printf("%c ", is_current(i) ? (is_clone ? 'c' : '=') : 's');
+		printf("%c ", is_current(i) ? '=' : 's');
 		while (*name) {
 			if (isspace(*name) || *name == '\\')
 				putchar('\\');
 			putchar(*name++);
 		}
-		printf(" %d %s %s %s %s %" PRIx32 " %s\n", snapid,
-				vdi_size_str, my_objs_str, cow_objs_str, dbuf, vid,
-				i->tag);
+		printf(" %d %s %s %s %s %" PRIx32 "\n", snapid,
+				vdi_size_str, my_objs_str, cow_objs_str, dbuf, vid);
 	} else {
-		printf("%c %-8s %5d %7s %7s %7s %s  %7" PRIx32 "  %s\n",
-				is_current(i) ? (is_clone ? 'c' : ' ') : 's',
-				name, snapid, vdi_size_str, my_objs_str, cow_objs_str,
-				dbuf, vid, i->tag);
+		printf("%c %-8s %5d %7s %7s %7s %s  %7" PRIx32 "\n",
+				is_current(i) ? ' ' : 's', name, snapid,
+				vdi_size_str, my_objs_str, cow_objs_str, dbuf, vid);
 	}
 }
 
@@ -196,10 +188,10 @@ static void get_oid(uint32_t vid, char *
 	}
 }
 
-typedef int (*obj_parser_func_t)(char *sheep, uint64_t oid,
+typedef void (*obj_parser_func_t)(char *sheep, uint64_t oid,
 				  struct sd_obj_rsp *rsp, char *buf, void *data);
 
-static int do_print_obj(char *sheep, uint64_t oid, struct sd_obj_rsp *rsp,
+static void do_print_obj(char *sheep, uint64_t oid, struct sd_obj_rsp *rsp,
 			 char *buf, void *data)
 {
 	switch (rsp->result) {
@@ -219,8 +211,6 @@ static int do_print_obj(char *sheep, uin
 		       sheep, rsp->result);
 		break;
 	}
-
-	return 0;
 }
 
 struct get_data_oid_info {
@@ -229,7 +219,7 @@ struct get_data_oid_info {
 	unsigned idx;
 };
 
-static int get_data_oid(char *sheep, uint64_t oid, struct sd_obj_rsp *rsp,
+static void get_data_oid(char *sheep, uint64_t oid, struct sd_obj_rsp *rsp,
 			 char *buf, void *data)
 {
 	struct get_data_oid_info *info = data;
@@ -240,10 +230,8 @@ static int get_data_oid(char *sheep, uin
 		if (info->success)
 			break;
 		info->success = 1;
-		if (inode->data_vdi_id[info->idx]) {
+		if (inode->data_vdi_id[info->idx])
 			info->data_oid = vid_to_data_oid(inode->data_vdi_id[info->idx], info->idx);
-			return 1;
-		}
 		break;
 	case SD_RES_NO_OBJ:
 		break;
@@ -256,14 +244,12 @@ static int get_data_oid(char *sheep, uin
 		       sheep, rsp->result);
 		break;
 	}
-
-	return 0;
 }
 
 static void parse_objs(uint64_t oid, obj_parser_func_t func, void *data, unsigned size)
 {
 	char name[128];
-	int i, fd, ret, cb_ret;
+	int i, fd, ret;
 	char *buf;
 
 	buf = zalloc(size);
@@ -298,11 +284,8 @@ static void parse_objs(uint64_t oid, obj
 
 		if (ret)
 			fprintf(stderr, "Failed to connect to %s\n", name);
-		else {
-			cb_ret = func(name, oid, rsp, buf, data);
-			if (cb_ret)
-				break;
-		}
+		else
+			func(name, oid, rsp, buf, data);
 	}
 
 	free(buf);
@@ -314,18 +297,16 @@ static int vdi_list(int argc, char **arg
 	char *vdiname = argv[optind];
 
 	if (!raw_output)
-		printf("  Name        Id    Size    Used  Shared    Creation time   VDI id  Tag\n");
+		printf("  Name        Id    Size    Used  Shared    Creation time   VDI id\n");
 
 	if (vdiname) {
 		struct get_vdi_info info;
 		memset(&info, 0, sizeof(info));
 		info.name = vdiname;
-		if (parse_vdi(print_vdi_list, SD_INODE_SIZE, &info) < 0)
-			return EXIT_SYSFAIL;
+		parse_vdi(print_vdi_list, SD_INODE_SIZE, &info);
 		return EXIT_SUCCESS;
 	} else {
-		if (parse_vdi(print_vdi_list, SD_INODE_SIZE, NULL) < 0)
-			return EXIT_SYSFAIL;
+		parse_vdi(print_vdi_list, SD_INODE_SIZE, NULL);
 		return EXIT_SUCCESS;
 	}
 }
@@ -333,8 +314,7 @@ static int vdi_list(int argc, char **arg
 static int vdi_tree(int argc, char **argv)
 {
 	init_tree();
-	if (parse_vdi(print_vdi_tree, SD_INODE_HEADER_SIZE, NULL) < 0)
-		return EXIT_SYSFAIL;
+	parse_vdi(print_vdi_tree, SD_INODE_HEADER_SIZE, NULL);
 	dump_tree();
 
 	return EXIT_SUCCESS;
@@ -347,8 +327,7 @@ static int vdi_graph(int argc, char **ar
 	printf("  node [shape = \"box\", fontname = \"Courier\"];\n\n");
 	printf("  \"0\" [shape = \"ellipse\", label = \"root\"];\n\n");
 
-	if (parse_vdi(print_vdi_graph, SD_INODE_HEADER_SIZE, NULL) < 0)
-		return EXIT_SYSFAIL;
+	parse_vdi(print_vdi_graph, SD_INODE_HEADER_SIZE, NULL);
 
 	/* print a footer */
 	printf("}\n");
@@ -751,6 +730,7 @@ static int vdi_object(int argc, char **a
 {
 	char *vdiname = argv[optind];
 	unsigned idx = vdi_cmd_data.index;
+	int ret;
 	struct get_vdi_info info;
 	uint32_t vid;
 
@@ -760,8 +740,7 @@ static int vdi_object(int argc, char **a
 	info.vid = 0;
 	info.snapid = vdi_cmd_data.snapshot_id;
 
-	if (parse_vdi(get_oid, SD_INODE_HEADER_SIZE, &info) < 0)
-		return EXIT_SYSFAIL;
+	ret = parse_vdi(get_oid, SD_INODE_HEADER_SIZE, &info);
 
 	vid = info.vid;
 	if (vid == 0) {
@@ -803,129 +782,6 @@ static int vdi_object(int argc, char **a
 	return EXIT_SUCCESS;
 }
 
-static int print_obj_epoch(uint64_t oid)
-{
-	int i, j, fd, ret, idx;
-	struct sd_vdi_req hdr;
-	struct sd_vdi_rsp *rsp = (struct sd_vdi_rsp *)&hdr;
-	unsigned rlen, wlen;
-	struct sd_vnode vnodes[SD_MAX_VNODES];
-	struct epoch_log *logs;
-	int vnodes_nr, nr_logs, log_length;
-	char host[128];
-
-	log_length = node_list_version * sizeof(struct epoch_log);
-again:
-	logs = malloc(log_length);
-	if (!logs) {
-		if (log_length < 10) {
-			fprintf(stderr, "No memory to allocate.\n");
-			return EXIT_SYSFAIL;
-		}
-		log_length /= 2;
-		goto again;
-	}
-
-	fd = connect_to(sdhost, sdport);
-	if (fd < 0)
-		goto error;
-
-	memset(&hdr, 0, sizeof(hdr));
-
-	hdr.opcode = SD_OP_STAT_CLUSTER;
-	hdr.epoch = node_list_version;
-	hdr.data_length = log_length;
-
-	rlen = hdr.data_length;
-	wlen = 0;
-	ret = exec_req(fd, (struct sd_req *)&hdr, logs, &wlen, &rlen);
-	close(fd);
-
-	if (ret != 0)
-		goto error;
-
-	if (rsp->result != SD_RES_SUCCESS)
-		printf("%s\n", sd_strerror(rsp->result));
-
-	nr_logs = rsp->data_length / sizeof(struct epoch_log);
-	for (i = nr_logs - 1; i >= 0; i--) {
-		vnodes_nr = nodes_to_vnodes(logs[i].nodes, logs[i].nr_nodes, vnodes);
-		printf("\nobj %"PRIx64" locations at epoch %d, copies = %d\n",
-				oid, logs[i].epoch, logs[i].nr_copies);
-		printf("---------------------------------------------------\n");
-		for (j = 0; j < logs[i].nr_copies; j++) {
-			idx = obj_to_sheep(vnodes, vnodes_nr, oid, j);
-			addr_to_str(host, sizeof(host), vnodes[idx].addr,
-						vnodes[idx].port);
-			printf("%s\n", host);
-		}
-	}
-
-	free(logs);
-	return EXIT_SUCCESS;
-error:
-	free(logs);
-	return EXIT_SYSFAIL;
-}
-
-static int vdi_track(int argc, char **argv)
-{
-	char *vdiname = argv[optind];
-	unsigned idx = vdi_cmd_data.index;
-	struct get_vdi_info info;
-	uint32_t vid;
-
-	memset(&info, 0, sizeof(info));
-	info.name = vdiname;
-	info.tag = vdi_cmd_data.snapshot_tag;
-	info.vid = 0;
-	info.snapid = vdi_cmd_data.snapshot_id;
-
-	if (parse_vdi(get_oid, SD_INODE_HEADER_SIZE, &info) < 0)
-		return EXIT_SYSFAIL;
-
-	vid = info.vid;
-	if (vid == 0) {
-		fprintf(stderr, "VDI not found\n");
-		return EXIT_MISSING;
-	}
-
-	if (idx == ~0) {
-		printf("Tracking the inode object 0x%" PRIx32 " with %d nodes\n",
-		       vid, nr_nodes);
-		print_obj_epoch(vid_to_vdi_oid(vid));
-	} else {
-		struct get_data_oid_info oid_info;
-
-		oid_info.success = 0;
-		oid_info.idx = idx;
-
-		if (idx >= MAX_DATA_OBJS) {
-			printf("The offset is too large!\n");
-			exit(EXIT_FAILURE);
-		}
-
-		parse_objs(vid_to_vdi_oid(vid), get_data_oid,
-					&oid_info, SD_DATA_OBJ_SIZE);
-
-		if (oid_info.success) {
-			if (oid_info.data_oid) {
-				printf("Tracking the object 0x%" PRIx64
-				       " (the inode vid 0x%" PRIx32 " idx %u)"
-					   " with %d nodes\n",
-				       oid_info.data_oid, vid, idx, nr_nodes);
-				print_obj_epoch(oid_info.data_oid);
-
-			} else
-				printf("The inode object 0x%" PRIx32 " idx %u is not allocated\n",
-				       vid, idx);
-		} else
-			fprintf(stderr, "Failed to read the inode object 0x%"PRIx32"\n", vid);
-	}
-
-	return EXIT_SUCCESS;
-}
-
 static int find_vdi_attr_oid(char *vdiname, char *tag, uint32_t snapid,
 			     char *key, void *value, unsigned int value_len,
 			     uint32_t *vid, uint64_t *oid, unsigned int *nr_copies,
@@ -1340,8 +1196,6 @@ static struct subcommand vdi_cmd[] = {
 	 SUBCMD_FLAG_NEED_NODELIST, vdi_graph},
 	{"object", "<vdiname>", "isaph", "show object information in the image",
 	 SUBCMD_FLAG_NEED_NODELIST|SUBCMD_FLAG_NEED_THIRD_ARG, vdi_object},
-	{"track", "<vdiname>", "isaph", "show the object epoch trace in the image",
-	 SUBCMD_FLAG_NEED_NODELIST|SUBCMD_FLAG_NEED_THIRD_ARG, vdi_track},
 	{"setattr", "<vdiname> <key> [value]", "dxaph", "set a VDI attribute",
 	 SUBCMD_FLAG_NEED_NODELIST|SUBCMD_FLAG_NEED_THIRD_ARG, vdi_setattr},
 	{"getattr", "<vdiname> <key>", "aph", "get a VDI attribute",
--- sheepdog-0.3.0.orig/collie/common.c
+++ sheepdog-0.3.0/collie/common.c
@@ -68,12 +68,12 @@ int sd_read_object(uint64_t oid, void *d
 	close(fd);
 
 	if (ret) {
-		fprintf(stderr, "Failed to read object %" PRIx64 "\n", oid);
+		fprintf(stderr, "Failed to read object %lx\n", oid);
 		return SD_RES_EIO;
 	}
 
 	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Failed to read object %" PRIx64 " %s\n", oid,
+		fprintf(stderr, "Failed to read object %lx %s\n", oid,
 			sd_strerror(rsp->result));
 		return rsp->result;
 	}
@@ -112,11 +112,11 @@ int sd_write_object(uint64_t oid, uint64
 	close(fd);
 
 	if (ret) {
-		fprintf(stderr, "Failed to write object %" PRIx64 "\n", oid);
+		fprintf(stderr, "Failed to write object %lx\n", oid);
 		return SD_RES_EIO;
 	}
 	if (rsp->result != SD_RES_SUCCESS) {
-		fprintf(stderr, "Failed to write object %" PRIx64 ": %s\n", oid,
+		fprintf(stderr, "Failed to write object %lx: %s\n", oid,
 				sd_strerror(rsp->result));
 		return rsp->result;
 	}
@@ -134,10 +134,8 @@ int parse_vdi(vdi_parser_func_t func, si
 	unsigned int rlen, wlen = 0;
 
 	fd = connect_to(sdhost, sdport);
-	if (fd < 0) {
-		fprintf(stderr, "Failed to connect to %s:%d\n", sdhost, sdport);
+	if (fd < 0)
 		return fd;
-	}
 
 	memset(&req, 0, sizeof(req));
 
@@ -148,8 +146,6 @@ int parse_vdi(vdi_parser_func_t func, si
 	rlen = sizeof(vdi_inuse);
 	ret = exec_req(fd, &req, vdi_inuse, &wlen, &rlen);
 	if (ret < 0) {
-		fprintf(stderr, "Failed to read VDIs from %s:%d\n",
-			sdhost, sdport);
 		close(fd);
 		return ret;
 	}
--- sheepdog-0.3.0.orig/collie/collie.c
+++ sheepdog-0.3.0/collie/collie.c
@@ -40,32 +40,29 @@ static const struct sd_option collie_opt
 	{'d', "delete", 0, "delete a key"},
 
 	/* cluster options */
-	{'b', "store", 1, "specify backend store"},
 	{'c', "copies", 1, "specify the data redundancy (number of copies)"},
 	{'H', "nohalt", 0, "serve IO requests even if there are too few\n\
                           nodes for the configured redundancy"},
 	{'f', "force", 0, "do not prompt for confirmation"},
-	{'R', "restore", 1, "restore the cluster"},
-	{'l', "list", 0, "list the user epoch information"},
 
 	{ 0, NULL, 0, NULL },
 };
 
 static void usage(struct command *commands, int status);
 
-uint32_t node_list_version;
+uint64_t node_list_version;
 
-struct sd_node node_list_entries[SD_MAX_NODES];
-struct sd_vnode vnode_list_entries[SD_MAX_VNODES];
+struct sheepdog_node_list_entry node_list_entries[SD_MAX_NODES];
+struct sheepdog_vnode_list_entry vnode_list_entries[SD_MAX_VNODES];
 int nr_nodes, nr_vnodes;
 unsigned master_idx;
 
-static int update_node_list(int max_nodes, uint32_t epoch)
+static int update_node_list(int max_nodes, int epoch)
 {
 	int fd, ret;
 	unsigned int size, wlen;
 	char *buf = NULL;
-	struct sd_node *ent;
+	struct sheepdog_node_list_entry *ent;
 	struct sd_node_req hdr;
 	struct sd_node_rsp *rsp = (struct sd_node_rsp *)&hdr;
 
@@ -287,7 +284,6 @@ int main(int argc, char **argv)
 		vdi_command,
 		node_command,
 		cluster_command,
-		debug_command,
 		{NULL,}
 	};
 
--- sheepdog-0.3.0.orig/sheep/store.c
+++ sheepdog-0.3.0/sheep/store.c
@@ -16,118 +16,285 @@
 #include <stdlib.h>
 #include <unistd.h>
 #include <poll.h>
+#include <sys/xattr.h>
 #include <sys/statvfs.h>
 #include <sys/types.h>
 #include <sys/stat.h>
+#include <fcntl.h>
 #include <time.h>
-#include <pthread.h>
 
 #include "sheep_priv.h"
 #include "strbuf.h"
 #include "util.h"
-#include "farm/farm.h"
 
 struct sheepdog_config {
 	uint64_t ctime;
 	uint16_t flags;
 	uint8_t copies;
-	uint8_t store[STORE_LEN];
+	uint8_t pad[3];
 };
 
 char *obj_path;
-char *mnt_path;
-char *jrnl_path;
-char *epoch_path;
+static char *epoch_path;
+static char *mnt_path;
+static char *jrnl_path;
 static char *config_path;
 
-mode_t def_dmode = S_IRUSR | S_IWUSR | S_IXUSR | S_IRGRP | S_IWGRP | S_IXGRP;
+static mode_t def_dmode = S_IRUSR | S_IWUSR | S_IXUSR | S_IRGRP | S_IWGRP | S_IXGRP;
 mode_t def_fmode = S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP;
 
-struct store_driver *sd_store;
-LIST_HEAD(store_drivers);
+extern struct store_driver store;
 
-static int do_local_io(struct request *req, uint32_t epoch)
+static int obj_cmp(const void *oid1, const void *oid2)
 {
-	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+	const uint64_t hval1 = fnv_64a_buf((void *)oid1, sizeof(uint64_t), FNV1A_64_INIT);
+	const uint64_t hval2 = fnv_64a_buf((void *)oid2, sizeof(uint64_t), FNV1A_64_INIT);
 
-	hdr->epoch = epoch;
-	dprintf("%x, %" PRIx64" , %u\n", hdr->opcode, hdr->oid, epoch);
+	if (hval1 < hval2)
+		return -1;
+	if (hval1 > hval2)
+		return 1;
+	return 0;
+}
+
+int stat_sheep(uint64_t *store_size, uint64_t *store_free, uint32_t epoch)
+{
+	struct statvfs vs;
+	int ret;
+	DIR *dir;
+	struct dirent *d;
+	uint64_t used = 0;
+	struct stat s;
+	char path[1024], store_dir[1024];
+
+	ret = statvfs(mnt_path, &vs);
+	if (ret)
+		return SD_RES_EIO;
+
+	snprintf(store_dir, sizeof(store_dir), "%s%08u", obj_path, epoch);
+	dir = opendir(store_dir);
+	if (!dir)
+		return SD_RES_EIO;
+
+	while ((d = readdir(dir))) {
+		if (!strcmp(d->d_name, ".") || !strcmp(d->d_name, ".."))
+			continue;
+
+		snprintf(path, sizeof(path), "%s/%s", store_dir, d->d_name);
+
+		ret = stat(path, &s);
+		if (ret)
+			continue;
+
+		used += s.st_size;
+	}
+
+	closedir(dir);
 
-	return do_process_work(req->op, &req->rq, &req->rp, req);
+	*store_size = (uint64_t)vs.f_frsize * vs.f_bfree + used;
+	*store_free = (uint64_t)vs.f_frsize * vs.f_bfree;
+
+	return SD_RES_SUCCESS;
 }
 
-static int forward_read_obj_req(struct request *req)
+static int merge_objlist(uint64_t *list1, int nr_list1,
+			 uint64_t *list2, int nr_list2);
+
+int get_obj_list(const struct sd_list_req *hdr, struct sd_list_rsp *rsp, void *data)
+{
+	uint64_t *list = (uint64_t *)data;
+	int i, nr = 0;
+	int res = SD_RES_SUCCESS;
+	int buf_len;
+	char *buf;
+
+	/* FIXME: handle larger size */
+	buf_len = (1 << 22);
+	buf = zalloc(buf_len);
+	if (!buf) {
+		eprintf("failed to allocate memory\n");
+		res = SD_RES_NO_MEM;
+		goto out;
+	}
+
+	for (i = 1; i <= hdr->tgt_epoch; i++) {
+		struct siocb iocb = { 0 };
+
+		iocb.buf = buf;
+		iocb.length = 0;
+		iocb.epoch = i;
+		store.get_objlist(&iocb);
+		nr = merge_objlist(list, nr, (uint64_t *)iocb.buf, iocb.length);
+	}
+out:
+	free(buf);
+	rsp->data_length = nr * sizeof(uint64_t);
+	for (i = 0; i < nr; i++) {
+		dprintf("oid %"PRIx64"\n", list[i]);
+	}
+	return res;
+}
+
+static int read_copy_from_cluster(struct request *req, uint32_t epoch,
+				  uint64_t oid, char *buf)
 {
-	int i, fd, ret = SD_RES_SUCCESS;
+	int i, n, nr, ret;
 	unsigned wlen, rlen;
-	struct sd_obj_req hdr = *(struct sd_obj_req *)&req->rq;
+	char name[128];
+	struct sheepdog_vnode_list_entry *e;
+	struct sd_obj_req hdr;
 	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
-	struct sd_vnode *v;
-	uint64_t oid = hdr.oid;
-	int nr_copies;
+	struct siocb iocb;
+	int fd;
 
-	hdr.flags |= SD_FLAG_CMD_IO_LOCAL;
+	e = req->entry;
+	nr = req->nr_vnodes;
 
-	if (hdr.copies)
-		nr_copies = hdr.copies;
-	else
-		nr_copies = get_nr_copies(req->vnodes);
+	for (i = 0; i < nr; i++) {
+		n = obj_to_sheep(e, nr, oid, i);
 
-	/* TODO: we can do better; we need to check this first */
-	for (i = 0; i < nr_copies; i++) {
-		v = oid_to_vnode(req->vnodes, oid, i);
-		if (vnode_is_local(v)) {
-			ret = do_local_io(req, hdr.epoch);
+		addr_to_str(name, sizeof(name), e[n].addr, 0);
+
+		if (is_myself(e[n].addr, e[n].port)) {
+			memset(&iocb, 0, sizeof(iocb));
+			iocb.epoch = epoch;
+			ret = store.open(oid, &iocb, 0);
 			if (ret != SD_RES_SUCCESS)
-				goto read_remote;
-			return ret;
+				continue;
+
+			iocb.buf = buf;
+			iocb.length = SD_DATA_OBJ_SIZE;
+			iocb.offset = 0;
+			ret = store.read(oid, &iocb);
+			if (ret != SD_RES_SUCCESS)
+				continue;
+			store.close(oid, &iocb);
+			goto out;
 		}
-	}
 
-read_remote:
-	for (i = 0; i < nr_copies; i++) {
-		v = oid_to_vnode(req->vnodes, oid, i);
-		if (vnode_is_local(v))
+		fd = connect_to(name, e[n].port);
+		if (fd < 0)
 			continue;
 
-		fd = get_sheep_fd(v->addr, v->port, v->node_idx, hdr.epoch);
-		if (fd < 0) {
-			ret = SD_RES_NETWORK_ERROR;
-			continue;
-		}
+		memset(&hdr, 0, sizeof(hdr));
+		hdr.opcode = SD_OP_READ_OBJ;
+		hdr.oid = oid;
+		hdr.epoch = epoch;
 
+		rlen = SD_DATA_OBJ_SIZE;
 		wlen = 0;
-		rlen = hdr.data_length;
+		hdr.flags = SD_FLAG_CMD_IO_LOCAL;
+		hdr.data_length = rlen;
+		hdr.offset = 0;
 
-		ret = exec_req(fd, (struct sd_req *)&hdr, req->data, &wlen, &rlen);
+		ret = exec_req(fd, (struct sd_req *)&hdr, buf, &wlen, &rlen);
 
-		if (ret) { /* network errors */
-			del_sheep_fd(fd);
-			ret = SD_RES_NETWORK_ERROR;
+		close(fd);
+
+		if (ret)
 			continue;
-		} else {
-			memcpy(&req->rp, rsp, sizeof(*rsp));
-			ret = rsp->result;
+
+		switch (rsp->result) {
+		case SD_RES_SUCCESS:
+			ret = SD_RES_SUCCESS;
+			goto out;
+		case SD_RES_OLD_NODE_VER:
+		case SD_RES_NEW_NODE_VER:
+			/* waits for the node list timer */
 			break;
+		default:
+			;
+		}
+	}
+
+	ret = SD_RES_EIO;
+out:
+	return ret;
+}
+
+static int do_local_io(struct request *req, uint32_t epoch);
+
+static int forward_read_obj_req(struct request *req)
+{
+	int i, n, nr, fd, ret;
+	unsigned wlen, rlen;
+	struct sd_obj_req hdr = *(struct sd_obj_req *)&req->rq;
+	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
+	struct sheepdog_vnode_list_entry *e;
+	uint64_t oid = hdr.oid;
+	int copies;
+
+	e = req->entry;
+	nr = req->nr_vnodes;
+
+	copies = hdr.copies;
+
+	/* temporary hack */
+	if (!copies)
+		copies = sys->nr_sobjs;
+	if (copies > req->nr_zones)
+		copies = req->nr_zones;
+
+	hdr.flags |= SD_FLAG_CMD_IO_LOCAL;
+
+	/* TODO: we can do better; we need to check this first */
+	for (i = 0; i < copies; i++) {
+		n = obj_to_sheep(e, nr, oid, i);
+
+		if (is_myself(e[n].addr, e[n].port)) {
+			ret = do_local_io(req, hdr.epoch);
+			goto out;
 		}
 	}
+
+	n = obj_to_sheep(e, nr, oid, 0);
+
+	fd = get_sheep_fd(e[n].addr, e[n].port, e[n].node_idx, hdr.epoch);
+	if (fd < 0) {
+		ret = SD_RES_NETWORK_ERROR;
+		goto out;
+	}
+
+	wlen = 0;
+	rlen = hdr.data_length;
+
+	ret = exec_req(fd, (struct sd_req *)&hdr, req->data, &wlen, &rlen);
+
+	if (ret) { /* network errors */
+		del_sheep_fd(fd);
+		ret = SD_RES_NETWORK_ERROR;
+	} else {
+		memcpy(&req->rp, rsp, sizeof(*rsp));
+		ret = rsp->result;
+	}
+out:
 	return ret;
 }
 
-int forward_write_obj_req(struct request *req)
+static int forward_write_obj_req(struct request *req)
 {
-	int i, fd, ret, pollret;
+	int i, n, nr, fd, ret, pollret;
 	unsigned wlen;
 	char name[128];
 	struct sd_obj_req hdr = *(struct sd_obj_req *)&req->rq;
 	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&req->rp;
-	struct sd_vnode *v;
+	struct sheepdog_vnode_list_entry *e;
 	uint64_t oid = hdr.oid;
-	int nr_copies;
+	int copies;
 	struct pollfd pfds[SD_MAX_REDUNDANCY];
 	int nr_fds, local = 0;
 
 	dprintf("%"PRIx64"\n", oid);
+	e = req->entry;
+	nr = req->nr_vnodes;
+
+	copies = hdr.copies;
+
+	/* temporary hack */
+	if (!copies)
+		copies = sys->nr_sobjs;
+	if (copies > req->nr_zones)
+		copies = req->nr_zones;
 
 	nr_fds = 0;
 	memset(pfds, 0, sizeof(pfds));
@@ -138,20 +305,19 @@ int forward_write_obj_req(struct request
 
 	wlen = hdr.data_length;
 
-	nr_copies = get_nr_copies(req->vnodes);
-	for (i = 0; i < nr_copies; i++) {
-		v = oid_to_vnode(req->vnodes, oid, i);
+	for (i = 0; i < copies; i++) {
+		n = obj_to_sheep(e, nr, oid, i);
 
-		addr_to_str(name, sizeof(name), v->addr, 0);
+		addr_to_str(name, sizeof(name), e[n].addr, 0);
 
-		if (vnode_is_local(v)) {
+		if (is_myself(e[n].addr, e[n].port)) {
 			local = 1;
 			continue;
 		}
 
-		fd = get_sheep_fd(v->addr, v->port, v->node_idx, hdr.epoch);
+		fd = get_sheep_fd(e[n].addr, e[n].port, e[n].node_idx, hdr.epoch);
 		if (fd < 0) {
-			eprintf("failed to connect to %s:%"PRIu32"\n", name, v->port);
+			eprintf("failed to connect to %s:%"PRIu32"\n", name, e[n].port);
 			ret = SD_RES_NETWORK_ERROR;
 			goto out;
 		}
@@ -245,16 +411,15 @@ out:
 
 int update_epoch_store(uint32_t epoch)
 {
-	if (!strcmp(sd_store->name, "simple")) {
-		char new[1024];
+	char new[1024];
+
+	snprintf(new, sizeof(new), "%s%08u/", obj_path, epoch);
+	mkdir(new, def_dmode);
 
-		snprintf(new, sizeof(new), "%s%08u/", obj_path, epoch);
-		mkdir(new, def_dmode);
-	}
 	return 0;
 }
 
-int update_epoch_log(uint32_t epoch)
+int update_epoch_log(int epoch)
 {
 	int fd, ret, len;
 	time_t t;
@@ -269,7 +434,7 @@ int update_epoch_log(uint32_t epoch)
 		goto err_open;
 	}
 
-	len = sys->nr_nodes * sizeof(struct sd_node);
+	len = sys->nr_nodes * sizeof(struct sheepdog_node_list_entry);
 	ret = write(fd, (char *)sys->nodes, len);
 	if (ret != len)
 		goto err;
@@ -289,176 +454,338 @@ err_open:
 	return -1;
 }
 
-static int fix_object_consistency(struct request *req)
+int write_object_local(uint64_t oid, char *data, unsigned int datalen,
+		       uint64_t offset, uint16_t flags, int copies,
+		       uint32_t epoch, int create)
 {
-	int ret = SD_RES_NO_MEM;
-	unsigned int data_length;
-	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
-	struct sd_obj_req req_bak = *((struct sd_obj_req *)&req->rq);
-	struct sd_obj_rsp rsp_bak = *((struct sd_obj_rsp *)&req->rp);
-	void *data = req->data, *buf;
-	uint64_t oid = hdr->oid;
-	int old_opcode = hdr->opcode;
-
-	if (is_vdi_obj(hdr->oid))
-		data_length = SD_INODE_SIZE;
-	else if (is_vdi_attr_obj(hdr->oid))
-		data_length = SD_ATTR_OBJ_SIZE;
-	else
-		data_length = SD_DATA_OBJ_SIZE;
-
-	buf = valloc(data_length);
-	if (buf == NULL) {
-		eprintf("failed to allocate memory\n");
-		goto out;
-	}
-	memset(buf, 0, data_length);
+	int ret;
+	struct request *req;
+	struct sd_obj_req *hdr;
 
-	req->data = buf;
-	hdr->offset = 0;
-	hdr->data_length = data_length;
-	hdr->opcode = SD_OP_READ_OBJ;
-	hdr->flags = 0;
-	req->op = get_sd_op(SD_OP_READ_OBJ);
-	ret = forward_read_obj_req(req);
-	if (ret != SD_RES_SUCCESS) {
-		eprintf("failed to read object %x\n", ret);
-		goto out;
-	}
+	req = zalloc(sizeof(*req));
+	if (!req)
+		return SD_RES_NO_MEM;
+	hdr = (struct sd_obj_req *)&req->rq;
 
-	hdr->opcode = SD_OP_CREATE_AND_WRITE_OBJ;
-	hdr->flags = SD_FLAG_CMD_WRITE;
 	hdr->oid = oid;
-	req->op = get_sd_op(hdr->opcode);
-	ret = forward_write_obj_req(req);
-	if (ret != SD_RES_SUCCESS) {
-		eprintf("failed to write object %x\n", ret);
-		goto out;
-	}
-out:
-	free(buf);
+	if (create)
+		hdr->opcode = SD_OP_CREATE_AND_WRITE_OBJ;
+	else
+		hdr->opcode = SD_OP_WRITE_OBJ;
+	hdr->copies = copies;
+	hdr->flags = flags | SD_FLAG_CMD_WRITE;
+	hdr->offset = offset;
+	hdr->data_length = datalen;
 	req->data = data;
-	req->op = get_sd_op(old_opcode);
-	*((struct sd_obj_req *)&req->rq) = req_bak;
-	*((struct sd_obj_rsp *)&req->rp) = rsp_bak;
+	req->op = get_sd_op(hdr->opcode);
+
+	ret = do_local_io(req, epoch);
+
+	free(req);
 
 	return ret;
 }
 
-static int handle_gateway_request(struct request *req)
+int read_object_local(uint64_t oid, char *data, unsigned int datalen,
+		      uint64_t offset, int copies, uint32_t epoch)
 {
-	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
-	uint64_t oid = hdr->oid;
-	uint32_t vid = oid_to_vid(oid);
-	uint32_t idx = data_oid_to_idx(oid);
-	struct object_cache *cache;
-	int ret, create = 0;
+	int ret;
+	struct request *req;
+	struct sd_obj_req *hdr;
+	struct sd_obj_rsp *rsp;
+	unsigned int rsp_data_length;
 
-	if (is_vdi_obj(oid))
-		idx |= 1 << CACHE_VDI_SHIFT;
+	req = zalloc(sizeof(*req));
+	if (!req)
+		return SD_RES_NO_MEM;
+	hdr = (struct sd_obj_req *)&req->rq;
+	rsp = (struct sd_obj_rsp *)&req->rp;
 
-	cache = find_object_cache(vid, 1);
+	hdr->oid = oid;
+	hdr->opcode = SD_OP_READ_OBJ;
+	hdr->copies = copies;
+	hdr->flags = 0;
+	hdr->offset = offset;
+	hdr->data_length = datalen;
+	req->data = data;
+	req->op = get_sd_op(hdr->opcode);
 
-	if (hdr->opcode == SD_OP_CREATE_AND_WRITE_OBJ)
-		create = 1;
+	ret = do_local_io(req, epoch);
 
-	if (object_cache_lookup(cache, idx, create) < 0) {
-		ret = object_cache_pull(cache, idx);
-		if (ret != SD_RES_SUCCESS)
-			return ret;
-	}
-	return object_cache_rw(cache, idx, req);
+	rsp_data_length = rsp->data_length;
+	free(req);
+
+	return ret;
 }
 
-static int bypass_object_cache(struct sd_obj_req *hdr)
+int store_remove_obj(const struct sd_req *req, struct sd_rsp *rsp, void *data)
 {
-	uint64_t oid = hdr->oid;
+	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
+	uint32_t epoch = hdr->epoch;
+	char path[1024];
 
-	if (!(hdr->flags & SD_FLAG_CMD_CACHE)) {
-		uint32_t vid = oid_to_vid(oid);
-		struct object_cache *cache;
+	snprintf(path, sizeof(path), "%s%08u/%016" PRIx64, obj_path,
+		 epoch, hdr->oid);
 
-		cache = find_object_cache(vid, 0);
-		if (!cache)
-			return 1;
-		if (hdr->flags & SD_FLAG_CMD_WRITE) {
-			object_cache_flush_and_delete(cache);
-			return 1;
-		} else  {
-			/* For read requet, we can read cache if any */
-			uint32_t idx = data_oid_to_idx(oid);
-			if (is_vdi_obj(oid))
-				idx |= 1 << CACHE_VDI_SHIFT;
-
-			if (object_cache_lookup(cache, idx, 0) < 0)
-				return 1;
-			else
-				return 0;
-		}
+	if (unlink(path) < 0) {
+		if (errno == ENOENT)
+			return SD_RES_NO_OBJ;
+		eprintf("%m\n");
+		return SD_RES_EIO;
 	}
 
-	/*
-	 * For vmstate && vdi_attr object, we don't do caching
-	 */
-	if (is_vmstate_obj(oid) || is_vdi_attr_obj(oid) ||
-	    hdr->flags & SD_FLAG_CMD_COW)
-		return 1;
-	return 0;
+	return SD_RES_SUCCESS;
 }
 
-void do_io_request(struct work *work)
+int store_read_obj(const struct sd_req *req, struct sd_rsp *rsp, void *data)
 {
-	struct request *req = container_of(work, struct request, work);
-	int ret = SD_RES_SUCCESS;
-	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
-	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&req->rp;
-	uint64_t oid = hdr->oid;
-	uint32_t opcode = hdr->opcode;
+	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
+	struct sd_obj_rsp *rsps = (struct sd_obj_rsp *)rsp;
+	struct request *request = (struct request *)data;
+	int ret;
 	uint32_t epoch = hdr->epoch;
+	struct siocb iocb;
 
-	dprintf("%x, %" PRIx64" , %u\n", opcode, oid, epoch);
+	memset(&iocb, 0, sizeof(iocb));
+	iocb.epoch = epoch;
+	iocb.flags = hdr->flags;
+	ret = store.open(hdr->oid, &iocb, 0);
+	if (ret != SD_RES_SUCCESS)
+		return ret;
 
-	if (hdr->flags & SD_FLAG_CMD_RECOVERY)
-		epoch = hdr->tgt_epoch;
+	iocb.buf = request->data;
+	iocb.length = hdr->data_length;
+	iocb.offset = hdr->offset;
+	ret = store.read(hdr->oid, &iocb);
+	if (ret != SD_RES_SUCCESS)
+		goto out;
 
-	if (hdr->flags & SD_FLAG_CMD_IO_LOCAL) {
-		ret = do_local_io(req, epoch);
-	} else {
-		if (bypass_object_cache(hdr)) {
-			/* fix object consistency when we read the object for the first time */
-			if (req->check_consistency) {
-				ret = fix_object_consistency(req);
-				if (ret != SD_RES_SUCCESS)
-					goto out;
-			}
-			if (hdr->flags & SD_FLAG_CMD_WRITE)
-				ret = forward_write_obj_req(req);
-			else
-				ret = forward_read_obj_req(req);
-		} else
-			ret = handle_gateway_request(req);
-	}
+	rsps->data_length = hdr->data_length;
+	rsps->copies = sys->nr_sobjs;
 out:
-	if (ret != SD_RES_SUCCESS)
-		dprintf("failed: %x, %" PRIx64" , %u, %"PRIx32"\n",
-			opcode, oid, epoch, ret);
-	rsp->result = ret;
+	store.close(hdr->oid, &iocb);
+	return ret;
 }
 
-int epoch_log_read_remote(uint32_t epoch, char *buf, int len)
+static int do_write_obj(struct siocb *iocb, struct sd_obj_req *req, uint32_t epoch, void *data)
 {
-	struct sd_obj_req hdr;
-	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
-	int fd, i, ret;
-	unsigned int rlen, wlen, nr, le = get_latest_epoch();
-	char host[128];
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
+	uint64_t oid = hdr->oid;
+	int ret = SD_RES_SUCCESS;
+	void *jd = NULL;
 
-	nr = epoch_log_read(le, (char *)nodes, sizeof(nodes));
-	nr /= sizeof(nodes[0]);
-	for (i = 0; i < nr; i++) {
-		if (is_myself(nodes[i].addr, nodes[i].port))
-			continue;
+	iocb->buf = data;
+	iocb->length = hdr->data_length;
+	iocb->offset = hdr->offset;
+	if (is_vdi_obj(oid)) {
+		char path[1024];
+
+		snprintf(path, sizeof(path), "%s%08u/%016" PRIx64, obj_path,
+			 epoch, oid);
+		jd = jrnl_begin(data, hdr->data_length,
+				   hdr->offset, path, jrnl_path);
+		if (!jd)
+			return SD_RES_EIO;
+		ret = store.write(oid, iocb);
+		jrnl_end(jd);
+	} else
+		ret = store.write(oid, iocb);
+
+	return ret;
+}
+
+int store_write_obj(const struct sd_req *req, struct sd_rsp *rsp, void *data)
+{
+	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
+	struct request *request = (struct request *)data;
+	int ret;
+	uint32_t epoch = hdr->epoch;
+	struct siocb iocb;
+
+	memset(&iocb, 0, sizeof(iocb));
+	iocb.epoch = epoch;
+	iocb.flags = hdr->flags;
+	ret = store.open(hdr->oid, &iocb, 0);
+	if (ret != SD_RES_SUCCESS)
+		return ret;
+
+	ret = do_write_obj(&iocb, hdr, epoch, request->data);
+
+	store.close(hdr->oid, &iocb);
+	return ret;
+}
+
+int store_create_and_write_obj(const struct sd_req *req, struct sd_rsp *rsp, void *data)
+{
+	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
+	struct request *request = (struct request *)data;
+	int ret;
+	uint32_t epoch = hdr->epoch;
+	char *buf = NULL;
+	struct siocb iocb;
+
+	if (!hdr->copies) {
+		eprintf("the number of copies cannot be zero\n");
+		return SD_RES_INVALID_PARMS;
+	}
+
+	memset(&iocb, 0, sizeof(iocb));
+	iocb.epoch = epoch;
+	iocb.flags = hdr->flags;
+	ret = store.open(hdr->oid, &iocb, 1);
+	if (ret != SD_RES_SUCCESS)
+		return ret;
+	if (hdr->flags & SD_FLAG_CMD_COW) {
+		dprintf("%" PRIu64 ", %" PRIx64 "\n", hdr->oid, hdr->cow_oid);
+
+		buf = xzalloc(SD_DATA_OBJ_SIZE);
+		ret = read_copy_from_cluster(request, hdr->epoch, hdr->cow_oid, buf);
+		if (ret != SD_RES_SUCCESS) {
+			eprintf("failed to read cow object\n");
+			goto out;
+		}
+		iocb.buf = buf;
+		iocb.length = SD_DATA_OBJ_SIZE;
+		iocb.offset = 0;
+		ret = store.write(hdr->oid, &iocb);
+		if (ret != SD_RES_SUCCESS)
+			goto out;
+	}
+	ret = do_write_obj(&iocb, hdr, epoch, request->data);
+out:
+	free(buf);
+	store.close(hdr->oid, &iocb);
+	return ret;
+}
+
+static int do_local_io(struct request *req, uint32_t epoch)
+{
+	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+	int ret = SD_RES_SUCCESS;
+
+	hdr->epoch = epoch;
+	dprintf("%x, %" PRIx64" , %u\n", hdr->opcode, hdr->oid, epoch);
+
+	ret = do_process_work(req->op, &req->rq, &req->rp, req);
+
+	if (ret == SD_RES_NO_OBJ && hdr->flags & SD_FLAG_CMD_RECOVERY) {
+		struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&req->rp;
+		int len = epoch_log_read(epoch - 1, req->data, hdr->data_length);
+		if (len < 0)
+			len = 0;
+		rsp->data_length = len;
+	}
+
+	return ret;
+}
+
+static int fix_object_consistency(struct request *req)
+{
+	int ret = SD_RES_NO_MEM;
+	unsigned int data_length;
+	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+	struct sd_obj_req req_bak = *((struct sd_obj_req *)&req->rq);
+	struct sd_obj_rsp rsp_bak = *((struct sd_obj_rsp *)&req->rp);
+	void *data = req->data, *buf;
+	uint64_t oid = hdr->oid;
+	int old_opcode = hdr->opcode;
+
+	if (is_vdi_obj(hdr->oid))
+		data_length = sizeof(struct sheepdog_inode);
+	else if (is_vdi_attr_obj(hdr->oid))
+		data_length = SD_MAX_VDI_ATTR_VALUE_LEN;
+	else
+		data_length = SD_DATA_OBJ_SIZE;
+
+	buf = valloc(data_length);
+	if (buf == NULL) {
+		eprintf("failed to allocate memory\n");
+		goto out;
+	}
+	memset(buf, 0, data_length);
+
+	req->data = buf;
+	hdr->offset = 0;
+	hdr->data_length = data_length;
+	hdr->opcode = SD_OP_READ_OBJ;
+	hdr->flags = 0;
+	req->op = get_sd_op(SD_OP_READ_OBJ);
+	ret = forward_read_obj_req(req);
+	if (ret != SD_RES_SUCCESS) {
+		eprintf("failed to read object %d\n", ret);
+		goto out;
+	}
+
+	hdr->opcode = SD_OP_WRITE_OBJ;
+	hdr->flags = SD_FLAG_CMD_WRITE;
+	hdr->oid = oid;
+	req->op = get_sd_op(SD_OP_WRITE_OBJ);
+	ret = forward_write_obj_req(req);
+	if (ret != SD_RES_SUCCESS) {
+		eprintf("failed to write object %d\n", ret);
+		goto out;
+	}
+out:
+	free(buf);
+	req->data = data;
+	req->op = get_sd_op(old_opcode);
+	*((struct sd_obj_req *)&req->rq) = req_bak;
+	*((struct sd_obj_rsp *)&req->rp) = rsp_bak;
+
+	return ret;
+}
+
+void do_io_request(struct work *work)
+{
+	struct request *req = container_of(work, struct request, work);
+	int ret = SD_RES_SUCCESS;
+	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&req->rp;
+	uint64_t oid = hdr->oid;
+	uint32_t opcode = hdr->opcode;
+	uint32_t epoch = hdr->epoch;
+
+	dprintf("%x, %" PRIx64" , %u\n", opcode, oid, epoch);
+
+	if (hdr->flags & SD_FLAG_CMD_RECOVERY)
+		epoch = hdr->tgt_epoch;
+
+	if (hdr->flags & SD_FLAG_CMD_IO_LOCAL) {
+		ret = do_local_io(req, epoch);
+	} else {
+		/* fix object consistency when we read the object for the first time */
+		if (req->check_consistency) {
+			ret = fix_object_consistency(req);
+			if (ret != SD_RES_SUCCESS)
+				goto out;
+		}
+
+		if (hdr->flags & SD_FLAG_CMD_WRITE)
+			ret = forward_write_obj_req(req);
+		else
+			ret = forward_read_obj_req(req);
+	}
+out:
+	if (ret != SD_RES_SUCCESS)
+		dprintf("failed: %x, %" PRIx64" , %u, %"PRIu32"\n",
+			opcode, oid, epoch, ret);
+	rsp->result = ret;
+}
+
+int epoch_log_read_remote(uint32_t epoch, char *buf, int len)
+{
+	struct sd_obj_req hdr;
+	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
+	int fd, i, ret;
+	unsigned int rlen, wlen, nr, le = get_latest_epoch();
+	char host[128];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
+
+	nr = epoch_log_read(le, (char *)nodes, ARRAY_SIZE(nodes));
+	nr /= sizeof(nodes[0]);
+	for (i = 0; i < nr; i++) {
+		if (is_myself(nodes[i].addr, nodes[i].port))
+			continue;
 
 		addr_to_str(host, sizeof(host), nodes[i].addr, 0);
 		fd = connect_to(host, nodes[i].port);
@@ -496,7 +823,7 @@ int epoch_log_read_nr(uint32_t epoch, ch
 	nr = epoch_log_read(epoch, buf, len);
 	if (nr < 0)
 		return nr;
-	nr /= sizeof(struct sd_node);
+	nr /= sizeof(struct sheepdog_node_list_entry);
 	return nr;
 }
 
@@ -517,7 +844,7 @@ int epoch_log_read(uint32_t epoch, char
 	return len;
 }
 
-uint32_t get_latest_epoch(void)
+int get_latest_epoch(void)
 {
 	DIR *dir;
 	struct dirent *d;
@@ -544,7 +871,7 @@ uint32_t get_latest_epoch(void)
 }
 
 /* remove directory recursively */
-int rmdir_r(char *dir_path)
+static int rmdir_r(char *dir_path)
 {
 	int ret;
 	struct stat s;
@@ -588,6 +915,35 @@ out:
 	return ret;
 }
 
+int remove_epoch(int epoch)
+{
+	int ret;
+	char path[PATH_MAX];
+
+	dprintf("remove epoch %"PRIu32"\n", epoch);
+	snprintf(path, sizeof(path), "%s%08u", epoch_path, epoch);
+	ret = unlink(path);
+	if (ret && ret != -ENOENT) {
+		eprintf("failed to remove %s: %s\n", path, strerror(-ret));
+		return SD_RES_EIO;
+	}
+
+	snprintf(path, sizeof(path), "%s%08u", obj_path, epoch);
+	ret = rmdir_r(path);
+	if (ret && ret != -ENOENT) {
+		eprintf("failed to remove %s: %s\n", path, strerror(-ret));
+		return SD_RES_EIO;
+	}
+
+	snprintf(path, sizeof(path), "%s%08u/", jrnl_path, epoch);
+	ret = rmdir_r(path);
+	if (ret && ret != -ENOENT) {
+		eprintf("failed to remove %s: %s\n", path, strerror(-ret));
+		return SD_RES_EIO;
+	}
+	return 0;
+}
+
 int set_cluster_ctime(uint64_t ct)
 {
 	int fd, ret;
@@ -604,34 +960,831 @@ int set_cluster_ctime(uint64_t ct)
 		ret = SD_RES_EIO;
 		goto err;
 	}
-	ret = xpwrite(fd, &ct, sizeof(ct), offsetof(struct sheepdog_config, ctime));
-	if (ret != sizeof(ct))
-		ret = SD_RES_EIO;
-	else
-		ret = SD_RES_SUCCESS;
+	ret = xpwrite(fd, &ct, sizeof(ct), offsetof(struct sheepdog_config, ctime));
+	if (ret != sizeof(ct))
+		ret = SD_RES_EIO;
+	else
+		ret = SD_RES_SUCCESS;
+
+	jrnl_end(jd);
+err:
+	close(fd);
+	return ret;
+}
+
+uint64_t get_cluster_ctime(void)
+{
+	int fd, ret;
+	uint64_t ct;
+
+	fd = open(config_path, O_RDONLY);
+	if (fd < 0)
+		return 0;
+
+	ret = xpread(fd, &ct, sizeof(ct),
+		     offsetof(struct sheepdog_config, ctime));
+	close(fd);
+
+	if (ret != sizeof(ct))
+		return 0;
+	return ct;
+}
+
+static int get_max_copies(struct sheepdog_node_list_entry *entries, int nr)
+{
+	int i, j;
+	unsigned int nr_zones = 0;
+	uint32_t zones[SD_MAX_REDUNDANCY];
+
+	for (i = 0; i < nr; i++) {
+		if (nr_zones >= ARRAY_SIZE(zones))
+			break;
+
+		for (j = 0; j < nr_zones; j++) {
+			if (zones[j] == entries[i].zone)
+				break;
+		}
+		if (j == nr_zones)
+			zones[nr_zones++] = entries[i].zone;
+	}
+
+	return min(sys->nr_sobjs, nr_zones);
+}
+
+/*
+ * contains_node - checks that the node id is included in the target nodes
+ *
+ * The target nodes to store replicated objects are the first N nodes
+ * from the base_idx'th on the consistent hash ring, where N is the
+ * number of copies of objects.
+ */
+static int contains_node(struct sheepdog_vnode_list_entry *key,
+			 struct sheepdog_vnode_list_entry *entry,
+			 int nr, int base_idx, int copies)
+{
+	int i;
+
+	for (i = 0; i < copies; i++) {
+		int idx = get_nth_node(entry, nr, base_idx, i);
+		if (memcmp(key->addr, entry[idx].addr, sizeof(key->addr)) == 0
+		    && key->port == entry[idx].port)
+			return idx;
+	}
+	return -1;
+}
+
+enum rw_state {
+	RW_INIT,
+	RW_RUN,
+};
+
+struct recovery_work {
+	enum rw_state state;
+
+	uint32_t epoch;
+	uint32_t done;
+
+	struct timer timer;
+	int retry;
+	struct work work;
+
+	int nr_blocking;
+	int count;
+	uint64_t *oids;
+
+	int old_nr_nodes;
+	struct sheepdog_node_list_entry old_nodes[SD_MAX_NODES];
+	int cur_nr_nodes;
+	struct sheepdog_node_list_entry cur_nodes[SD_MAX_NODES];
+	int old_nr_vnodes;
+	struct sheepdog_vnode_list_entry old_vnodes[SD_MAX_VNODES];
+	int cur_nr_vnodes;
+	struct sheepdog_vnode_list_entry cur_vnodes[SD_MAX_VNODES];
+};
+
+static struct recovery_work *next_rw;
+static struct recovery_work *recovering_work;
+
+/*
+ * find_tgt_node - find the node from which we should recover objects
+ *
+ * This function compares two node lists, the current target nodes and
+ * the previous target nodes, and finds the node from the previous
+ * target nodes which corresponds to the copy_idx'th node of the
+ * current target nodes.  The correspondence is injective and
+ * maximizes the number of nodes which can recover objects locally.
+ *
+ * For example, consider the number of redundancy is 5, the consistent
+ * hash ring is {A, B, C, D, E, F}, and the node G is newly added.
+ * The parameters of this function are
+ *   old_entry = {A, B, C, D, E, F},    old_nr = 6, old_idx = 3
+ *   cur_entry = {A, B, C, D, E, F, G}, cur_nr = 7, cur_idx = 3
+ *
+ * In this case:
+ *   the previous target nodes: {D, E, F, A, B}
+ *     (the first 5 nodes from the 3rd node on the previous hash ring)
+ *   the current target nodes : {D, E, F, G, A}
+ *     (the first 5 nodes from the 3rd node on the current hash ring)
+ *
+ * The correspondence between copy_idx and return value are as follows:
+ * ----------------------------
+ * copy_idx       0  1  2  3  4
+ * src_node       D  E  F  G  A
+ * tgt_node       D  E  F  B  A
+ * return value   0  1  2  4  3
+ * ----------------------------
+ *
+ * The node D, E, F, and A can recover objects from local, and the
+ * node G recovers from the node B.
+ */
+static int find_tgt_node(struct sheepdog_vnode_list_entry *old_entry,
+			 int old_nr, int old_idx, int old_copies,
+			 struct sheepdog_vnode_list_entry *cur_entry,
+			 int cur_nr, int cur_idx, int cur_copies,
+			 int copy_idx)
+{
+	int i, j, idx;
+
+	dprintf("%"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32"\n",
+		old_idx, old_nr, old_copies, cur_idx, cur_nr, cur_copies, copy_idx);
+
+	/* If the same node is in the previous target nodes, return its index */
+	idx = contains_node(cur_entry + get_nth_node(cur_entry, cur_nr, cur_idx, copy_idx),
+			    old_entry, old_nr, old_idx, old_copies);
+	if (idx >= 0) {
+		dprintf("%"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32"\n", idx, copy_idx, cur_idx, cur_nr);
+		return idx;
+	}
+
+	for (i = 0, j = 0; ; i++, j++) {
+		if (i < copy_idx) {
+			/* Skip if the node can recover from its local */
+			idx = contains_node(cur_entry + get_nth_node(cur_entry, cur_nr, cur_idx, i),
+					    old_entry, old_nr, old_idx, old_copies);
+			if (idx >= 0)
+				continue;
+
+			/* Find the next target which needs to recover from remote */
+			while (j < old_copies &&
+			       contains_node(old_entry + get_nth_node(old_entry, old_nr, old_idx, j),
+					     cur_entry, cur_nr, cur_idx, cur_copies) >= 0)
+				j++;
+		}
+		if (j == old_copies) {
+			/*
+			 * Cannot find the target because the number of zones
+			 * is smaller than the number of copies.  We can select
+			 * any node in this case, so select the first one.
+			 */
+			return old_idx;
+		}
+
+		if (i == copy_idx) {
+			/* Found the target node correspoinding to copy_idx */
+			dprintf("%"PRIu32", %"PRIu32", %"PRIu32"\n",
+				get_nth_node(old_entry, old_nr, old_idx, j),
+				copy_idx, (cur_idx + i) % cur_nr);
+			return get_nth_node(old_entry, old_nr, old_idx, j);
+		}
+
+	}
+
+	return -1;
+}
+
+static int __recover_one(struct recovery_work *rw,
+			 struct sheepdog_vnode_list_entry *_old_entry,
+			 int old_nr, int old_copies,
+			 struct sheepdog_vnode_list_entry *_cur_entry,
+			 int cur_nr, int cur_copies, int cur_idx,
+			 int copy_idx, uint32_t epoch, uint32_t tgt_epoch,
+			 uint64_t oid, char *buf, int buf_len)
+{
+	struct sheepdog_vnode_list_entry *e;
+	struct sd_obj_req hdr;
+	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
+	char name[128];
+	unsigned wlen = 0, rlen;
+	int fd, ret;
+	struct sheepdog_vnode_list_entry *old_entry, *cur_entry, *next_entry;
+	int next_nr, next_copies;
+	int tgt_idx = -1;
+	int old_idx;
+
+	old_entry = malloc(sizeof(*old_entry) * SD_MAX_VNODES);
+	cur_entry = malloc(sizeof(*cur_entry) * SD_MAX_VNODES);
+	next_entry = malloc(sizeof(*next_entry) * SD_MAX_VNODES);
+	if (!old_entry || !cur_entry || !next_entry) {
+		eprintf("failed to allocate memory\n");
+		goto err;
+	}
+
+	memcpy(old_entry, _old_entry, sizeof(*old_entry) * old_nr);
+	memcpy(cur_entry, _cur_entry, sizeof(*cur_entry) * cur_nr);
+next:
+	dprintf("recover object %"PRIx64" from epoch %"PRIu32"\n", oid, tgt_epoch);
+	old_idx = obj_to_sheep(old_entry, old_nr, oid, 0);
+
+	tgt_idx = find_tgt_node(old_entry, old_nr, old_idx, old_copies,
+				cur_entry, cur_nr, cur_idx, cur_copies, copy_idx);
+	if (tgt_idx < 0) {
+		eprintf("cannot find target node %"PRIx64"\n", oid);
+		goto err;
+	}
+	e = old_entry + tgt_idx;
+
+	if (is_myself(e->addr, e->port)) {
+		struct siocb iocb = { 0 };
+
+		iocb.epoch = epoch;
+		ret = store.link(oid, &iocb, tgt_epoch);
+		if (ret == SD_RES_SUCCESS)
+			goto out;
+
+		if (ret == SD_RES_NO_OBJ) {
+			next_nr = epoch_log_read(tgt_epoch - 1, buf, buf_len);
+			if (next_nr <= 0) {
+				eprintf("no previous epoch: %"PRIu32"\n", tgt_epoch - 1);
+				goto err;
+			}
+			next_nr /= sizeof(struct sheepdog_node_list_entry);
+			next_copies = get_max_copies((struct sheepdog_node_list_entry *)buf,
+						     next_nr);
+			next_nr = nodes_to_vnodes((struct sheepdog_node_list_entry *)buf,
+						  next_nr, next_entry);
+			goto not_found;
+		}
+
+		eprintf("Cannot recover from local store for %"PRIx64"\n", oid);
+		goto err;
+	}
+
+	addr_to_str(name, sizeof(name), e->addr, 0);
+
+	fd = connect_to(name, e->port);
+	if (fd < 0) {
+		eprintf("failed to connect to %s:%"PRIu32"\n", name, e->port);
+		goto err;
+	}
+
+	if (is_vdi_obj(oid))
+		rlen = sizeof(struct sheepdog_inode);
+	else if (is_vdi_attr_obj(oid))
+		rlen = SD_MAX_VDI_ATTR_VALUE_LEN;
+	else
+		rlen = SD_DATA_OBJ_SIZE;
+
+	memset(&hdr, 0, sizeof(hdr));
+	hdr.opcode = SD_OP_READ_OBJ;
+	hdr.oid = oid;
+	hdr.epoch = epoch;
+	hdr.flags = SD_FLAG_CMD_RECOVERY | SD_FLAG_CMD_IO_LOCAL;
+	hdr.tgt_epoch = tgt_epoch;
+	hdr.data_length = rlen;
+
+	ret = exec_req(fd, (struct sd_req *)&hdr, buf, &wlen, &rlen);
+
+	close(fd);
+
+	if (ret != 0) {
+		eprintf("%"PRIu32"\n", rsp->result);
+		goto err;
+	}
+
+	rsp = (struct sd_obj_rsp *)&hdr;
+
+	if (rsp->result == SD_RES_SUCCESS) {
+		char path[PATH_MAX], tmp_path[PATH_MAX];
+		int flags = O_DSYNC | O_RDWR | O_CREAT;
+
+		snprintf(path, sizeof(path), "%s%08u/%016" PRIx64, obj_path,
+			 epoch, oid);
+		snprintf(tmp_path, sizeof(tmp_path), "%s%08u/%016" PRIx64 ".tmp",
+			 obj_path, epoch, oid);
+
+		fd = open(tmp_path, flags, def_fmode);
+		if (fd < 0) {
+			eprintf("failed to open %s: %m\n", tmp_path);
+			goto err;
+		}
+
+		ret = write(fd, buf, rlen);
+		if (ret != rlen) {
+			eprintf("failed to write object\n");
+			goto err;
+		}
+
+		close(fd);
+
+		dprintf("rename %s to %s\n", tmp_path, path);
+		ret = rename(tmp_path, path);
+		if (ret < 0) {
+			eprintf("failed to rename %s to %s: %m\n", tmp_path, path);
+			goto err;
+		}
+		dprintf("recovered oid %"PRIx64" to epoch %"PRIu32"\n", oid, epoch);
+		goto out;
+	}
+
+	if (rsp->result == SD_RES_NEW_NODE_VER || rsp->result == SD_RES_OLD_NODE_VER
+	    || rsp->result == SD_RES_NETWORK_ERROR) {
+		eprintf("retrying: %"PRIu32", %"PRIx64"\n", rsp->result, oid);
+		rw->retry = 1;
+		goto out;
+	}
+
+	if (rsp->result != SD_RES_NO_OBJ || rsp->data_length == 0) {
+		eprintf("%"PRIu32"\n", rsp->result);
+		goto err;
+	}
+	next_nr = rsp->data_length / sizeof(struct sheepdog_node_list_entry);
+	next_copies = get_max_copies((struct sheepdog_node_list_entry *)buf, next_nr);
+	next_nr = nodes_to_vnodes((struct sheepdog_node_list_entry *)buf,
+				  next_nr, next_entry);
+
+not_found:
+	for (copy_idx = 0; copy_idx < old_copies; copy_idx++)
+		if (get_nth_node(old_entry, old_nr, old_idx, copy_idx) == tgt_idx)
+			break;
+	if (copy_idx == old_copies) {
+		eprintf("bug: cannot find the proper copy_idx\n");
+		goto err;
+	}
+
+	dprintf("%"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32", %"PRIu32"\n", rsp->result, rsp->data_length, tgt_idx,
+		old_idx, old_nr, copy_idx);
+	memcpy(cur_entry, old_entry, sizeof(*old_entry) * old_nr);
+	cur_copies = old_copies;
+	cur_nr = old_nr;
+	cur_idx = old_idx;
+
+	memcpy(old_entry, next_entry, next_nr * sizeof(*next_entry));
+	old_copies = next_copies;
+	old_nr = next_nr;
+
+	tgt_epoch--;
+	goto next;
+out:
+	free(old_entry);
+	free(cur_entry);
+	free(next_entry);
+	return 0;
+err:
+	free(old_entry);
+	free(cur_entry);
+	free(next_entry);
+	return -1;
+}
+
+static void recover_one(struct work *work)
+{
+	struct recovery_work *rw = container_of(work, struct recovery_work, work);
+	char *buf = NULL;
+	int ret;
+	uint64_t oid = rw->oids[rw->done];
+	int old_copies, cur_copies;
+	uint32_t epoch = rw->epoch;
+	int i, copy_idx = 0, cur_idx = -1;
+	struct siocb iocb;
+
+	eprintf("%"PRIu32" %"PRIu32", %16"PRIx64"\n", rw->done, rw->count, oid);
+
+	memset(&iocb, 0, sizeof(iocb));
+	iocb.epoch = epoch;
+	ret = store.open(oid, &iocb, 0);
+	if (ret == SD_RES_SUCCESS) {
+		/* the object is already recovered */
+		store.close(oid, &iocb);
+		goto out;
+	}
+
+	if (is_vdi_obj(oid))
+		buf = malloc(sizeof(struct sheepdog_inode));
+	else if (is_vdi_attr_obj(oid))
+		buf = malloc(SD_MAX_VDI_ATTR_VALUE_LEN);
+	else if (is_data_obj(oid))
+		buf = valloc(SD_DATA_OBJ_SIZE);
+	else
+		buf = malloc(SD_DATA_OBJ_SIZE);
+
+	if (!sys->nr_sobjs)
+		goto fail;
+
+	cur_idx = obj_to_sheep(rw->cur_vnodes, rw->cur_nr_vnodes, oid, 0);
+
+	old_copies = get_max_copies(rw->old_nodes, rw->old_nr_nodes);
+	cur_copies = get_max_copies(rw->cur_nodes, rw->cur_nr_nodes);
+
+	copy_idx = -1;
+	for (i = 0; i < cur_copies; i++) {
+		int n = obj_to_sheep(rw->cur_vnodes, rw->cur_nr_vnodes, oid, i);
+		if (is_myself(rw->cur_vnodes[n].addr, rw->cur_vnodes[n].port)) {
+			copy_idx = i;
+			break;
+		}
+	}
+	if (copy_idx < 0) {
+		eprintf("bug: copy_idx < 0\n");
+		goto out;
+	}
+
+	dprintf("%"PRIu32", %"PRIu32", %"PRIu32"\n", cur_idx, rw->cur_nr_nodes,
+		copy_idx);
+
+	ret = __recover_one(rw, rw->old_vnodes, rw->old_nr_vnodes, old_copies,
+			    rw->cur_vnodes, rw->cur_nr_vnodes, cur_copies,
+			    cur_idx, copy_idx, epoch, epoch - 1, oid,
+			    buf, SD_DATA_OBJ_SIZE);
+	if (ret == 0)
+		goto out;
+
+	for (i = 0; i < cur_copies; i++) {
+		if (i == copy_idx)
+			continue;
+		ret = __recover_one(rw, rw->old_vnodes, rw->old_nr_vnodes, old_copies,
+				    rw->cur_vnodes, rw->cur_nr_vnodes, cur_copies, cur_idx, i,
+				    epoch, epoch - 1, oid, buf, SD_DATA_OBJ_SIZE);
+		if (ret == 0)
+			goto out;
+	}
+fail:
+	eprintf("failed to recover object %"PRIx64"\n", oid);
+out:
+	free(buf);
+}
+
+static struct recovery_work *suspended_recovery_work;
+
+static void recover_timer(void *data)
+{
+	struct recovery_work *rw = (struct recovery_work *)data;
+	uint64_t oid = rw->oids[rw->done];
+
+	if (is_access_to_busy_objects(oid)) {
+		suspended_recovery_work = rw;
+		return;
+	}
+
+	queue_work(sys->recovery_wqueue, &rw->work);
+}
+
+void resume_recovery_work(void)
+{
+	struct recovery_work *rw;
+	uint64_t oid;
+
+	if (!suspended_recovery_work)
+		return;
+
+	rw = suspended_recovery_work;
+
+	oid =  rw->oids[rw->done];
+	if (is_access_to_busy_objects(oid))
+		return;
+
+	suspended_recovery_work = NULL;
+	queue_work(sys->recovery_wqueue, &rw->work);
+}
+
+int is_recoverying_oid(uint64_t oid)
+{
+	uint64_t hval = fnv_64a_buf(&oid, sizeof(uint64_t), FNV1A_64_INIT);
+	uint64_t min_hval;
+	struct recovery_work *rw = recovering_work;
+	int ret, i;
+	struct siocb iocb;
+
+	if (oid == 0)
+		return 0;
+
+	if (!rw)
+		return 0; /* there is no thread working for object recovery */
+
+	min_hval = fnv_64a_buf(&rw->oids[rw->done + rw->nr_blocking], sizeof(uint64_t), FNV1A_64_INIT);
+
+	if (before(rw->epoch, sys->epoch))
+		return 1;
+
+	if (rw->state == RW_INIT)
+		return 1;
+
+	memset(&iocb, 0, sizeof(iocb));
+	iocb.epoch = sys->epoch;
+	ret = store.open(oid, &iocb, 0);
+	if (ret == SD_RES_SUCCESS) {
+		dprintf("the object %" PRIx64 " is already recoverd\n", oid);
+		store.close(oid, &iocb);
+		return 0;
+	}
+
+	/* the first 'rw->nr_blocking' objects were already scheduled to be done earlier */
+	for (i = 0; i < rw->nr_blocking; i++)
+		if (rw->oids[rw->done + i] == oid)
+			return 1;
+
+	if (min_hval <= hval) {
+		uint64_t *p;
+		p = bsearch(&oid, rw->oids + rw->done + rw->nr_blocking,
+			    rw->count - rw->done - rw->nr_blocking, sizeof(oid), obj_cmp);
+		if (p) {
+			dprintf("recover the object %" PRIx64 " first\n", oid);
+			if (rw->nr_blocking == 0)
+				rw->nr_blocking = 1; /* the first oid may be processed now */
+			if (p > rw->oids + rw->done + rw->nr_blocking) {
+				/* this object should be recovered earlier */
+				memmove(rw->oids + rw->done + rw->nr_blocking + 1,
+					rw->oids + rw->done + rw->nr_blocking,
+					sizeof(uint64_t) * (p - (rw->oids + rw->done + rw->nr_blocking)));
+				rw->oids[rw->done + rw->nr_blocking] = oid;
+				rw->nr_blocking++;
+			}
+			return 1;
+		}
+	}
+
+	dprintf("the object %" PRIx64 " is not found\n", oid);
+	return 0;
+}
+
+static void recover_done(struct work *work)
+{
+	struct recovery_work *rw = container_of(work, struct recovery_work, work);
+	uint64_t oid;
+
+	if (rw->state == RW_INIT)
+		rw->state = RW_RUN;
+	else if (!rw->retry) {
+		rw->done++;
+		if (rw->nr_blocking > 0)
+			rw->nr_blocking--;
+	}
+
+	oid = rw->oids[rw->done];
+
+	if (rw->retry && !next_rw) {
+		rw->retry = 0;
+
+		rw->timer.callback = recover_timer;
+		rw->timer.data = rw;
+		add_timer(&rw->timer, 2);
+		return;
+	}
+
+	if (rw->done < rw->count && !next_rw) {
+		rw->work.fn = recover_one;
+
+		if (is_access_to_busy_objects(oid)) {
+			suspended_recovery_work = rw;
+			return;
+		}
+		resume_pending_requests();
+		queue_work(sys->recovery_wqueue, &rw->work);
+		return;
+	}
+
+	dprintf("recovery complete: new epoch %"PRIu32"\n", rw->epoch);
+	recovering_work = NULL;
+
+	sys->recovered_epoch = rw->epoch;
+
+	free(rw->oids);
+	free(rw);
+
+	if (next_rw) {
+		rw = next_rw;
+		next_rw = NULL;
+
+		recovering_work = rw;
+		queue_work(sys->recovery_wqueue, &rw->work);
+	}
+
+	resume_pending_requests();
+}
+
+static int __fill_obj_list(struct sheepdog_node_list_entry *e, uint32_t epoch,
+			   uint8_t *buf, size_t buf_size)
+{
+	int fd, ret;
+	unsigned wlen, rlen;
+	char name[128];
+	struct sd_list_req hdr;
+	struct sd_list_rsp *rsp;
+
+	addr_to_str(name, sizeof(name), e->addr, 0);
+
+	dprintf("%s %"PRIu32"\n", name, e->port);
+
+	fd = connect_to(name, e->port);
+	if (fd < 0) {
+		eprintf("%s %"PRIu32"\n", name, e->port);
+		return -1;
+	}
+
+	wlen = 0;
+	rlen = buf_size;
+
+	memset(&hdr, 0, sizeof(hdr));
+	hdr.opcode = SD_OP_GET_OBJ_LIST;
+	hdr.tgt_epoch = epoch - 1;
+	hdr.flags = 0;
+	hdr.data_length = rlen;
+
+	ret = exec_req(fd, (struct sd_req *)&hdr, buf, &wlen, &rlen);
+
+	close(fd);
+
+	rsp = (struct sd_list_rsp *)&hdr;
+
+	if (ret || rsp->result != SD_RES_SUCCESS) {
+		eprintf("retrying: %"PRIu32", %"PRIu32"\n", ret, rsp->result);
+		return -1;
+	}
+
+	dprintf("%lu\n", rsp->data_length / sizeof(uint64_t));
+
+	return rsp->data_length / sizeof(uint64_t);
+}
+
+static int merge_objlist(uint64_t *list1, int nr_list1, uint64_t *list2, int nr_list2)
+{
+	int i;
+	int old_nr_list1 = nr_list1;
+
+	for (i = 0; i < nr_list2; i++) {
+		if (bsearch(list2 + i, list1, old_nr_list1, sizeof(*list1), obj_cmp))
+			continue;
+
+		list1[nr_list1++] = list2[i];
+	}
+
+	qsort(list1, nr_list1, sizeof(*list1), obj_cmp);
+
+	return nr_list1;
+}
+
+static int screen_obj_list(struct sheepdog_vnode_list_entry *nodes, int nodes_nr,
+			   uint64_t *list, int list_nr, int nr_objs)
+{
+	int ret, i, cp, idx;
+	struct strbuf buf = STRBUF_INIT;
+
+	for (i = 0; i < list_nr; i++) {
+		for (cp = 0; cp < nr_objs; cp++) {
+			idx = obj_to_sheep(nodes, nodes_nr, list[i], cp);
+			if (is_myself(nodes[idx].addr, nodes[idx].port))
+				break;
+		}
+		if (cp == nr_objs)
+			continue;
+		strbuf_add(&buf, &list[i], sizeof(uint64_t));
+	}
+	memcpy(list, buf.buf, buf.len);
+
+	ret = buf.len / sizeof(uint64_t);
+	dprintf("%d\n", ret);
+	strbuf_release(&buf);
+
+	return ret;
+}
+
+#define MAX_RETRY_CNT  6
+
+static int fill_obj_list(struct recovery_work *rw,
+			 struct sheepdog_node_list_entry *old_entry, int old_nr,
+			 struct sheepdog_node_list_entry *cur_entry, int cur_nr,
+			 int nr_objs)
+{
+	int i, j;
+	uint8_t *buf = NULL;
+	size_t buf_size = SD_DATA_OBJ_SIZE; /* FIXME */
+	int retry_cnt;
+
+	buf = malloc(buf_size);
+	if (!buf)
+		goto fail;
+
+	for (i = 0; i < cur_nr; i++) {
+		int nr;
+
+		for (j = 0; j < old_nr; j++)
+			if (node_cmp(cur_entry + i, old_entry + j) == 0)
+				break;
+
+		if (j == old_nr)
+			/* cur_entry[i] doesn't have a list file */
+			continue;
+
+		retry_cnt = 0;
+	retry:
+		nr  = __fill_obj_list(cur_entry + i, rw->epoch, buf, buf_size);
+		if (nr < 0) {
+			retry_cnt++;
+			if (retry_cnt > MAX_RETRY_CNT) {
+				eprintf("failed to get object list\n");
+				eprintf("some objects may be lost\n");
+				continue;
+			} else {
+				if (next_rw) {
+					dprintf("go to the next recovery\n");
+					break;
+				}
+				dprintf("trying to get object list again\n");
+				sleep(1);
+				goto retry;
+			}
+		}
+		nr = screen_obj_list(rw->cur_vnodes, rw->cur_nr_vnodes, (uint64_t *)buf,
+				     nr, nr_objs);
+		if (nr)
+			rw->count = merge_objlist(rw->oids, rw->count, (uint64_t *)buf, nr);
+	}
+
+	dprintf("%d\n", rw->count);
+	free(buf);
+	return 0;
+fail:
+	free(buf);
+	rw->retry = 1;
+	return -1;
+}
+
+static void __start_recovery(struct work *work)
+{
+	struct recovery_work *rw = container_of(work, struct recovery_work, work);
+	uint32_t epoch = rw->epoch;
+	int nr_objs;
+
+	dprintf("%u\n", epoch);
+
+	if (rw->cur_nr_nodes == 0) {
+		/* setup node list and virtual node list */
+		rw->cur_nr_nodes = epoch_log_read(epoch, (char *)rw->cur_nodes,
+						  sizeof(rw->cur_nodes));
+		if (rw->cur_nr_nodes <= 0) {
+			eprintf("failed to read epoch log for epoch %"PRIu32"\n", epoch);
+			goto fail;
+		}
+		rw->cur_nr_nodes /= sizeof(struct sheepdog_node_list_entry);
+
+		rw->old_nr_nodes = epoch_log_read(epoch - 1, (char *)rw->old_nodes,
+						  sizeof(rw->old_nodes));
+		if (rw->old_nr_nodes <= 0) {
+			eprintf("failed to read epoch log for epoch %"PRIu32"\n", epoch - 1);
+			goto fail;
+		}
+		rw->old_nr_nodes /= sizeof(struct sheepdog_node_list_entry);
+
+		rw->old_nr_vnodes = nodes_to_vnodes(rw->old_nodes, rw->old_nr_nodes,
+						    rw->old_vnodes);
+		rw->cur_nr_vnodes = nodes_to_vnodes(rw->cur_nodes, rw->cur_nr_nodes,
+						    rw->cur_vnodes);
+	}
 
-	jrnl_end(jd);
-err:
-	close(fd);
-	return ret;
+	if (!sys->nr_sobjs)
+		goto fail;
+	nr_objs = get_max_copies(rw->cur_nodes, rw->cur_nr_nodes);
+
+	if (fill_obj_list(rw, rw->old_nodes, rw->old_nr_nodes, rw->cur_nodes,
+			  rw->cur_nr_nodes, nr_objs) != 0) {
+		eprintf("fatal recovery error\n");
+		goto fail;
+	}
+
+	return;
+fail:
+	rw->count = 0;
+	return;
 }
 
-uint64_t get_cluster_ctime(void)
+int start_recovery(uint32_t epoch)
 {
-	int fd, ret;
-	uint64_t ct;
+	struct recovery_work *rw;
 
-	fd = open(config_path, O_RDONLY);
-	if (fd < 0)
-		return 0;
+	rw = zalloc(sizeof(struct recovery_work));
+	if (!rw)
+		return -1;
 
-	ret = xpread(fd, &ct, sizeof(ct),
-		     offsetof(struct sheepdog_config, ctime));
-	close(fd);
+	rw->state = RW_INIT;
+	rw->oids = malloc(1 << 20); /* FIXME */
+	rw->epoch = epoch;
+	rw->count = 0;
+
+	rw->work.fn = __start_recovery;
+	rw->work.done = recover_done;
+
+	if (recovering_work != NULL) {
+		if (next_rw) {
+			/* skip the previous epoch recovery */
+			free(next_rw->oids);
+			free(next_rw);
+		}
+		next_rw = rw;
+	} else {
+		recovering_work = rw;
+		queue_work(sys->recovery_wqueue, &rw->work);
+	}
 
-	if (ret != sizeof(ct))
-		return 0;
-	return ct;
+	return 0;
 }
 
 static int init_path(const char *d, int *new)
@@ -678,16 +1831,7 @@ int init_base_path(const char *d)
 
 static int init_obj_path(const char *base_path)
 {
-	int new, len;
-
-	len = strlen(base_path);
-	/* farm needs extra HEX_LEN + 3 chars to store snapshot objects.
-	 * HEX_LEN + 3 = '/' + hex(2) + '/' + hex(38) + '\0'
-	 */
-	if (len + HEX_LEN + 3 > PATH_MAX) {
-		eprintf("insanely long object directory %s", base_path);
-		return -1;
-	}
+	int new;
 
 	obj_path = zalloc(strlen(base_path) + strlen(OBJ_PATH) + 1);
 	sprintf(obj_path, "%s" OBJ_PATH, base_path);
@@ -699,12 +1843,54 @@ static int init_obj_path(const char *bas
 
 static int init_epoch_path(const char *base_path)
 {
-	int new;
+	int new, ret;
+	uint32_t epoch, latest_epoch;
+	DIR *dir;
+	char path[1024];
+	struct dirent *dent;
+	uint64_t oid;
 
 	epoch_path = zalloc(strlen(base_path) + strlen(EPOCH_PATH) + 1);
 	sprintf(epoch_path, "%s" EPOCH_PATH, base_path);
 
-	return init_path(epoch_path, &new);
+	ret = init_path(epoch_path, &new);
+	if (new || ret)
+		return ret;
+
+	latest_epoch = get_latest_epoch();
+
+	for (epoch = 1; epoch <= latest_epoch; epoch++) {
+		snprintf(path, sizeof(path), "%s/%08u", obj_path, epoch);
+
+		vprintf(SDOG_INFO, "found the object directory %s\n", path);
+
+		dir = opendir(path);
+		if (!dir) {
+			if (errno == ENOENT)
+				continue;
+
+			vprintf(SDOG_ERR, "failed to open the epoch directory: %m\n");
+			return SD_RES_EIO;
+		}
+
+		while ((dent = readdir(dir))) {
+			if (!strcmp(dent->d_name, ".") ||
+			    !strcmp(dent->d_name, ".."))
+				continue;
+
+			oid = strtoull(dent->d_name, NULL, 16);
+
+			if (!is_vdi_obj(oid))
+				continue;
+
+			vprintf(SDOG_DEBUG, "found the VDI object %" PRIx64 "\n", oid);
+
+			set_bit(oid_to_vid(oid), sys->vdi_inuse);
+		}
+		closedir(dir);
+	}
+
+	return 0;
 }
 
 static int init_mnt_path(const char *base_path)
@@ -774,42 +1960,6 @@ static int init_config_path(const char *
 	return 0;
 }
 
-static int init_store_driver(void)
-{
-	char driver_name[STORE_LEN], *p;
-	int ret;
-
-	memset(driver_name, '\0', sizeof(driver_name));
-	ret = get_cluster_store(driver_name);
-	if (ret != SD_RES_SUCCESS)
-		return ret;
-
-	p = memchr(driver_name, '\0', STORE_LEN);
-	if (!p) {
-		/*
-		 * If the driver name is not NUL terminated we are in deep
-		 * trouble, let's get out here.
-		 */
-		dprintf("store name not NUL terminated\n");
-		return SD_RES_NO_STORE;
-	}
-
-	/*
-	 * The store file might not exist in case this is a new sheep that
-	 * never joined a cluster before.
-	 */
-	if (p == driver_name)
-		return 0;
-
-	sd_store = find_store_driver(driver_name);
-	if (!sd_store) {
-		dprintf("store %s not found\n", driver_name);
-		return SD_RES_NO_STORE;
-	}
-
-	return sd_store->init(obj_path);
-}
-
 int init_store(const char *d)
 {
 	int ret;
@@ -834,22 +1984,15 @@ int init_store(const char *d)
 	if (ret)
 		return ret;
 
-	ret = init_store_driver();
-	if (ret)
-		return ret;
-
-	ret = init_objlist_cache();
+	ret = store.init(obj_path);
 	if (ret)
 		return ret;
 
-	ret = object_cache_init(d);
-	if (ret)
-		return 1;
 	return ret;
 }
 
 int read_epoch(uint32_t *epoch, uint64_t *ct,
-	       struct sd_node *entries, int *nr_entries)
+	       struct sheepdog_node_list_entry *entries, int *nr_entries)
 {
 	int ret;
 
@@ -868,236 +2011,6 @@ int read_epoch(uint32_t *epoch, uint64_t
 	return SD_RES_SUCCESS;
 }
 
-static int write_object_local(uint64_t oid, char *data, unsigned int datalen,
-			      uint64_t offset, uint16_t flags, int copies,
-			      uint32_t epoch, int create)
-{
-	int ret;
-	struct request *req;
-	struct sd_obj_req *hdr;
-
-	req = zalloc(sizeof(*req));
-	if (!req)
-		return SD_RES_NO_MEM;
-	hdr = (struct sd_obj_req *)&req->rq;
-
-	hdr->oid = oid;
-	if (create)
-		hdr->opcode = SD_OP_CREATE_AND_WRITE_OBJ;
-	else
-		hdr->opcode = SD_OP_WRITE_OBJ;
-	hdr->copies = copies;
-	hdr->flags = flags | SD_FLAG_CMD_WRITE;
-	hdr->offset = offset;
-	hdr->data_length = datalen;
-	req->data = data;
-	req->op = get_sd_op(hdr->opcode);
-
-	ret = do_local_io(req, epoch);
-
-	free(req);
-
-	return ret;
-}
-int write_object(struct vnode_info *vnodes, uint32_t node_version,
-		 uint64_t oid, char *data, unsigned int datalen,
-		 uint64_t offset, uint16_t flags, int nr_copies, int create)
-{
-	struct sd_obj_req hdr;
-	struct sd_vnode *v;
-	int i, fd, ret;
-	char name[128];
-
-	for (i = 0; i < nr_copies; i++) {
-		unsigned rlen = 0, wlen = datalen;
-
-		v = oid_to_vnode(vnodes, oid, i);
-		if (vnode_is_local(v)) {
-			ret = write_object_local(oid, data, datalen, offset,
-						 flags, nr_copies, node_version,
-						 create);
-
-			if (ret != 0) {
-				eprintf("fail %"PRIx64" %"PRIx32"\n", oid, ret);
-				return -1;
-			}
-
-			continue;
-		}
-
-		addr_to_str(name, sizeof(name), v->addr, 0);
-
-		fd = connect_to(name, v->port);
-		if (fd < 0) {
-			eprintf("failed to connect to host %s\n", name);
-			return -1;
-		}
-
-		memset(&hdr, 0, sizeof(hdr));
-		hdr.epoch = node_version;
-		if (create)
-			hdr.opcode = SD_OP_CREATE_AND_WRITE_OBJ;
-		else
-			hdr.opcode = SD_OP_WRITE_OBJ;
-
-		hdr.oid = oid;
-		hdr.copies = nr_copies;
-
-		hdr.flags = flags;
-		hdr.flags |= SD_FLAG_CMD_WRITE | SD_FLAG_CMD_IO_LOCAL;
-		hdr.data_length = wlen;
-		hdr.offset = offset;
-
-		ret = exec_req(fd, (struct sd_req *)&hdr, data, &wlen, &rlen);
-		close(fd);
-		if (ret) {
-			eprintf("failed to update host %s\n", name);
-			return -1;
-		}
-	}
-
-	return 0;
-}
-
-static int read_object_local(uint64_t oid, char *data, unsigned int datalen,
-			     uint64_t offset, int copies, uint32_t epoch)
-{
-	int ret;
-	struct request *req;
-	struct sd_obj_req *hdr;
-
-	req = zalloc(sizeof(*req));
-	if (!req)
-		return SD_RES_NO_MEM;
-	hdr = (struct sd_obj_req *)&req->rq;
-
-	hdr->oid = oid;
-	hdr->opcode = SD_OP_READ_OBJ;
-	hdr->copies = copies;
-	hdr->flags = 0;
-	hdr->offset = offset;
-	hdr->data_length = datalen;
-	req->data = data;
-	req->op = get_sd_op(hdr->opcode);
-
-	ret = do_local_io(req, epoch);
-
-	free(req);
-	return ret;
-}
-int read_object(struct vnode_info *vnodes, uint32_t node_version,
-		uint64_t oid, char *data, unsigned int datalen,
-		uint64_t offset, int nr_copies)
-{
-	struct sd_obj_req hdr;
-	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
-	struct sd_vnode *v;
-	char name[128];
-	int i = 0, fd, ret, last_error = SD_RES_SUCCESS;
-
-	/* search a local object first */
-	for (i = 0; i < nr_copies; i++) {
-		v = oid_to_vnode(vnodes, oid, i);
-		if (vnode_is_local(v)) {
-			ret = read_object_local(oid, data, datalen, offset,
-						nr_copies, node_version);
-
-			if (ret != SD_RES_SUCCESS) {
-				eprintf("fail %"PRIx64" %"PRId32"\n", oid, ret);
-				return ret;
-			}
-
-			return SD_RES_SUCCESS;
-		}
-
-	}
-
-	for (i = 0; i < nr_copies; i++) {
-		unsigned wlen = 0, rlen = datalen;
-
-		v = oid_to_vnode(vnodes, oid, i);
-
-		addr_to_str(name, sizeof(name), v->addr, 0);
-
-		fd = connect_to(name, v->port);
-		if (fd < 0) {
-			printf("%s(%d): %s, %m\n", __func__, __LINE__,
-			       name);
-			return SD_RES_EIO;
-		}
-
-		memset(&hdr, 0, sizeof(hdr));
-		hdr.epoch = node_version;
-		hdr.opcode = SD_OP_READ_OBJ;
-		hdr.oid = oid;
-
-		hdr.flags =  SD_FLAG_CMD_IO_LOCAL;
-		hdr.data_length = rlen;
-		hdr.offset = offset;
-
-		ret = exec_req(fd, (struct sd_req *)&hdr, data, &wlen, &rlen);
-		close(fd);
-
-		if (ret) {
-			last_error = SD_RES_EIO;
-			continue;
-		}
-
-		if (rsp->result == SD_RES_SUCCESS)
-			return SD_RES_SUCCESS;
-
-		last_error = rsp->result;
-	}
-
-	return last_error;
-}
-
-int remove_object(struct vnode_info *vnodes, uint32_t node_version,
-		  uint64_t oid, int nr)
-{
-	char name[128];
-	struct sd_obj_req hdr;
-	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
-	struct sd_vnode *v;
-	int i = 0, fd, ret, err = 0;
-
-	for (i = 0; i < nr; i++) {
-		unsigned wlen = 0, rlen = 0;
-
-		v = oid_to_vnode(vnodes, oid, i);
-
-		addr_to_str(name, sizeof(name), v->addr, 0);
-
-		fd = connect_to(name, v->port);
-		if (fd < 0) {
-			rsp->result = SD_RES_EIO;
-			return -1;
-		}
-
-		memset(&hdr, 0, sizeof(hdr));
-		hdr.epoch = node_version;
-		hdr.opcode = SD_OP_REMOVE_OBJ;
-		hdr.oid = oid;
-
-		hdr.flags = 0;
-		hdr.data_length = rlen;
-
-		ret = exec_req(fd, (struct sd_req *)&hdr, NULL, &wlen, &rlen);
-		close(fd);
-
-		if (ret)
-			return -1;
-
-		if (rsp->result != SD_RES_SUCCESS)
-			err = 1;
-	}
-
-	if (err)
-		return -1;
-
-	return 0;
-}
-
 int set_cluster_copies(uint8_t copies)
 {
 	int fd, ret;
@@ -1186,58 +2099,6 @@ int get_cluster_flags(uint16_t *flags)
 		ret = SD_RES_EIO;
 	else
 		ret = SD_RES_SUCCESS;
-
-	close(fd);
-out:
-	return ret;
-}
-
-int set_cluster_store(const char *name)
-{
-	int fd, ret = SD_RES_EIO, len;
-	void *jd;
-
-	fd = open(config_path, O_DSYNC | O_WRONLY);
-	if (fd < 0)
-		goto out;
-
-	len = strlen(name) + 1;
-	if (len > STORE_LEN)
-		goto err;
-	jd = jrnl_begin(name, len,
-			offsetof(struct sheepdog_config, store),
-			config_path, jrnl_path);
-	if (!jd) {
-		ret = SD_RES_EIO;
-		goto err;
-	}
-	ret = xpwrite(fd, name, len, offsetof(struct sheepdog_config, store));
-	if (ret != len)
-		ret = SD_RES_EIO;
-	else
-		ret = SD_RES_SUCCESS;
-	jrnl_end(jd);
-err:
-	close(fd);
-out:
-	return ret;
-}
-
-int get_cluster_store(char *buf)
-{
-	int fd, ret = SD_RES_EIO;
-
-	fd = open(config_path, O_RDONLY);
-	if (fd < 0)
-		goto out;
-
-	ret = pread(fd, buf, STORE_LEN,
-		    offsetof(struct sheepdog_config, store));
-
-	if (ret == -1)
-		ret = SD_RES_EIO;
-	else
-		ret = SD_RES_SUCCESS;
 
 	close(fd);
 out:
--- sheepdog-0.3.0.orig/sheep/work.c
+++ sheepdog-0.3.0/sheep/work.c
@@ -32,14 +32,40 @@
 #include "event.h"
 
 static int efd;
-int total_nr_workers;
-LIST_HEAD(worker_info_list);
+static LIST_HEAD(worker_info_list);
+
+struct work_queue {
+	int wq_state;
+	int nr_active;
+	struct list_head pending_list;
+	struct list_head blocked_list;
+};
 
 enum wq_state {
 	WQ_BLOCKED = (1U << 0),
 	WQ_DEAD = (1U << 1),
 };
 
+struct worker_info {
+	struct list_head worker_info_siblings;
+
+	int nr_threads;
+
+	pthread_mutex_t finished_lock;
+	struct list_head finished_list;
+
+	/* wokers sleep on this and signaled by tgtd */
+	pthread_cond_t pending_cond;
+	/* locked by tgtd and workers */
+	pthread_mutex_t pending_lock;
+	/* protected by pending_lock */
+	struct work_queue q;
+
+	pthread_mutex_t startup_lock;
+
+	pthread_t worker_thread[0];
+};
+
 static void work_queue_set_blocked(struct work_queue *q)
 {
 	q->wq_state |= WQ_BLOCKED;
@@ -218,11 +244,6 @@ static int init_eventfd(void)
 	}
 
 	ret = register_event(efd, bs_thread_request_done, NULL);
-	if (ret) {
-		eprintf("failed to register event fd %m\n");
-		close(efd);
-		return 1;
-	}
 
 	return 0;
 }
@@ -268,7 +289,6 @@ struct work_queue *init_work_queue(int n
 
 	list_add(&wi->worker_info_siblings, &worker_info_list);
 
-	total_nr_workers += nr;
 	return &wi->q;
 destroy_threads:
 
--- sheepdog-0.3.0.orig/sheep/sdnet.c
+++ sheepdog-0.3.0/sheep/sdnet.c
@@ -8,7 +8,6 @@
  * You should have received a copy of the GNU General Public License
  * along with this program. If not, see <http://www.gnu.org/licenses/>.
  */
-#include <assert.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <unistd.h>
@@ -26,27 +25,31 @@ void resume_pending_requests(void)
 
 	list_for_each_entry_safe(next, tmp, &sys->req_wait_for_obj_list,
 				 r_wlist) {
-		struct event_struct *cevent = &next->cev;
+		struct cpg_event *cevent = &next->cev;
 
 		list_del(&next->r_wlist);
-		list_add_tail(&cevent->event_list, &sys->request_queue);
+		list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
 	}
 
-	if (!list_empty(&sys->request_queue))
-		process_request_event_queues();
+	if (!list_empty(&sys->cpg_event_siblings))
+		start_cpg_event_work();
 }
 
-static int is_access_local(struct request *req, uint64_t oid)
+int is_access_local(struct sheepdog_vnode_list_entry *e, int nr_nodes,
+		    uint64_t oid, int copies)
 {
-	struct sd_vnode *v;
-	int nr_copies;
-	int i;
+	int i, n;
 
-	nr_copies = get_nr_copies(req->vnodes);
+	if (oid == 0)
+		return 0;
+
+	if (copies > nr_nodes)
+		copies = nr_nodes;
+
+	for (i = 0; i < copies; i++) {
+		n = obj_to_sheep(e, nr_nodes, oid, i);
 
-	for (i = 0; i < nr_copies; i++) {
-		v = oid_to_vnode(req->vnodes, oid, i);
-		if (vnode_is_local(v))
+		if (is_myself(e[n].addr, e[n].port))
 			return 1;
 	}
 
@@ -56,107 +59,112 @@ static int is_access_local(struct reques
 static void setup_access_to_local_objects(struct request *req)
 {
 	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+	int copies;
 
 	if (hdr->flags & SD_FLAG_CMD_IO_LOCAL) {
 		req->local_oid = hdr->oid;
 		return;
 	}
 
-	if (is_access_local(req, hdr->oid))
-		req->local_oid = hdr->oid;
-
-	if (hdr->cow_oid)
-		if (is_access_local(req, hdr->cow_oid))
-			req->local_cow_oid = hdr->cow_oid;
-}
-
-static void check_object_consistency(struct sd_obj_req *hdr)
-{
-	uint32_t vdi_id = oid_to_vid(hdr->oid);
-	struct data_object_bmap *bmap, *n;
-	int nr_bmaps = 0;
-
-	list_for_each_entry_safe(bmap, n, &sys->consistent_obj_list, list) {
-		nr_bmaps++;
-		if (bmap->vdi_id == vdi_id) {
-			set_bit(data_oid_to_idx(hdr->oid), bmap->dobjs);
-			list_del(&bmap->list);
-			list_add_tail(&bmap->list, &sys->consistent_obj_list);
-			return;
-		}
-	}
-
-	bmap = zalloc(sizeof(*bmap));
-	if (bmap == NULL) {
-		eprintf("failed to allocate memory\n");
-		return;
-	}
-
-	dprintf("allocating a new object map\n");
+	copies = hdr->copies;
+	if (!copies)
+		copies = sys->nr_sobjs;
+	if (copies > req->nr_zones)
+		copies = req->nr_zones;
 
-	bmap->vdi_id = vdi_id;
-	list_add_tail(&bmap->list, &sys->consistent_obj_list);
-	set_bit(data_oid_to_idx(hdr->oid), bmap->dobjs);
-	if (nr_bmaps >= MAX_DATA_OBJECT_BMAPS) {
-		/* the first entry is the least recently used one */
-		bmap = list_first_entry(&sys->consistent_obj_list,
-					struct data_object_bmap, list);
-		list_del(&bmap->list);
-		free(bmap);
-	}
+	if (is_access_local(req->entry, req->nr_vnodes, hdr->oid, copies))
+		req->local_oid = hdr->oid;
 }
 
 static void io_op_done(struct work *work)
 {
 	struct request *req = container_of(work, struct request, work);
-	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+	struct cpg_event *cevent = &req->cev;
+	int again = 0;
+	int copies = sys->nr_sobjs;
+
+	if (copies > req->nr_zones)
+		copies = req->nr_zones;
 
 	list_del(&req->r_wlist);
+
 	sys->nr_outstanding_io--;
+	/*
+	 * TODO: if the request failed due to epoch unmatch,
+	 * we should retry here (adds this request to the tail
+	 * of sys->cpg_event_siblings.
+	 */
+	if (!(req->rq.flags & SD_FLAG_CMD_IO_LOCAL) &&
+	    (req->rp.result == SD_RES_OLD_NODE_VER ||
+	     req->rp.result == SD_RES_NEW_NODE_VER ||
+	     req->rp.result == SD_RES_NETWORK_ERROR ||
+	     req->rp.result == SD_RES_WAIT_FOR_JOIN ||
+	     req->rp.result == SD_RES_WAIT_FOR_FORMAT)) {
 
-	switch (req->rp.result) {
-	case SD_RES_OLD_NODE_VER:
-	case SD_RES_NEW_NODE_VER:
-	case SD_RES_NETWORK_ERROR:
-	case SD_RES_WAIT_FOR_JOIN:
-	case SD_RES_WAIT_FOR_FORMAT:
-		if (!(req->rq.flags & SD_FLAG_CMD_IO_LOCAL))
-			goto retry;
-		break;
-	case SD_RES_EIO:
-		if (is_access_local(req, hdr->oid)) {
-			eprintf("leaving sheepdog cluster\n");
-			leave_cluster();
+		req->rq.epoch = sys->epoch;
+		setup_ordered_sd_vnode_list(req);
+		setup_access_to_local_objects(req);
 
-			if (!(req->rq.flags & SD_FLAG_CMD_IO_LOCAL))
-				goto retry;
+		list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
+		again = 1;
+	} else if (req->rp.result == SD_RES_SUCCESS && req->check_consistency) {
+		struct sd_obj_req *obj_hdr = (struct sd_obj_req *)&req->rq;
+		uint32_t vdi_id = oid_to_vid(obj_hdr->oid);
+		struct data_object_bmap *bmap, *n;
+		int nr_bmaps = 0;
 
+		if (!is_data_obj(obj_hdr->oid))
+			goto done;
+
+		list_for_each_entry_safe(bmap, n, &sys->consistent_obj_list, list) {
+			nr_bmaps++;
+			if (bmap->vdi_id == vdi_id) {
+				set_bit(data_oid_to_idx(obj_hdr->oid), bmap->dobjs);
+				list_del(&bmap->list);
+				list_add_tail(&bmap->list, &sys->consistent_obj_list);
+				goto done;
+			}
+		}
+		bmap = zalloc(sizeof(*bmap));
+		if (bmap == NULL) {
+			eprintf("failed to allocate memory\n");
+			goto done;
+		}
+		dprintf("allocating a new object map\n");
+		bmap->vdi_id = vdi_id;
+		list_add_tail(&bmap->list, &sys->consistent_obj_list);
+		set_bit(data_oid_to_idx(obj_hdr->oid), bmap->dobjs);
+		if (nr_bmaps >= MAX_DATA_OBJECT_BMAPS) {
+			/* the first entry is the least recently used one */
+			bmap = list_first_entry(&sys->consistent_obj_list,
+						struct data_object_bmap, list);
+			list_del(&bmap->list);
+			free(bmap);
+		}
+	} else if (is_access_local(req->entry, req->nr_vnodes,
+				   ((struct sd_obj_req *)&req->rq)->oid, copies) &&
+		   req->rp.result == SD_RES_EIO) {
+		eprintf("leaving sheepdog cluster\n");
+		leave_cluster();
+
+		if (req->rq.flags & SD_FLAG_CMD_IO_LOCAL)
 			/* hack to retry */
 			req->rp.result = SD_RES_NETWORK_ERROR;
+		else {
+			req->rq.epoch = sys->epoch;
+			setup_ordered_sd_vnode_list(req);
+			setup_access_to_local_objects(req);
+
+			list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
+			again = 1;
 		}
-		break;
-	case SD_RES_SUCCESS:
-		if (req->check_consistency && is_data_obj(hdr->oid))
-			check_object_consistency(hdr);
-		break;
 	}
-
+done:
 	resume_pending_requests();
 	resume_recovery_work();
 
-	req->done(req);
-	return;
-
-retry:
-	req->rq.epoch = sys->epoch;
-
-	put_vnode_info(req->vnodes);
-	req->vnodes = get_vnode_info();
-	setup_access_to_local_objects(req);
-	list_add_tail(&req->cev.event_list, &sys->request_queue);
-
-	resume_pending_requests();
-	resume_recovery_work();
+	if (!again)
+		req->done(req);
 }
 
 static void local_op_done(struct work *work)
@@ -188,76 +196,9 @@ static void do_local_request(struct work
 	rsp->result = ret;
 }
 
-static int check_epoch(struct request *req)
-{
-	uint32_t req_epoch = req->rq.epoch;
-	uint32_t opcode = req->rq.opcode;
-	int ret = SD_RES_SUCCESS;
-
-	if (before(req_epoch, sys->epoch)) {
-		ret = SD_RES_OLD_NODE_VER;
-		eprintf("old node version %u, %u, %x\n",
-				sys->epoch, req_epoch, opcode);
-	} else if (after(req_epoch, sys->epoch)) {
-		ret = SD_RES_NEW_NODE_VER;
-		eprintf("new node version %u, %u, %x\n",
-				sys->epoch, req_epoch, opcode);
-	}
-	return ret;
-}
-
-static int check_request(struct request *req)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
-
-	/*
-	 * if we go for a cached object, we don't care if it is busy
-	 * or being recovered.
-	 */
-	if ((hdr->flags & SD_FLAG_CMD_CACHE) && object_is_cached(hdr->oid))
-		return 0;
-
-	if (!req->local_oid && !req->local_cow_oid)
-		return 0;
-	else {
-		int ret = check_epoch(req);
-		if (ret != SD_RES_SUCCESS) {
-			req->rp.result = ret;
-			sys->nr_outstanding_io++;
-			req->work.done(&req->work);
-			return -1;
-		}
-	}
-
-	if (!req->local_oid)
-		return 0;
-
-	if (is_recoverying_oid(req->local_oid)) {
-		if (req->rq.flags & SD_FLAG_CMD_IO_LOCAL) {
-			/* Sheep peer request */
-			req->rp.result = SD_RES_NEW_NODE_VER;
-			sys->nr_outstanding_io++;
-			req->work.done(&req->work);
-		} else {
-			/* Gateway request */
-			list_del(&req->r_wlist);
-			list_add_tail(&req->r_wlist, &sys->req_wait_for_obj_list);
-		}
-		return -1;
-	}
-
-	if (is_access_to_busy_objects(req->local_oid)) {
-		list_del(&req->r_wlist);
-		list_add_tail(&req->r_wlist, &sys->req_wait_for_obj_list);
-		return -1;
-	}
-
-	return 0;
-}
-
 static void queue_request(struct request *req)
 {
-	struct event_struct *cevent = &req->cev;
+	struct cpg_event *cevent = &req->cev;
 	struct sd_req *hdr = (struct sd_req *)&req->rq;
 	struct sd_rsp *rsp = (struct sd_rsp *)&req->rp;
 
@@ -287,38 +228,13 @@ static void queue_request(struct request
 			goto done;
 		}
 		break;
-	case SD_STATUS_HALT:
-		if (!is_force_op(req->op)) {
-			rsp->result = SD_RES_HALT;
-			goto done;
-		}
-		break;
 	default:
 		break;
 	}
 
-	/*
-	 * we set epoch for non direct requests here. Note that we
-	 * can't access to sys->epoch after calling
-	 * process_request_event_queues(that is, passing requests to work
-	 * threads).
-	 */
-	if (!(hdr->flags & SD_FLAG_CMD_IO_LOCAL))
-		hdr->epoch = sys->epoch;
-	/*
-	 * force operations shouldn't access req->vnodes in their
-	 * process_work() and process_main() because they can be
-	 * called before we set up current_vnode_info
-	 */
-	if (!is_force_op(req->op))
-		req->vnodes = get_vnode_info();
-
 	if (is_io_op(req->op)) {
 		req->work.fn = do_io_request;
 		req->work.done = io_op_done;
-		setup_access_to_local_objects(req);
-		if (check_request(req) < 0)
-			return;
 	} else if (is_local_op(req->op)) {
 		req->work.fn = do_local_request;
 		req->work.done = local_op_done;
@@ -331,11 +247,25 @@ static void queue_request(struct request
 		req->done(req);
 		return;
 	}
+
 	list_del(&req->r_wlist);
 
-	cevent->ctype = EVENT_REQUEST;
-	list_add_tail(&cevent->event_list, &sys->request_queue);
-	process_request_event_queues();
+	/*
+	 * we set epoch for non direct requests here. Note that we
+	 * can't access to sys->epoch after calling
+	 * start_cpg_event_work(that is, passing requests to work
+	 * threads).
+	 */
+	if (!(hdr->flags & SD_FLAG_CMD_IO_LOCAL))
+		hdr->epoch = sys->epoch;
+
+	setup_ordered_sd_vnode_list(req);
+	if (is_io_op(req->op))
+		setup_access_to_local_objects(req);
+
+	cevent->ctype = CPG_EVENT_REQUEST;
+	list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
+	start_cpg_event_work();
 	return;
 done:
 	req->done(req);
@@ -378,7 +308,7 @@ static void free_request(struct request
 	sys->outstanding_data_size -= req->data_length;
 
 	list_del(&req->r_siblings);
-	put_vnode_info(req->vnodes);
+	free_ordered_sd_vnode_list(req->entry);
 	free(req->data);
 	free(req);
 }
@@ -477,7 +407,6 @@ static void client_rx_handler(struct cli
 
 	req->done = req_done;
 
-	dprintf("connection from: %s:%d\n", ci->conn.ipstr, ci->conn.port);
 	queue_request(req);
 }
 
@@ -569,7 +498,6 @@ again:
 
 static void destroy_client(struct client_info *ci)
 {
-	dprintf("connection from: %s:%d\n", ci->conn.ipstr, ci->conn.port);
 	close(ci->conn.fd);
 	free(ci);
 }
@@ -589,29 +517,11 @@ static void client_decref(struct client_
 static struct client_info *create_client(int fd, struct cluster_info *cluster)
 {
 	struct client_info *ci;
-	struct sockaddr_storage from;
-	socklen_t namesize = sizeof(from);
 
 	ci = zalloc(sizeof(*ci));
 	if (!ci)
 		return NULL;
 
-	if (getpeername(fd, (struct sockaddr *)&from, &namesize))
-		return NULL;
-
-	switch (from.ss_family) {
-	case AF_INET:
-		ci->conn.port = ntohs(((struct sockaddr_in *)&from)->sin_port);
-		inet_ntop(AF_INET, &((struct sockaddr_in *)&from)->sin_addr,
-				ci->conn.ipstr, sizeof(ci->conn.ipstr));
-		break;
-	case AF_INET6:
-		ci->conn.port = ntohs(((struct sockaddr_in6 *)&from)->sin6_port);
-		inet_ntop(AF_INET6, &((struct sockaddr_in6 *)&from)->sin6_addr,
-				ci->conn.ipstr, sizeof(ci->conn.ipstr));
-		break;
-	}
-
 	ci->conn.fd = fd;
 	ci->conn.events = EPOLLIN;
 	ci->refcnt = 1;
@@ -634,8 +544,7 @@ static void client_handler(int fd, int e
 	if (events & EPOLLOUT)
 		client_tx_handler(ci);
 
-	if ((events & (EPOLLERR | EPOLLHUP))
-		|| is_conn_dead(&ci->conn)) {
+	if (is_conn_dead(&ci->conn)) {
 		if (!(ci->conn.events & EPOLLIN))
 			list_del(&ci->conn.blocking_siblings);
 
@@ -702,6 +611,186 @@ int create_listen_port(int port, void *d
 	return create_listen_ports(port, create_listen_port_fn, data);
 }
 
+int write_object(struct sheepdog_vnode_list_entry *e,
+		 int vnodes, int zones, uint32_t node_version,
+		 uint64_t oid, char *data, unsigned int datalen,
+		 uint64_t offset, uint16_t flags, int nr, int create)
+{
+	struct sd_obj_req hdr;
+	int i, n, fd, ret;
+	char name[128];
+
+	if (nr > zones)
+		nr = zones;
+
+	for (i = 0; i < nr; i++) {
+		unsigned rlen = 0, wlen = datalen;
+
+		n = obj_to_sheep(e, vnodes, oid, i);
+
+		if (is_myself(e[n].addr, e[n].port)) {
+			ret = write_object_local(oid, data, datalen, offset,
+						 flags, nr, node_version, create);
+
+			if (ret != 0) {
+				eprintf("fail %"PRIx64" %"PRIx32"\n", oid, ret);
+				return -1;
+			}
+
+			continue;
+		}
+
+		addr_to_str(name, sizeof(name), e[n].addr, 0);
+
+		fd = connect_to(name, e[n].port);
+		if (fd < 0) {
+			eprintf("failed to connect to host %s\n", name);
+			return -1;
+		}
+
+		memset(&hdr, 0, sizeof(hdr));
+		hdr.epoch = node_version;
+		if (create)
+			hdr.opcode = SD_OP_CREATE_AND_WRITE_OBJ;
+		else
+			hdr.opcode = SD_OP_WRITE_OBJ;
+
+		hdr.oid = oid;
+		hdr.copies = nr;
+
+		hdr.flags = flags;
+		hdr.flags |= SD_FLAG_CMD_WRITE | SD_FLAG_CMD_IO_LOCAL;
+		hdr.data_length = wlen;
+		hdr.offset = offset;
+
+		ret = exec_req(fd, (struct sd_req *)&hdr, data, &wlen, &rlen);
+		close(fd);
+		if (ret) {
+			eprintf("failed to update host %s\n", name);
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+int read_object(struct sheepdog_vnode_list_entry *e,
+		int vnodes, int zones, uint32_t node_version,
+		uint64_t oid, char *data, unsigned int datalen,
+		uint64_t offset, int nr)
+{
+	struct sd_obj_req hdr;
+	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
+	char name[128];
+	int i = 0, n, fd, ret, last_error = SD_RES_SUCCESS;
+
+	if (nr > zones)
+		nr = zones;
+
+	/* search a local object first */
+	for (i = 0; i < nr; i++) {
+		n = obj_to_sheep(e, vnodes, oid, i);
+
+		if (is_myself(e[n].addr, e[n].port)) {
+			ret = read_object_local(oid, data, datalen, offset, nr,
+						node_version);
+
+			if (ret != SD_RES_SUCCESS) {
+				eprintf("fail %"PRIx64" %"PRId32"\n", oid, ret);
+				return ret;
+			}
+
+			return SD_RES_SUCCESS;
+		}
+
+	}
+
+	for (i = 0; i < nr; i++) {
+		unsigned wlen = 0, rlen = datalen;
+
+		n = obj_to_sheep(e, vnodes, oid, i);
+
+		addr_to_str(name, sizeof(name), e[n].addr, 0);
+
+		fd = connect_to(name, e[n].port);
+		if (fd < 0) {
+			printf("%s(%d): %s, %m\n", __func__, __LINE__,
+			       name);
+			return SD_RES_EIO;
+		}
+
+		memset(&hdr, 0, sizeof(hdr));
+		hdr.epoch = node_version;
+		hdr.opcode = SD_OP_READ_OBJ;
+		hdr.oid = oid;
+
+		hdr.flags =  SD_FLAG_CMD_IO_LOCAL;
+		hdr.data_length = rlen;
+		hdr.offset = offset;
+
+		ret = exec_req(fd, (struct sd_req *)&hdr, data, &wlen, &rlen);
+		close(fd);
+
+		if (ret) {
+			last_error = SD_RES_EIO;
+			continue;
+		}
+
+		if (rsp->result == SD_RES_SUCCESS)
+			return SD_RES_SUCCESS;
+
+		last_error = rsp->result;
+	}
+
+	return last_error;
+}
+
+int remove_object(struct sheepdog_vnode_list_entry *e,
+		  int vnodes, int zones, uint32_t node_version,
+		  uint64_t oid, int nr)
+{
+	char name[128];
+	struct sd_obj_req hdr;
+	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
+	int i = 0, n, fd, ret;
+
+	if (nr > zones)
+		nr = zones;
+
+	for (i = 0; i < nr; i++) {
+		unsigned wlen = 0, rlen = 0;
+
+		n = obj_to_sheep(e, vnodes, oid, i);
+
+		addr_to_str(name, sizeof(name), e[n].addr, 0);
+
+		fd = connect_to(name, e[n].port);
+		if (fd < 0) {
+			rsp->result = SD_RES_EIO;
+			return -1;
+		}
+
+		memset(&hdr, 0, sizeof(hdr));
+		hdr.epoch = node_version;
+		hdr.opcode = SD_OP_REMOVE_OBJ;
+		hdr.oid = oid;
+
+		hdr.flags = 0;
+		hdr.data_length = rlen;
+
+		ret = exec_req(fd, (struct sd_req *)&hdr, NULL, &wlen, &rlen);
+		close(fd);
+
+		if (ret)
+			return -1;
+	}
+
+	if (rsp->result != SD_RES_SUCCESS)
+		return -1;
+
+	return 0;
+}
+
 static __thread int cached_fds[SD_MAX_NODES];
 static __thread uint32_t cached_epoch = 0;
 
--- sheepdog-0.3.0.orig/sheep/work.h
+++ sheepdog-0.3.0/sheep/work.h
@@ -18,36 +18,6 @@ struct work {
 	enum work_attr attr;
 };
 
-struct work_queue {
-	int wq_state;
-	int nr_active;
-	struct list_head pending_list;
-	struct list_head blocked_list;
-};
-
-struct worker_info {
-	struct list_head worker_info_siblings;
-
-	int nr_threads;
-
-	pthread_mutex_t finished_lock;
-	struct list_head finished_list;
-
-	/* wokers sleep on this and signaled by tgtd */
-	pthread_cond_t pending_cond;
-	/* locked by tgtd and workers */
-	pthread_mutex_t pending_lock;
-	/* protected by pending_lock */
-	struct work_queue q;
-
-	pthread_mutex_t startup_lock;
-
-	pthread_t worker_thread[0];
-};
-
-extern struct list_head worker_info_list;
-extern int total_nr_workers;
-
 struct work_queue *init_work_queue(int nr);
 void queue_work(struct work_queue *q, struct work *work);
 
--- sheepdog-0.3.0.orig/sheep/sheep.c
+++ sheepdog-0.3.0/sheep/sheep.c
@@ -21,36 +21,27 @@
 #include <sys/syslog.h>
 
 #include "sheep_priv.h"
-#include "trace/trace.h"
 
 #define EPOLL_SIZE 4096
 #define DEFAULT_OBJECT_DIR "/tmp"
 #define LOG_FILE_NAME "sheep.log"
 
-static unsigned nr_io_worker = 4;
-static unsigned nr_gateway_worker = 4;
-
 LIST_HEAD(cluster_drivers);
 static char program_name[] = "sheep";
 
 static struct option const long_options[] = {
-	{"asyncflush", no_argument, NULL, 'a'},
-	{"cluster", required_argument, NULL, 'c'},
-	{"debug", no_argument, NULL, 'd'},
-	{"directio", no_argument, NULL, 'D'},
+	{"port", required_argument, NULL, 'p'},
 	{"foreground", no_argument, NULL, 'f'},
-	{"nr_gateway_worker", required_argument, NULL, 'g'},
-	{"help", no_argument, NULL, 'h'},
-	{"nr_io_worker", required_argument, NULL, 'i'},
 	{"loglevel", required_argument, NULL, 'l'},
-	{"stdout", no_argument, NULL, 'o'},
-	{"port", required_argument, NULL, 'p'},
-	{"vnodes", required_argument, NULL, 'v'},
+	{"debug", no_argument, NULL, 'd'},
+	{"directio", no_argument, NULL, 'D'},
 	{"zone", required_argument, NULL, 'z'},
+	{"cluster", required_argument, NULL, 'c'},
+	{"help", no_argument, NULL, 'h'},
 	{NULL, 0, NULL, 0},
 };
 
-static const char *short_options = "ac:dDfg:hi:l:op:v:z:";
+static const char *short_options = "p:fl:dDz:c:h";
 
 static void usage(int status)
 {
@@ -62,18 +53,14 @@ static void usage(int status)
 Sheepdog daemon (version %s)\n\
 Usage: %s [OPTION]... [PATH]\n\
 Options:\n\
-  -a, --asyncflush        flush the object cache asynchronously\n\
-  -c, --cluster           specify the cluster driver\n\
-  -d, --debug             include debug messages in the log\n\
-  -D, --directio          use direct IO when accessing the object from object cache\n\
+  -p, --port              specify the TCP port on which to listen\n\
   -f, --foreground        make the program run in the foreground\n\
-  -g, --nr_gateway_worker set the number of workers for Guests' requests (default 4)\n\
-  -h, --help              display this help and exit\n\
-  -i, --nr_io_worker      set the number of workers for sheep internal requests (default 4)\n\
   -l, --loglevel          specify the level of logging detail\n\
-  -p, --port              specify the TCP port on which to listen\n\
-  -v, --vnodes            specify the number of virtual nodes\n\
+  -d, --debug             include debug messages in the log\n\
+  -D, --directio          use direct IO when accessing the object store\n\
   -z, --zone              specify the zone id\n\
+  -c, --cluster           specify the cluster driver\n\
+  -h, --help              display this help and exit\n\
 ", PACKAGE_VERSION, program_name);
 	exit(status);
 }
@@ -102,11 +89,9 @@ int main(int argc, char **argv)
 	int ret, port = SD_LISTEN_PORT;
 	const char *dir = DEFAULT_OBJECT_DIR;
 	int is_daemon = 1;
-	int to_stdout = 0;
 	int log_level = SDOG_INFO;
 	char path[PATH_MAX];
 	int64_t zone = -1;
-	int nr_vnodes = SD_DEFAULT_VNODES;
 	char *p;
 	struct cluster_driver *cdrv;
 
@@ -144,30 +129,6 @@ int main(int argc, char **argv)
 			dprintf("direct IO mode\n");
 			sys->use_directio = 1;
 			break;
-		case 'a':
-			sys->async_flush = 1;
-			break;
-		case 'g':
-			nr_gateway_worker = strtol(optarg, &p, 10);
-			if (optarg == p || nr_gateway_worker < 4 || nr_gateway_worker > UINT32_MAX) {
-				fprintf(stderr, "Invalid number of gateway workers '%s': "
-					"must be an integer between 4 and %u\n",
-					optarg, UINT32_MAX);
-				exit(1);
-			}
-			break;
-		case 'i':
-			nr_io_worker = strtol(optarg, &p, 10);
-			if (optarg == p || nr_io_worker < 4 || nr_io_worker > UINT32_MAX) {
-				fprintf(stderr, "Invalid number of internal IO workers '%s': "
-					"must be an integer between 4 and %u\n",
-					optarg, UINT32_MAX);
-				exit(1);
-			}
-			break;
-		case 'o':
-			to_stdout = 1;
-			break;
 		case 'z':
 			zone = strtol(optarg, &p, 10);
 			if (optarg == p || zone < 0 || UINT32_MAX < zone) {
@@ -178,15 +139,6 @@ int main(int argc, char **argv)
 			}
 			sys->this_node.zone = zone;
 			break;
-		case 'v':
-			nr_vnodes = strtol(optarg, &p, 10);
-			if (optarg == p || nr_vnodes < 0 || SD_MAX_VNODES < nr_vnodes) {
-				fprintf(stderr, "Invalid number of virtual nodes '%s': "
-					"must be an integer between 0 and %u\n",
-					optarg, SD_MAX_VNODES);
-				exit(1);
-			}
-			break;
 		case 'c':
 			sys->cdrv = find_cdrv(optarg);
 			if (!sys->cdrv) {
@@ -224,7 +176,7 @@ int main(int argc, char **argv)
 	if (ret)
 		exit(1);
 
-	ret = log_init(program_name, LOG_SPACE_SIZE, to_stdout, log_level, path);
+	ret = log_init(program_name, LOG_SPACE_SIZE, is_daemon, log_level, path);
 	if (ret)
 		exit(1);
 
@@ -240,29 +192,19 @@ int main(int argc, char **argv)
 	if (ret)
 		exit(1);
 
-	ret = create_cluster(port, zone, nr_vnodes);
+	ret = create_cluster(port, zone);
 	if (ret) {
 		eprintf("failed to create sheepdog cluster\n");
 		exit(1);
 	}
 
-	sys->event_wqueue = init_work_queue(1);
-	sys->gateway_wqueue = init_work_queue(nr_gateway_worker);
-	sys->io_wqueue = init_work_queue(nr_io_worker);
+	sys->cpg_wqueue = init_work_queue(1);
+	sys->gateway_wqueue = init_work_queue(NR_GW_WORKER_THREAD);
+	sys->io_wqueue = init_work_queue(NR_IO_WORKER_THREAD);
 	sys->recovery_wqueue = init_work_queue(1);
 	sys->deletion_wqueue = init_work_queue(1);
-	sys->flush_wqueue = init_work_queue(1);
-	if (!sys->event_wqueue || !sys->gateway_wqueue || !sys->io_wqueue ||
-	    !sys->recovery_wqueue || !sys->deletion_wqueue ||
-	    !sys->flush_wqueue)
-		exit(1);
-
-	ret = init_signal();
-	if (ret)
-		exit(1);
-
-	ret = trace_init();
-	if (ret)
+	if (!sys->cpg_wqueue || !sys->gateway_wqueue || !sys->io_wqueue ||
+	    !sys->recovery_wqueue || !sys->deletion_wqueue)
 		exit(1);
 
 	vprintf(SDOG_NOTICE, "sheepdog daemon (version %s) started\n", PACKAGE_VERSION);
--- sheepdog-0.3.0.orig/sheep/Makefile.am
+++ sheepdog-0.3.0/sheep/Makefile.am
@@ -24,10 +24,8 @@ INCLUDES		= -I$(top_builddir)/include -I
 
 sbin_PROGRAMS		= sheep
 
-sheep_SOURCES		= sheep.c group.c sdnet.c store.c vdi.c work.c \
-			  journal.c ops.c recovery.c cluster/local.c strbuf.c \
-			  simple_store.c object_cache.c object_list_cache.c
-
+sheep_SOURCES		= sheep.c group.c sdnet.c store.c vdi.c work.c journal.c ops.c \
+			  cluster/local.c strbuf.c simple_store.c
 if BUILD_COROSYNC
 sheep_SOURCES		+= cluster/corosync.c
 endif
@@ -38,20 +36,12 @@ if BUILD_ACCORD
 sheep_SOURCES		+= cluster/accord.c
 endif
 
-if BUILD_FARM
-sheep_SOURCES		+= farm/sha1_file.c farm/trunk.c farm/snap.c farm/farm.c
-endif
-
-if BUILD_TRACE
-sheep_SOURCES		+= trace/trace.c trace/mcount.S trace/stabs.c trace/graph.c
-endif
-
 sheep_LDADD	  	= ../lib/libsheepdog.a -lpthread \
-			  $(libcpg_LIBS) $(libcfg_LIBS) $(libacrd_LIBS) $(LIBS)
+			  $(libcpg_LIBS) $(libcfg_LIBS) $(libacrd_LIBS)
 sheep_DEPENDENCIES	= ../lib/libsheepdog.a
 
 
-noinst_HEADERS		= work.h sheep_priv.h cluster.h strbuf.h farm/farm.h trace/trace.h
+noinst_HEADERS		= work.h sheep_priv.h cluster.h strbuf.h
 
 EXTRA_DIST		= 
 
--- sheepdog-0.3.0.orig/sheep/ops.c
+++ sheepdog-0.3.0/sheep/ops.c
@@ -10,21 +10,8 @@
  */
 #include <stdio.h>
 #include <stdlib.h>
-#include <dirent.h>
-#include <errno.h>
-#include <fcntl.h>
-#include <mntent.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <unistd.h>
-#include <sys/statvfs.h>
-#include <sys/types.h>
-#include <sys/stat.h>
-#include <pthread.h>
 
 #include "sheep_priv.h"
-#include "strbuf.h"
-#include "trace/trace.h"
 
 enum sd_op_type {
 	SD_OP_TYPE_CLUSTER = 1, /* cluster operations */
@@ -60,72 +47,12 @@ struct sd_op_template {
 	int (*process_main)(const struct sd_req *req, struct sd_rsp *rsp, void *data);
 };
 
-struct flush_work {
-	struct object_cache *cache;
-	struct work work;
-};
-
-static void get_store_dir(struct strbuf *buf, uint32_t epoch)
-{
-	if (!strcmp(sd_store->name, "simple"))
-		strbuf_addf(buf, "%s%08u/", obj_path, epoch);
-	else /* XXX assume other store doesn't need epoch/obj pattern */
-		strbuf_addf(buf, "%s", obj_path);
-}
-
-static int stat_sheep(uint64_t *store_size, uint64_t *store_free, uint32_t epoch)
-{
-	struct statvfs vs;
-	int ret;
-	DIR *dir;
-	struct dirent *d;
-	uint64_t used = 0;
-	struct stat s;
-	char path[1024];
-	struct strbuf store_dir = STRBUF_INIT;
-
-	ret = statvfs(mnt_path, &vs);
-	if (ret) {
-		ret = SD_RES_EIO;
-		goto out;
-	}
-
-	get_store_dir(&store_dir, epoch);
-	dir = opendir(store_dir.buf);
-	if (!dir) {
-		ret = SD_RES_EIO;
-		goto out;
-	}
-
-	while ((d = readdir(dir))) {
-		if (!strcmp(d->d_name, ".") || !strcmp(d->d_name, ".."))
-			continue;
-
-		snprintf(path, sizeof(path), "%s/%s", store_dir.buf, d->d_name);
-
-		ret = stat(path, &s);
-		if (ret)
-			continue;
-
-		used += s.st_size;
-	}
-
-	closedir(dir);
-	ret = SD_RES_SUCCESS;
-
-	*store_size = (uint64_t)vs.f_frsize * vs.f_bfree + used;
-	*store_free = (uint64_t)vs.f_frsize * vs.f_bfree;
-out:
-	strbuf_release(&store_dir);
-	return ret;
-}
-
 static int cluster_new_vdi(const struct sd_req *req, struct sd_rsp *rsp,
 			   void *data)
 {
 	const struct sd_vdi_req *hdr = (const struct sd_vdi_req *)req;
 	struct sd_vdi_rsp *vdi_rsp = (struct sd_vdi_rsp *)rsp;
-	uint32_t vid = 0, nr_copies = sys->nr_copies;
+	uint32_t vid = 0, nr_copies = sys->nr_sobjs;
 	int ret;
 
 	ret = add_vdi(hdr->epoch, data, hdr->data_length, hdr->vdi_size, &vid,
@@ -156,14 +83,12 @@ static int cluster_del_vdi(const struct
 {
 	const struct sd_vdi_req *hdr = (const struct sd_vdi_req *)req;
 	struct sd_vdi_rsp *vdi_rsp = (struct sd_vdi_rsp *)rsp;
-	uint32_t vid = 0, nr_copies = sys->nr_copies;
+	uint32_t vid = 0, nr_copies = sys->nr_sobjs;
 	int ret;
 
 	ret = del_vdi(hdr->epoch, data, hdr->data_length, &vid,
 		      hdr->snapid, &nr_copies);
 
-	if (ret == SD_RES_SUCCESS)
-		object_cache_delete(vid);
 	vdi_rsp->vdi_id = vid;
 	vdi_rsp->copies = nr_copies;
 
@@ -175,7 +100,7 @@ static int cluster_get_vdi_info(const st
 {
 	const struct sd_vdi_req *hdr = (const struct sd_vdi_req *)req;
 	struct sd_vdi_rsp *vdi_rsp = (struct sd_vdi_rsp *)rsp;
-	uint32_t vid = 0, nr_copies = sys->nr_copies;
+	uint32_t vid = 0, nr_copies = sys->nr_sobjs;
 	void *tag;
 	int ret;
 
@@ -200,56 +125,24 @@ static int cluster_get_vdi_info(const st
 	return ret;
 }
 
-static int remove_epoch(uint32_t epoch)
-{
-	int ret;
-	char path[PATH_MAX];
-
-	dprintf("remove epoch %"PRIu32"\n", epoch);
-	snprintf(path, sizeof(path), "%s%08u", epoch_path, epoch);
-	ret = unlink(path);
-	if (ret && ret != -ENOENT) {
-		eprintf("failed to remove %s: %s\n", path, strerror(-ret));
-		return SD_RES_EIO;
-	}
-
-	snprintf(path, sizeof(path), "%s%08u/", jrnl_path, epoch);
-	ret = rmdir_r(path);
-	if (ret && ret != -ENOENT) {
-		eprintf("failed to remove %s: %s\n", path, strerror(-ret));
-		return SD_RES_EIO;
-	}
-	return 0;
-}
-
 static int cluster_make_fs(const struct sd_req *req, struct sd_rsp *rsp,
 			   void *data)
 {
 	const struct sd_so_req *hdr = (const struct sd_so_req *)req;
-	int i, ret;
-	uint32_t latest_epoch;
-	uint64_t created_time;
-	struct siocb iocb = { 0 };
-
-	sd_store = find_store_driver(data);
-	if (!sd_store)
-		return SD_RES_NO_STORE;
+	int i, latest_epoch, ret;
+	uint64_t ctime;
 
-	latest_epoch = get_latest_epoch();
-	iocb.epoch = latest_epoch;
-	sd_store->format(&iocb);
-	sd_store->init(obj_path);
-	sys->nr_copies = hdr->copies;
+	sys->nr_sobjs = hdr->copies;
 	sys->flags = hdr->flags;
-	if (!sys->nr_copies)
-		sys->nr_copies = SD_DEFAULT_REDUNDANCY;
+	if (!sys->nr_sobjs)
+		sys->nr_sobjs = SD_DEFAULT_REDUNDANCY;
 
-	created_time = hdr->ctime;
-	set_cluster_ctime(created_time);
+	ctime = hdr->ctime;
+	set_cluster_ctime(ctime);
 
+	latest_epoch = get_latest_epoch();
 	for (i = 1; i <= latest_epoch; i++)
 		remove_epoch(i);
-
 	memset(sys->vdi_inuse, 0, sizeof(sys->vdi_inuse));
 
 	sys->epoch = 1;
@@ -261,7 +154,7 @@ static int cluster_make_fs(const struct
 
 	update_epoch_store(sys->epoch);
 
-	set_cluster_copies(sys->nr_copies);
+	set_cluster_copies(sys->nr_sobjs);
 	set_cluster_flags(sys->flags);
 
 	if (sys_flag_nohalt())
@@ -269,7 +162,7 @@ static int cluster_make_fs(const struct
 	else {
 		int nr_zones = get_zones_nr_from(sys->nodes, sys->nr_nodes);
 
-		if (nr_zones >= sys->nr_copies)
+		if (nr_zones >= sys->nr_sobjs)
 			sys_stat_set(SD_STATUS_OK);
 		else
 			sys_stat_set(SD_STATUS_HALT);
@@ -291,14 +184,14 @@ static int cluster_get_vdi_attr(const st
 {
 	const struct sd_vdi_req *hdr = (const struct sd_vdi_req *)req;
 	struct sd_vdi_rsp *vdi_rsp = (struct sd_vdi_rsp *)rsp;
-	uint32_t vid = 0, attrid = 0, nr_copies = sys->nr_copies;
-	uint64_t created_time = 0;
+	uint32_t vid = 0, attrid = 0, nr_copies = sys->nr_sobjs;
+	uint64_t ctime = 0;
 	int ret;
 	struct sheepdog_vdi_attr *vattr;
 
 	vattr = data;
 	ret = lookup_vdi(hdr->epoch, vattr->name, vattr->tag,
-			 &vid, hdr->snapid, &nr_copies, &created_time);
+			 &vid, hdr->snapid, &nr_copies, &ctime);
 	if (ret != SD_RES_SUCCESS)
 		return ret;
 
@@ -307,7 +200,7 @@ static int cluster_get_vdi_attr(const st
 	vid = fnv_64a_buf(vattr->name, strlen(vattr->name), FNV1A_64_INIT);
 	vid &= SD_NR_VDIS - 1;
 	ret = get_vdi_attr(hdr->epoch, data, hdr->data_length, vid,
-			   &attrid, nr_copies, created_time,
+			   &attrid, nr_copies, ctime,
 			   hdr->flags & SD_FLAG_CMD_CREAT,
 			   hdr->flags & SD_FLAG_CMD_EXCL,
 			   hdr->flags & SD_FLAG_CMD_DEL);
@@ -319,29 +212,14 @@ static int cluster_get_vdi_attr(const st
 	return ret;
 }
 
-static int local_get_store_list(const struct sd_req *req, struct sd_rsp *rsp,
-				void *data)
-{
-	struct strbuf buf = STRBUF_INIT;
-	struct store_driver *driver;
-
-	list_for_each_entry(driver, &store_drivers, list) {
-		strbuf_addf(&buf, "%s ", driver->name);
-	}
-	memcpy(data, buf.buf, buf.len);
-
-	strbuf_release(&buf);
-	return SD_RES_SUCCESS;
-}
-
 static int local_read_vdis(const struct sd_req *req, struct sd_rsp *rsp,
 			   void *data)
 {
 	return read_vdis(data, req->data_length, &rsp->data_length);
 }
 
-static int get_node_idx(struct sd_node *ent,
-			struct sd_node *entries, int nr_nodes)
+static int get_node_idx(struct sheepdog_node_list_entry *ent,
+			struct sheepdog_node_list_entry *entries, int nr_nodes)
 {
 	ent = bsearch(ent, entries, nr_nodes, sizeof(*ent), node_cmp);
 	if (!ent)
@@ -358,7 +236,7 @@ static int local_get_node_list(const str
 
 	nr_nodes = sys->nr_nodes;
 	memcpy(data, sys->nodes, sizeof(*sys->nodes) * nr_nodes);
-	node_rsp->data_length = nr_nodes * sizeof(struct sd_node);
+	node_rsp->data_length = nr_nodes * sizeof(struct sheepdog_node_list_entry);
 	node_rsp->nr_nodes = nr_nodes;
 	node_rsp->local_idx = get_node_idx(&sys->this_node, data, nr_nodes);
 	node_rsp->master_idx = -1;
@@ -375,23 +253,12 @@ static int local_stat_sheep(const struct
 	return stat_sheep(&node_rsp->store_size, &node_rsp->store_free, epoch);
 }
 
-static int local_stat_recovery(const struct sd_req *req, struct sd_rsp *rsp,
-					void *data)
-{
-	if (node_in_recovery())
-		return SD_RES_SUCCESS;
-	else
-		return SD_RES_UNKNOWN;
-
-	return SD_RES_UNKNOWN;
-}
-
 static int local_stat_cluster(const struct sd_req *req, struct sd_rsp *rsp,
 			      void *data)
 {
 	struct epoch_log *log;
-	int i, max_logs;
-	uint32_t sys_stat = sys_stat_get(), epoch;
+	int i, max_logs, epoch;
+	uint32_t sys_stat = sys_stat_get();
 
 	max_logs = rsp->data_length / sizeof(*log);
 	epoch = get_latest_epoch();
@@ -409,7 +276,6 @@ static int local_stat_cluster(const stru
 			log->nr_nodes = epoch_log_read_remote(epoch,
 							      (char *)log->nodes,
 							      sizeof(log->nodes));
-		log->nr_copies = get_max_nr_copies_from(log->nodes, log->nr_nodes);
 
 		rsp->data_length += sizeof(*log);
 		log->nr_nodes /= sizeof(log->nodes[0]);
@@ -454,7 +320,7 @@ static int local_get_epoch(const struct
 {
 	const struct sd_obj_req *obj_req = (const struct sd_obj_req *)req;
 	struct sd_obj_rsp *obj_rsp = (struct sd_obj_rsp *)rsp;
-	uint32_t epoch = obj_req->tgt_epoch;
+	int epoch = obj_req->tgt_epoch;
 	int len, ret;
 	dprintf("%d\n", epoch);
 	len = epoch_log_read(epoch, (char *)data, obj_req->data_length);
@@ -492,18 +358,17 @@ static int cluster_manual_recover(const
 	if (ret)
 		goto out;
 
-	sys->nr_copies = c;
+	sys->nr_sobjs = c;
 	sys->flags = f;
 
 	s = SD_STATUS_OK;
 	if (!sys_flag_nohalt()) {
 		nr_zones = get_zones_nr_from(sys->nodes, sys->nr_nodes);
-		if (nr_zones < sys->nr_copies)
+		if (nr_zones < sys->nr_sobjs)
 			s = SD_STATUS_HALT;
 	}
 
-	dprintf("flags %d, nr_zones %d, copies %d\n", sys->flags, nr_zones,
-		sys->nr_copies);
+	dprintf("flags %d, nr_zones %d, copies %d\n", sys->flags, nr_zones, sys->nr_sobjs);
 
 	sys->epoch++; /* some nodes are left, so we get a new epoch */
 	ret = update_epoch_log(sys->epoch);
@@ -518,365 +383,6 @@ out:
 	return ret;
 }
 
-static int cluster_snapshot(const struct sd_req *req, struct sd_rsp *rsp,
-			    void *data)
-{
-	int ret;
-	struct siocb iocb = { 0 };
-
-	if (sd_store->snapshot)
-		ret = sd_store->snapshot(&iocb);
-	else
-		ret = SD_RES_NO_SUPPORT;
-
-	return ret;
-}
-
-static int cluster_cleanup(const struct sd_req *req, struct sd_rsp *rsp,
-				void *data)
-{
-	int ret;
-	struct siocb iocb = { 0 };
-	iocb.epoch = sys->epoch;
-
-	if (node_in_recovery())
-		return SD_RES_CLUSTER_RECOVERING;
-
-	if (sd_store->cleanup)
-		ret = sd_store->cleanup(&iocb);
-	else
-		ret = SD_RES_NO_SUPPORT;
-
-	return ret;
-}
-
-static int cluster_restore(const struct sd_req *req, struct sd_rsp *rsp,
-			   void *data)
-{
-	const struct sd_obj_req *hdr = (const struct sd_obj_req *)req;
-	int ret;
-	struct siocb iocb = { .epoch = hdr->tgt_epoch };
-
-	if (sd_store->restore)
-		ret = sd_store->restore(&iocb);
-	else
-		ret = SD_RES_NO_SUPPORT;
-	return ret;
-}
-
-static int local_get_snap_file(const struct sd_req *req, struct sd_rsp *rsp,
-			    void *data)
-{
-	int ret;
-	struct siocb iocb = { .buf = data };
-
-	if (sd_store->get_snap_file) {
-		ret = sd_store->get_snap_file(&iocb);
-		rsp->data_length = iocb.length;
-	} else
-		ret = SD_RES_NO_SUPPORT;
-
-	return ret;
-}
-
-static void flush_vdi_fn(struct work *work)
-{
-	struct flush_work *fw = container_of(work, struct flush_work, work);
-
-	dprintf("flush vdi %"PRIx32"\n", fw->cache->vid);
-	if (object_cache_push(fw->cache) != SD_RES_SUCCESS)
-		eprintf("failed to flush vdi %"PRIx32"\n", fw->cache->vid);
-}
-
-static void flush_vdi_done(struct work *work)
-{
-	struct flush_work *fw = container_of(work, struct flush_work, work);
-	dprintf("flush vdi %"PRIx32" done\n", fw->cache->vid);
-	free(fw);
-}
-
-static int local_flush_vdi(const struct sd_req *req, struct sd_rsp *rsp, void *data)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
-	uint64_t oid = hdr->oid;
-	uint32_t vid = oid_to_vid(oid);
-	struct object_cache *cache = find_object_cache(vid, 0);
-
-	if (cache) {
-		if (!sys->async_flush)
-			return object_cache_push(cache);
-		else {
-			struct flush_work *fw = xmalloc(sizeof(*fw));
-			fw->work.fn = flush_vdi_fn;
-			fw->work.done = flush_vdi_done;
-			fw->cache = cache;
-			queue_work(sys->flush_wqueue, &fw->work);
-		}
-	}
-
-	return SD_RES_SUCCESS;
-}
-
-static int local_trace_ops(const struct sd_req *req, struct sd_rsp *rsp, void *data)
-{
-	int enable = req->data_length, ret;
-
-	if (enable)
-		ret = trace_enable();
-	else
-		ret = trace_disable();
-
-	return ret;
-}
-
-static int local_trace_cat_ops(const struct sd_req *req, struct sd_rsp *rsp, void *data)
-{
-	rsp->data_length = trace_copy_buffer(data);
-	dprintf("%u\n", rsp->data_length);
-	trace_reset_buffer();
-	return SD_RES_SUCCESS;
-}
-
-static int read_copy_from_replica(struct request *req, uint32_t epoch,
-				  uint64_t oid, char *buf)
-{
-	int i, nr_copies, ret;
-	unsigned wlen, rlen;
-	char name[128];
-	struct sd_vnode *v;
-	struct sd_obj_req hdr;
-	struct sd_obj_rsp *rsp = (struct sd_obj_rsp *)&hdr;
-	struct siocb iocb;
-	int fd;
-
-	nr_copies = get_nr_copies(req->vnodes);
-	for (i = 0; i < nr_copies; i++) {
-		v = oid_to_vnode(req->vnodes, oid, i);
-
-		addr_to_str(name, sizeof(name), v->addr, 0);
-
-		if (vnode_is_local(v)) {
-			memset(&iocb, 0, sizeof(iocb));
-			iocb.epoch = epoch;
-			ret = sd_store->open(oid, &iocb, 0);
-			if (ret != SD_RES_SUCCESS)
-				continue;
-
-			iocb.buf = buf;
-			iocb.length = SD_DATA_OBJ_SIZE;
-			iocb.offset = 0;
-			ret = sd_store->read(oid, &iocb);
-			if (ret != SD_RES_SUCCESS)
-				continue;
-			sd_store->close(oid, &iocb);
-			goto out;
-		}
-
-		fd = connect_to(name, v->port);
-		if (fd < 0)
-			continue;
-
-		memset(&hdr, 0, sizeof(hdr));
-		hdr.opcode = SD_OP_READ_OBJ;
-		hdr.oid = oid;
-		hdr.epoch = epoch;
-
-		rlen = SD_DATA_OBJ_SIZE;
-		wlen = 0;
-		hdr.flags = SD_FLAG_CMD_IO_LOCAL;
-		hdr.data_length = rlen;
-		hdr.offset = 0;
-
-		ret = exec_req(fd, (struct sd_req *)&hdr, buf, &wlen, &rlen);
-
-		close(fd);
-
-		dprintf("%x, %x\n", ret, rsp->result);
-		if (ret)
-			continue;
-
-		switch (rsp->result) {
-		case SD_RES_SUCCESS:
-			ret = SD_RES_SUCCESS;
-			goto out;
-		default:
-			;
-		}
-	}
-
-	ret = rsp->result;
-out:
-	return ret;
-}
-
-static int store_remove_obj(const struct sd_req *req, struct sd_rsp *rsp, void *data)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
-	uint32_t epoch = hdr->epoch;
-	struct strbuf buf = STRBUF_INIT;
-	int ret = SD_RES_SUCCESS;
-
-	get_store_dir(&buf, epoch);
-	strbuf_addf(&buf, "%016" PRIx64, hdr->oid);
-	if (unlink(buf.buf) < 0) {
-		if (errno == ENOENT) {
-			ret = SD_RES_NO_OBJ;
-			goto out;
-		}
-		eprintf("%m\n");
-		ret =  SD_RES_EIO;
-	}
-	pthread_rwlock_wrlock(&obj_list_cache.lock);
-	if (!objlist_cache_rb_remove(&obj_list_cache.root, hdr->oid))
-		obj_list_cache.cache_size--;
-	pthread_rwlock_unlock(&obj_list_cache.lock);
- out:
-	strbuf_release(&buf);
-	return ret;
-}
-
-static int store_read_obj(const struct sd_req *req, struct sd_rsp *rsp, void *data)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
-	struct sd_obj_rsp *rsps = (struct sd_obj_rsp *)rsp;
-	struct request *request = (struct request *)data;
-	int ret;
-	uint32_t epoch = hdr->epoch;
-	struct siocb iocb;
-
-	memset(&iocb, 0, sizeof(iocb));
-	iocb.epoch = epoch;
-	iocb.flags = hdr->flags;
-	ret = sd_store->open(hdr->oid, &iocb, 0);
-	if (ret != SD_RES_SUCCESS)
-		return ret;
-
-	iocb.buf = request->data;
-	iocb.length = hdr->data_length;
-	iocb.offset = hdr->offset;
-	ret = sd_store->read(hdr->oid, &iocb);
-	if (ret != SD_RES_SUCCESS)
-		goto out;
-
-	rsps->data_length = hdr->data_length;
-	rsps->copies = sys->nr_copies;
-out:
-	sd_store->close(hdr->oid, &iocb);
-	return ret;
-}
-
-static int do_write_obj(struct siocb *iocb, struct sd_obj_req *req, uint32_t epoch, void *data)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
-	uint64_t oid = hdr->oid;
-	int ret = SD_RES_SUCCESS;
-	void *jd = NULL;
-
-	iocb->buf = data;
-	iocb->length = hdr->data_length;
-	iocb->offset = hdr->offset;
-	if (is_vdi_obj(oid)) {
-		struct strbuf buf = STRBUF_INIT;
-
-		get_store_dir(&buf, epoch);
-		strbuf_addf(&buf, "%016" PRIx64, oid);
-		jd = jrnl_begin(data, hdr->data_length,
-				   hdr->offset, buf.buf, jrnl_path);
-		if (!jd) {
-			strbuf_release(&buf);
-			return SD_RES_EIO;
-		}
-		ret = sd_store->write(oid, iocb);
-		jrnl_end(jd);
-		strbuf_release(&buf);
-	} else
-		ret = sd_store->write(oid, iocb);
-
-	return ret;
-}
-
-static int store_write_obj(const struct sd_req *req, struct sd_rsp *rsp,
-			   void *data)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
-	struct request *request = (struct request *)data;
-	int ret;
-	uint32_t epoch = hdr->epoch;
-	struct siocb iocb;
-
-	memset(&iocb, 0, sizeof(iocb));
-	iocb.epoch = epoch;
-	iocb.flags = hdr->flags;
-	ret = sd_store->open(hdr->oid, &iocb, 0);
-	if (ret != SD_RES_SUCCESS)
-		return ret;
-
-	ret = do_write_obj(&iocb, hdr, epoch, request->data);
-
-	sd_store->close(hdr->oid, &iocb);
-	return ret;
-}
-
-static int store_create_and_write_obj(const struct sd_req *req,
-				struct sd_rsp *rsp, void *data)
-{
-	struct sd_obj_req *hdr = (struct sd_obj_req *)req;
-	struct request *request = (struct request *)data;
-	struct sd_obj_req cow_hdr;
-	int ret;
-	uint32_t epoch = hdr->epoch;
-	char *buf = NULL;
-	struct siocb iocb;
-	unsigned data_length;
-
-	if (is_vdi_obj(hdr->oid))
-		data_length = SD_INODE_SIZE;
-	else if (is_vdi_attr_obj(hdr->oid))
-		data_length = SD_ATTR_OBJ_SIZE;
-	else
-		data_length = SD_DATA_OBJ_SIZE;
-
-	memset(&iocb, 0, sizeof(iocb));
-	iocb.epoch = epoch;
-	iocb.flags = hdr->flags;
-	iocb.length = data_length;
-	ret = sd_store->open(hdr->oid, &iocb, 1);
-	if (ret != SD_RES_SUCCESS)
-		return ret;
-	if (hdr->flags & SD_FLAG_CMD_COW) {
-		dprintf("%" PRIx64 ", %" PRIx64 "\n", hdr->oid, hdr->cow_oid);
-
-		buf = valloc(SD_DATA_OBJ_SIZE);
-		if (!buf) {
-			eprintf("can not allocate memory\n");
-			goto out;
-		}
-		if (hdr->data_length != SD_DATA_OBJ_SIZE) {
-			ret = read_copy_from_replica(request, hdr->epoch, hdr->cow_oid, buf);
-			if (ret != SD_RES_SUCCESS) {
-				eprintf("failed to read cow object\n");
-				goto out;
-			}
-		}
-
-		memcpy(buf + hdr->offset, request->data, hdr->data_length);
-		memcpy(&cow_hdr, hdr, sizeof(cow_hdr));
-		cow_hdr.offset = 0;
-		cow_hdr.data_length = SD_DATA_OBJ_SIZE;
-
-		ret = do_write_obj(&iocb, &cow_hdr, epoch, buf);
-	} else
-		ret = do_write_obj(&iocb, hdr, epoch, request->data);
-
-	if (SD_RES_SUCCESS == ret)
-		check_and_insert_objlist_cache(hdr->oid);
-out:
-	if (buf)
-		free(buf);
-	sd_store->close(hdr->oid, &iocb);
-	return ret;
-}
-
 static struct sd_op_template sd_ops[] = {
 
 	/* cluster operations */
@@ -927,31 +433,7 @@ static struct sd_op_template sd_ops[] =
 		.process_main = cluster_manual_recover,
 	},
 
-	[SD_OP_SNAPSHOT] = {
-		.type = SD_OP_TYPE_CLUSTER,
-		.force = 1,
-		.process_main = cluster_snapshot,
-	},
-
-	[SD_OP_RESTORE] = {
-		.type = SD_OP_TYPE_CLUSTER,
-		.force = 1,
-		.process_main = cluster_restore,
-	},
-
-	[SD_OP_CLEANUP] = {
-		.type = SD_OP_TYPE_CLUSTER,
-		.force = 1,
-		.process_main = cluster_cleanup,
-	},
-
 	/* local operations */
-	[SD_OP_GET_STORE_LIST] = {
-		.type = SD_OP_TYPE_LOCAL,
-		.force = 1,
-		.process_work = local_get_store_list,
-	},
-
 	[SD_OP_READ_VDIS] = {
 		.type = SD_OP_TYPE_LOCAL,
 		.force = 1,
@@ -969,11 +451,6 @@ static struct sd_op_template sd_ops[] =
 		.process_work = local_stat_sheep,
 	},
 
-	[SD_OP_STAT_RECOVERY] = {
-		.type = SD_OP_TYPE_LOCAL,
-		.process_main = local_stat_recovery,
-	},
-
 	[SD_OP_STAT_CLUSTER] = {
 		.type = SD_OP_TYPE_LOCAL,
 		.force = 1,
@@ -996,29 +473,6 @@ static struct sd_op_template sd_ops[] =
 		.process_work = local_get_epoch,
 	},
 
-	[SD_OP_GET_SNAP_FILE] = {
-		.type = SD_OP_TYPE_LOCAL,
-		.force = 1,
-		.process_work = local_get_snap_file,
-	},
-
-	[SD_OP_FLUSH_VDI] = {
-		.type = SD_OP_TYPE_LOCAL,
-		.process_work = local_flush_vdi,
-	},
-
-	[SD_OP_TRACE] = {
-		.type = SD_OP_TYPE_LOCAL,
-		.force = 1,
-		.process_main = local_trace_ops,
-	},
-
-	[SD_OP_TRACE_CAT] = {
-		.type = SD_OP_TYPE_LOCAL,
-		.force = 1,
-		.process_main = local_trace_cat_ops,
-	},
-
 	/* I/O operations */
 	[SD_OP_CREATE_AND_WRITE_OBJ] = {
 		.type = SD_OP_TYPE_IO,
--- sheepdog-0.3.0.orig/sheep/journal.c
+++ sheepdog-0.3.0/sheep/journal.c
@@ -20,6 +20,7 @@
 #include "sheep_priv.h"
 
 #define JRNL_END_MARK           0x87654321UL
+#define IS_END_MARK_SET(var)    (var == JRNL_END_MARK)
 
 /* Journal header for data object */
 struct jrnl_head {
@@ -30,7 +31,7 @@ struct jrnl_head {
 
 struct jrnl_descriptor {
 	struct jrnl_head head;
-	const void *data;
+	void *data;
 	int fd;      /* Open file fd */
 	int target_fd;
 	char path[256];
@@ -88,6 +89,18 @@ static int jrnl_remove(struct jrnl_descr
 	return ret;
 }
 
+static int jrnl_has_end_mark(struct jrnl_descriptor *jd)
+{
+	ssize_t ret;
+	uint32_t end_mark = 0;
+	struct jrnl_head *head = (struct jrnl_head *) &jd->head;
+
+	ret = pread64(jd->fd, &end_mark, sizeof(end_mark),
+		      sizeof(*head) + head->size);
+
+	return IS_END_MARK_SET(end_mark);
+}
+
 static int jrnl_write_header(struct jrnl_descriptor *jd)
 {
 	ssize_t ret;
@@ -179,7 +192,7 @@ static int jrnl_apply_to_target_object(s
 /*
  * We cannot use this function for concurrent write operations
  */
-struct jrnl_descriptor *jrnl_begin(const void *buf, size_t count, off_t offset,
+struct jrnl_descriptor *jrnl_begin(void *buf, size_t count, off_t offset,
 		 const char *path, const char *jrnl_dir)
 {
 	int ret;
@@ -240,9 +253,8 @@ int jrnl_recover(const char *jrnl_dir)
 
 	vprintf(SDOG_NOTICE, "starting journal recovery\n");
 	while ((d = readdir(dir))) {
-		struct jrnl_descriptor jd;
-		uint32_t end_mark = 0;
 		int ret;
+		struct jrnl_descriptor jd;
 
 		if (!strcmp(d->d_name, ".") || !strcmp(d->d_name, ".."))
 			continue;
@@ -255,18 +267,8 @@ int jrnl_recover(const char *jrnl_dir)
 				jrnl_file_path);
 			goto end_while_3;
 		}
-
-		ret = pread64(jd.fd, &end_mark, sizeof(end_mark),
-				sizeof(jd.head) + jd.head.size);
-		if (ret != sizeof(end_mark)) {
-			eprintf("can't read journal end mark for object %s\n",
-				jd.head.target_path);
+		if (!jrnl_has_end_mark(&jd))
 			goto end_while_2;
-		}
-
-		if (end_mark != JRNL_END_MARK)
-			goto end_while_2;
-
 		jd.target_fd = open(jd.head.target_path, O_DSYNC | O_RDWR);
 		if (ret) {
 			eprintf("unable to open the object file %s for recovery\n",
--- sheepdog-0.3.0.orig/sheep/sheep_priv.h
+++ sheepdog-0.3.0/sheep/sheep_priv.h
@@ -20,7 +20,8 @@
 #include "net.h"
 #include "sheep.h"
 #include "cluster.h"
-#include "rbtree.h"
+
+#define SD_OP_REMOVE_OBJ     0x91
 
 #define SD_OP_GET_OBJ_LIST   0xA1
 #define SD_OP_GET_EPOCH      0XA2
@@ -34,19 +35,19 @@
 
 #define SD_RES_NETWORK_ERROR    0x81 /* Network error between sheep */
 
-enum event_type {
-	EVENT_JOIN,
-	EVENT_LEAVE,
-	EVENT_NOTIFY,
-	EVENT_REQUEST,
+enum cpg_event_type {
+	CPG_EVENT_JOIN,
+	CPG_EVENT_LEAVE,
+	CPG_EVENT_NOTIFY,
+	CPG_EVENT_REQUEST,
 };
 
 #define is_membership_change_event(x) \
-	((x) == EVENT_JOIN || (x) == EVENT_LEAVE)
+	((x) == CPG_EVENT_JOIN || (x) == CPG_EVENT_LEAVE)
 
-struct event_struct {
-	enum event_type ctype;
-	struct list_head event_list;
+struct cpg_event {
+	enum cpg_event_type ctype;
+	struct list_head cpg_event_list;
 };
 
 struct client_info {
@@ -63,12 +64,11 @@ struct client_info {
 };
 
 struct request;
-struct vnode_info;
 
 typedef void (*req_end_t) (struct request *);
 
 struct request {
-	struct event_struct cev;
+	struct cpg_event cev;
 	struct sd_req rq;
 	struct sd_rsp rp;
 
@@ -83,9 +83,10 @@ struct request {
 	struct list_head pending_list;
 
 	uint64_t local_oid;
-	uint64_t local_cow_oid;
 
-	struct vnode_info *vnodes;
+	struct sheepdog_vnode_list_entry *entry;
+	int nr_vnodes;
+	int nr_zones;
 	int check_consistency;
 
 	req_end_t done;
@@ -109,7 +110,7 @@ struct cluster_info {
 
 	/* set after finishing the JOIN procedure */
 	int join_finished;
-	struct sd_node this_node;
+	struct sheepdog_node_list_entry this_node;
 
 	uint32_t epoch;
 	uint32_t status;
@@ -120,11 +121,11 @@ struct cluster_info {
 	 */
 	struct list_head leave_list;
 
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	int nr_nodes;
 
 	/* this array contains a list of ordered virtual nodes */
-	struct sd_vnode vnodes[SD_MAX_VNODES];
+	struct sheepdog_vnode_list_entry vnodes[SD_MAX_VNODES];
 	int nr_vnodes;
 
 	struct list_head pending_list;
@@ -136,11 +137,10 @@ struct cluster_info {
 	struct list_head consistent_obj_list;
 	struct list_head blocking_conn_list;
 
-	int nr_copies;
+	uint32_t nr_sobjs;
 
-	struct list_head request_queue;
-	struct list_head event_queue;
-	struct event_struct *cur_cevent;
+	struct list_head cpg_event_siblings;
+	struct cpg_event *cur_cevent;
 	int nr_outstanding_io;
 	int nr_outstanding_reqs;
 	unsigned int outstanding_data_size;
@@ -148,14 +148,12 @@ struct cluster_info {
 	uint32_t recovered_epoch;
 
 	int use_directio;
-	uint8_t async_flush;
 
-	struct work_queue *event_wqueue;
+	struct work_queue *cpg_wqueue;
 	struct work_queue *gateway_wqueue;
 	struct work_queue *io_wqueue;
 	struct work_queue *deletion_wqueue;
 	struct work_queue *recovery_wqueue;
-	struct work_queue *flush_wqueue;
 };
 
 struct siocb {
@@ -168,59 +166,20 @@ struct siocb {
 };
 
 struct store_driver {
-	struct list_head list;
-	const char *name;
+	const char *driver_name;
 	int (*init)(char *path);
 	int (*open)(uint64_t oid, struct siocb *, int create);
 	int (*write)(uint64_t oid, struct siocb *);
 	int (*read)(uint64_t oid, struct siocb *);
 	int (*close)(uint64_t oid, struct siocb *);
-	int (*format)(struct siocb *);
 	/* Operations in recovery */
 	int (*get_objlist)(struct siocb *);
-	int (*link)(uint64_t oid, struct siocb *, uint32_t tgt_epoch);
-	int (*atomic_put)(uint64_t oid, struct siocb *);
-	int (*begin_recover)(struct siocb *);
-	int (*end_recover)(struct siocb *);
-	/* Operations for snapshot */
-	int (*snapshot)(struct siocb *);
-	int (*cleanup)(struct siocb *);
-	int (*restore)(struct siocb *);
-	int (*get_snap_file)(struct siocb *);
+	int (*link)(uint64_t oid, struct siocb *, int tgt_epoch);
 };
 
-extern struct list_head store_drivers;
-#define add_store_driver(driver)                                 \
-static void __attribute__((constructor)) add_ ## driver(void) {  \
-	list_add(&driver.list, &store_drivers);                  \
-}
-
-static inline struct store_driver *find_store_driver(const char *name)
-{
-	struct store_driver *driver;
-
-	list_for_each_entry(driver, &store_drivers, list) {
-		if (strcmp(driver->name, name) == 0)
-			return driver;
-	}
-	return NULL;
-}
-
-struct objlist_cache {
-	struct rb_root root;
-	int cache_size;
-	pthread_rwlock_t lock;
-};
+extern void register_store_driver(struct store_driver *);
 
 extern struct cluster_info *sys;
-extern struct store_driver *sd_store;
-extern char *obj_path;
-extern char *mnt_path;
-extern char *jrnl_path;
-extern char *epoch_path;
-extern mode_t def_fmode;
-extern mode_t def_dmode;
-extern struct objlist_cache obj_list_cache;
 
 int create_listen_port(int port, void *data);
 
@@ -243,77 +202,77 @@ int get_vdi_attr(uint32_t epoch, struct
 		 uint32_t vid, uint32_t *attrid, int copies, uint64_t ctime,
 		 int write, int excl, int delete);
 
-int get_zones_nr_from(struct sd_node *nodes, int nr_nodes);
-struct vnode_info *get_vnode_info(void);
-void put_vnode_info(struct vnode_info *vnodes);
-
-struct sd_vnode *oid_to_vnode(struct vnode_info *vnode_info, uint64_t oid,
-		int copy_idx);
-int get_nr_copies(struct vnode_info *vnode_info);
-
+int get_zones_nr_from(struct sheepdog_node_list_entry *nodes, int nr_nodes);
+void setup_ordered_sd_vnode_list(struct request *req);
+int get_ordered_sd_vnode_list(struct sheepdog_vnode_list_entry **entries,
+			      int *nr_vnodes, int *nr_zones);
+void free_ordered_sd_vnode_list(struct sheepdog_vnode_list_entry *entries);
 int is_access_to_busy_objects(uint64_t oid);
+int is_access_local(struct sheepdog_vnode_list_entry *e, int nr_nodes,
+		    uint64_t oid, int copies);
 
 void resume_pending_requests(void);
 
-int create_cluster(int port, int64_t zone, int nr_vnodes);
+int create_cluster(int port, int64_t zone);
 int leave_cluster(void);
 
-void process_request_event_queues(void);
+void start_cpg_event_work(void);
 void do_io_request(struct work *work);
-int forward_write_obj_req(struct request *req);
+int write_object_local(uint64_t oid, char *data, unsigned int datalen,
+		       uint64_t offset, uint16_t flags, int copies,
+		       uint32_t epoch, int create);
+int read_object_local(uint64_t oid, char *data, unsigned int datalen,
+		      uint64_t offset, int copies, uint32_t epoch);
 
 int read_epoch(uint32_t *epoch, uint64_t *ctime,
-	       struct sd_node *entries, int *nr_entries);
+	       struct sheepdog_node_list_entry *entries, int *nr_entries);
 void do_cluster_request(struct work *work);
 
 int update_epoch_store(uint32_t epoch);
-int update_epoch_log(uint32_t epoch);
+int update_epoch_log(int epoch);
 
 int set_cluster_copies(uint8_t copies);
 int get_cluster_copies(uint8_t *copies);
 int set_cluster_flags(uint16_t flags);
 int get_cluster_flags(uint16_t *flags);
-int set_cluster_store(const char *name);
-int get_cluster_store(char *buf);
 
-int store_file_write(void *buffer, size_t len);
-void *store_file_read(void);
-int get_max_nr_copies_from(struct sd_node *entries, int nr);
+int store_create_and_write_obj(const struct sd_req *, struct sd_rsp *, void *);
+int store_write_obj(const struct sd_req *, struct sd_rsp *, void *);
+int store_read_obj(const struct sd_req *, struct sd_rsp *, void *);
+int store_remove_obj(const struct sd_req *, struct sd_rsp *, void *);
+
+#define NR_GW_WORKER_THREAD 4
+#define NR_IO_WORKER_THREAD 4
 
 int epoch_log_read(uint32_t epoch, char *buf, int len);
 int epoch_log_read_nr(uint32_t epoch, char *buf, int len);
 int epoch_log_read_remote(uint32_t epoch, char *buf, int len);
-uint32_t get_latest_epoch(void);
+int get_latest_epoch(void);
+int remove_epoch(int epoch);
 int set_cluster_ctime(uint64_t ctime);
 uint64_t get_cluster_ctime(void);
-int get_obj_list(const struct sd_list_req *, struct sd_list_rsp *, void *);
+int stat_sheep(uint64_t *store_size, uint64_t *store_free, uint32_t epoch);
+int get_obj_list(const struct sd_list_req *hdr, struct sd_list_rsp *rsp, void *data);
 
 int start_recovery(uint32_t epoch);
 void resume_recovery_work(void);
 int is_recoverying_oid(uint64_t oid);
-int node_in_recovery(void);
 
-int write_object(struct vnode_info *vnodes, uint32_t node_version,
+int write_object(struct sheepdog_vnode_list_entry *e,
+		 int vnodes, int zones, uint32_t node_version,
 		 uint64_t oid, char *data, unsigned int datalen,
 		 uint64_t offset, uint16_t flags, int nr, int create);
-int read_object(struct vnode_info *vnodes, uint32_t node_version,
+int read_object(struct sheepdog_vnode_list_entry *e,
+		int vnodes, int zones, uint32_t node_version,
 		uint64_t oid, char *data, unsigned int datalen,
 		uint64_t offset, int nr);
-int remove_object(struct vnode_info *vnodes, uint32_t node_version,
+int remove_object(struct sheepdog_vnode_list_entry *e,
+		  int vnodes, int zones, uint32_t node_version,
 		  uint64_t oid, int nr);
-int merge_objlist(uint64_t *list1, int nr_list1, uint64_t *list2, int nr_list2);
 
 void del_sheep_fd(int fd);
 int get_sheep_fd(uint8_t *addr, uint16_t port, int node_idx, uint32_t epoch);
 
-int rmdir_r(char *dir_path);
-
-int prealloc(int fd, uint32_t size);
-
-int init_objlist_cache(void);
-int objlist_cache_rb_remove(struct rb_root *root, uint64_t oid);
-int check_and_insert_objlist_cache(uint64_t oid);
-
 /* Operations */
 
 struct sd_op_template *get_sd_op(uint8_t opcode);
@@ -329,7 +288,7 @@ int do_process_main(struct sd_op_templat
 		    struct sd_rsp *rsp, void *data);
 
 /* Journal */
-struct jrnl_descriptor *jrnl_begin(const void *buf, size_t count, off_t offset,
+struct jrnl_descriptor *jrnl_begin(void *buf, size_t count, off_t offset,
 				   const char *path, const char *jrnl_dir);
 int jrnl_end(struct jrnl_descriptor * jd);
 int jrnl_recover(const char *jrnl_dir);
@@ -341,11 +300,6 @@ static inline int is_myself(uint8_t *add
 		port == sys->this_node.port;
 }
 
-static inline int vnode_is_local(struct sd_vnode *v)
-{
-	return is_myself(v->addr, v->port);
-}
-
 /* Cluster status/flag helper */
 
 static inline int sys_flag_nohalt(void)
@@ -403,46 +357,4 @@ static inline int sys_can_halt(void)
 	return sys_stat_ok() && !sys_flag_nohalt();
 }
 
-/* object_cache */
-/*
- * Object Cache ID
- *
- *  0 - 19 (20 bits): data object space
- *  20 - 27 (8 bits): reserved
- *  28 - 31 (4 bits): object type indentifier space
- */
-
-#define CACHE_VDI_SHIFT       31
-#define CACHE_VDI_BIT         (UINT32_C(1) << CACHE_VDI_SHIFT)
-
-struct object_cache {
-	uint32_t vid;
-	struct hlist_node hash;
-
-	struct list_head dirty_lists[2];
-	struct list_head *active_dirty_list;
-
-	struct rb_root dirty_trees[2];
-	struct rb_root *active_dirty_tree;
-
-	pthread_mutex_t lock;
-};
-
-struct object_cache_entry {
-	uint32_t idx;
-	struct rb_node rb;
-	struct list_head list;
-	int create;
-};
-
-struct object_cache *find_object_cache(uint32_t vid, int create);
-int object_cache_lookup(struct object_cache *oc, uint32_t index, int create);
-int object_cache_rw(struct object_cache *oc, uint32_t idx, struct request *);
-int object_cache_pull(struct object_cache *oc, uint32_t index);
-int object_cache_push(struct object_cache *oc);
-int object_cache_init(const char *p);
-int object_is_cached(uint64_t oid);
-void object_cache_delete(uint32_t vid);
-int object_cache_flush_and_delete(struct object_cache *oc);
-
 #endif
--- sheepdog-0.3.0.orig/sheep/cluster.h
+++ sheepdog-0.3.0/sheep/cluster.h
@@ -15,7 +15,6 @@
 #include <stdlib.h>
 #include <stdint.h>
 #include <inttypes.h>
-#include <arpa/inet.h>
 #include <memory.h>
 
 #include "sheepdog_proto.h"
@@ -32,6 +31,18 @@ enum cluster_join_result {
 				 * will leave the cluster (restart later). */
 };
 
+struct cdrv_handlers {
+	void (*join_handler)(struct sheepdog_node_list_entry *joined,
+			     struct sheepdog_node_list_entry *members,
+			     size_t nr_members, enum cluster_join_result result,
+			     void *opaque);
+	void (*leave_handler)(struct sheepdog_node_list_entry *left,
+			      struct sheepdog_node_list_entry *members,
+			      size_t nr_members);
+	void (*notify_handler)(struct sheepdog_node_list_entry *sender,
+			       void *msg, size_t msg_len);
+};
+
 struct cluster_driver {
 	const char *name;
 
@@ -42,23 +53,27 @@ struct cluster_driver {
 	 * may be used with the poll(2) to monitor cluster events.  On
 	 * error, returns -1.
 	 */
-	int (*init)(const char *option, uint8_t *myaddr);
+	int (*init)(struct cdrv_handlers *handlers, const char *option,
+		    uint8_t *myaddr);
 
 	/*
 	 * Join the cluster
 	 *
-	 * This function is used to join the cluster, and notifies a join
-	 * event to all the nodes.  The copy of 'opaque' is passed to
-	 * sd_check_join_cb() and sd_join_handler().
-	 *
-	 * sd_check_join_cb() is called on one of the nodes which already
+	 * This function is used to join the cluster, and notifies a
+	 * join event to all the nodes.  The copy of 'opaque' is
+	 * passed to check_join_cb() and join_handler().
+	 * check_join_cb() is called on one of the nodes which already
 	 * paticipate in the cluster.  If the content of 'opaque' is
-	 * changed in sd_check_join_cb(), the updated 'opaque' must be
-	 * passed to sd_join_handler().
+	 * changed in check_join_cb(), the updated 'opaque' must be
+	 * passed to join_handler().
 	 *
 	 * Returns zero on success, -1 on error
 	 */
-	int (*join)(struct sd_node *myself, void *opaque, size_t opaque_len);
+	int (*join)(struct sheepdog_node_list_entry *myself,
+		    enum cluster_join_result (*check_join_cb)(
+			    struct sheepdog_node_list_entry *joining,
+			    void *opaque),
+		    void *opaque, size_t opaque_len);
 
 	/*
 	 * Leave the cluster
@@ -73,14 +88,14 @@ struct cluster_driver {
 	/*
 	 * Notify a message to all nodes in the cluster
 	 *
-	 * This function sends 'msg' to all the nodes.  The notified messages
-	 * can be read through sd_notify_handler().
-	 *
-	 * If 'block_cb' is specified, block_cb() is called before 'msg' is
-	 * notified to all the nodes.  All the cluster events including this
-	 * notification are blocked until block_cb() returns or this blocking
-	 * node leaves the cluster.  The sheep daemon can sleep in block_cb(),
-	 * so this callback must be not called from the dispatch (main) thread.
+	 * This function sends 'msg' to all the nodes.  The notified
+	 * messages can be read through notify_handler() in
+	 * cdrv_handlers.  If 'block_cb' is specified, block_cb() is
+	 * called before 'msg' is notified to all the nodes.  All the
+	 * cluster events including this notification are blocked
+	 * until block_cb() returns or this blocking node leaves the
+	 * cluster.  The sheep daemon can sleep in block_cb(), so this
+	 * callback must be not called from the dispatch (main) thread.
 	 *
 	 * Returns zero on success, -1 on error
 	 */
@@ -142,54 +157,15 @@ static inline const char *get_cdrv_optio
 		return NULL;
 }
 
-static inline char *node_to_str(struct sd_node *id)
+static inline char *node_to_str(struct sheepdog_node_list_entry *id)
 {
 	static char str[256];
 	char name[256];
-	int af = AF_INET6;
-	uint8_t *addr = id->addr;
 
-	/* Find address family type */
-	if (addr[12]) {
-		int  oct_no = 0;
-		while (!addr[oct_no] && oct_no++ < 12)
-			;
-		if (oct_no == 12)
-			af = AF_INET;
-	}
-
-	snprintf(str, sizeof(str), "%s ip:%s port:%d",
-		(af == AF_INET) ? "IPv4" : "IPv6",
-		addr_to_str(name, sizeof(name), id->addr, 0), id->port);
+	snprintf(str, sizeof(str), "ip: %s, port: %d",
+		 addr_to_str(name, sizeof(name), id->addr, 0), id->port);
 
 	return str;
 }
 
-static inline struct sd_node *str_to_node(const char *str, struct sd_node *id)
-{
-	int port, af = AF_INET6;
-	char v[8], ip[256];
-
-	sscanf(str, "%s ip:%s port:%d", v, ip, &port);
-	id->port = port;
-
-	if (strcmp(v, "IPv4") == 0)
-		af = AF_INET;
-
-	if (!str_to_addr(af, ip, id->addr))
-		return NULL;
-
-	return id;
-}
-
-/* callbacks back into sheepdog from the cluster drivers */
-void sd_join_handler(struct sd_node *joined, struct sd_node *members,
-		size_t nr_members, enum cluster_join_result result,
-		void *opaque);
-void sd_leave_handler(struct sd_node *left, struct sd_node *members,
-		size_t nr_members);
-void sd_notify_handler(struct sd_node *sender, void *msg, size_t msg_len);
-enum cluster_join_result sd_check_join_cb(struct sd_node *joining,
-		void *opaque);
-
 #endif
--- sheepdog-0.3.0.orig/sheep/simple_store.c
+++ sheepdog-0.3.0/sheep/simple_store.c
@@ -26,53 +26,18 @@
 #include "util.h"
 
 
-static int def_store_flags = O_DIRECT | O_DSYNC | O_RDWR;
+extern char *obj_path;
 
-static int simple_store_write(uint64_t oid, struct siocb *iocb);
+extern mode_t def_fmode;
 
-static int simple_store_init(char *path)
-{
-	uint32_t epoch, latest_epoch;
-	DIR *dir;
-	struct dirent *dent;
-	char p[PATH_MAX];
-
-	eprintf("use simple store driver\n");
-	strcpy(p, path);
-	latest_epoch = get_latest_epoch();
-	for (epoch = 1; epoch <= latest_epoch; epoch++) {
-		snprintf(p, PATH_MAX, "%s/%08u", path, epoch);
-		dir = opendir(p);
-		if (!dir) {
-			if (errno == ENOENT)
-				continue;
-
-			vprintf(SDOG_ERR, "failed to open the epoch directory: %m\n");
-			return SD_RES_EIO;
-		}
-
-		vprintf(SDOG_INFO, "found the object directory %s\n", path);
-		while ((dent = readdir(dir))) {
-			uint64_t oid;
-
-			if (!strcmp(dent->d_name, ".") ||
-					!strcmp(dent->d_name, ".."))
-				continue;
-
-			oid = strtoull(dent->d_name, NULL, 16);
-			if (oid == 0 || oid == ULLONG_MAX)
-				continue;
+static int def_store_flags = O_DSYNC | O_RDWR;
 
-			if (!is_vdi_obj(oid))
-				continue;
+struct store_driver store;
 
-			vprintf(SDOG_DEBUG, "found the VDI object %" PRIx64 "\n", oid);
-
-			set_bit(oid_to_vid(oid), sys->vdi_inuse);
-		}
-		closedir(dir);
-	}
-	return SD_RES_SUCCESS;
+static int simple_store_init(char *path)
+{
+	eprintf("Use simple store driver\n");
+	return 0;
 }
 
 static int store_write_last_sector(uint64_t oid, struct siocb *iocb)
@@ -80,7 +45,6 @@ static int store_write_last_sector(uint6
 	const int size = SECTOR_SIZE;
 	char *buf = NULL;
 	int ret;
-	uint32_t length = iocb->length;
 
 	buf = valloc(size);
 	if (!buf) {
@@ -91,8 +55,8 @@ static int store_write_last_sector(uint6
 
 	iocb->buf = buf;
 	iocb->length = size;
-	iocb->offset = length - size;
-	ret = simple_store_write(oid, iocb);
+	iocb->offset = SD_DATA_OBJ_SIZE - size;
+	ret = store.write(oid, iocb);
 	free(buf);
 
 	return ret;
@@ -104,8 +68,8 @@ static int simple_store_open(uint64_t oi
 	int ret;
 	int flags = def_store_flags;
 
-	if (is_vdi_obj(oid))
-		flags &= ~O_DIRECT;
+	if (sys->use_directio && is_data_obj(oid))
+		flags |= O_DIRECT;
 
 	if (create)
 		flags |= O_CREAT | O_TRUNC;
@@ -136,7 +100,7 @@ static int simple_store_open(uint64_t oi
 		/*
 		 * Preallocate the whole object to get a better filesystem layout.
 		 */
-		ret = fallocate(iocb->fd, 0, 0, iocb->length);
+		ret = fallocate(iocb->fd, 0, 0, SD_DATA_OBJ_SIZE);
 		if (ret < 0) {
 			if (errno != ENOSYS && errno != EOPNOTSUPP) {
 				ret = SD_RES_EIO;
@@ -181,12 +145,13 @@ static int simple_store_close(uint64_t o
 	return SD_RES_SUCCESS;
 }
 
-static int get_epoch_obj_list(uint32_t epoch, uint64_t *objlist, int *nr)
+static int simple_store_get_objlist(struct siocb *siocb)
 {
 	struct strbuf buf = STRBUF_INIT;
+	int epoch = siocb->epoch;
+	uint64_t *objlist = (uint64_t *)siocb->buf;
 	DIR *dir;
 	struct dirent *d;
-	int length = 0;
 	int ret = SD_RES_SUCCESS;
 
 	strbuf_addf(&buf, "%s%08u/", obj_path, epoch);
@@ -198,6 +163,7 @@ static int get_epoch_obj_list(uint32_t e
 		ret = SD_RES_EIO;
 		goto out;
 	}
+
 	while ((d = readdir(dir))) {
 		uint64_t oid;
 		if (!strcmp(d->d_name, ".") || !strcmp(d->d_name, ".."))
@@ -207,58 +173,15 @@ static int get_epoch_obj_list(uint32_t e
 		if (oid == 0)
 			continue;
 
-		objlist[length++] = oid;
+		objlist[siocb->length++] = oid;
 	}
 	closedir(dir);
-	*nr = length;
 out:
 	strbuf_release(&buf);
 	return ret;
 }
 
-static int simple_store_get_objlist(struct siocb *siocb)
-{
-	uint64_t *objlist = (uint64_t*)siocb->buf;
-	uint64_t *buf;
-	uint32_t epoch;
-	int nr = 0, obj_nr = 0;
-	DIR *dir;
-	struct dirent *d;
-	int ret = SD_RES_SUCCESS, r;
-
-	dir = opendir(obj_path);
-	if (!dir) {
-		ret = SD_RES_EIO;
-		goto out;
-	}
-
-	buf = zalloc(1 << 22);
-	if (!buf) {
-		dprintf("no memory to allocate.\n");
-		ret = SD_RES_NO_MEM;
-		goto out;
-	}
-
-	while ((d = readdir(dir))) {
-		if (!strcmp(d->d_name, ".") || !strcmp(d->d_name, ".."))
-			continue;
-		epoch = strtoul(d->d_name, NULL, 16);
-		if (epoch == 0)
-			continue;
-
-		r = get_epoch_obj_list(epoch, buf, &obj_nr);
-		if (SD_RES_SUCCESS == r)
-			nr = merge_objlist(objlist, nr, buf, obj_nr);
-	}
-	closedir(dir);
-
-	siocb->length = nr;
-	free(buf);
-out:
-	return ret;
-}
-
-static int simple_store_link(uint64_t oid, struct siocb *iocb, uint32_t tgt_epoch)
+static int simple_store_link(uint64_t oid, struct siocb *iocb, int tgt_epoch)
 {
        char old[PATH_MAX], new[PATH_MAX];
 
@@ -276,70 +199,8 @@ static int simple_store_link(uint64_t oi
        return SD_RES_EIO;
 }
 
-static int simple_store_atomic_put(uint64_t oid, struct siocb *iocb)
-{
-	char path[PATH_MAX], tmp_path[PATH_MAX];
-	int flags = O_DSYNC | O_RDWR | O_CREAT;
-	int ret = SD_RES_EIO, epoch = iocb->epoch, fd;
-	uint32_t len = iocb->length;
-
-	snprintf(path, sizeof(path), "%s%08u/%016" PRIx64, obj_path,
-		 epoch, oid);
-	snprintf(tmp_path, sizeof(tmp_path), "%s%08u/%016" PRIx64 ".tmp",
-		 obj_path, epoch, oid);
-
-	fd = open(tmp_path, flags, def_fmode);
-	if (fd < 0) {
-		eprintf("failed to open %s: %m\n", tmp_path);
-		goto out;
-	}
-
-	ret = write(fd, iocb->buf, len);
-	if (ret != len) {
-		eprintf("failed to write object. %m\n");
-		ret = SD_RES_EIO;
-		goto out_close;
-	}
-
-
-	ret = rename(tmp_path, path);
-	if (ret < 0) {
-		eprintf("failed to rename %s to %s: %m\n", tmp_path, path);
-		ret = SD_RES_EIO;
-		goto out_close;
-	}
-	dprintf("%"PRIx64"\n", oid);
-	ret = SD_RES_SUCCESS;
-out_close:
-	close(fd);
-out:
-	return ret;
-}
-
-static int simple_store_format(struct siocb *iocb)
-{
-	char path[PATH_MAX];
-	unsigned epoch = iocb->epoch, ret, i;
-	const char name[] = "simple";
-
-	dprintf("epoch %u\n", epoch);
-	for (i = 1; i <= epoch; i++) {
-		snprintf(path, sizeof(path), "%s%08u", obj_path, i);
-		ret = rmdir_r(path);
-		if (ret && ret != -ENOENT) {
-			eprintf("failed to remove %s: %s\n", path, strerror(-ret));
-			return SD_RES_EIO;
-		}
-	}
-
-	if (set_cluster_store(name) < 0)
-		return SD_RES_EIO;
-
-	return SD_RES_SUCCESS;
-}
-
-struct store_driver simple_store = {
-	.name = "simple",
+struct store_driver store = {
+	.driver_name = "simple",
 	.init = simple_store_init,
 	.open = simple_store_open,
 	.write = simple_store_write,
@@ -347,8 +208,10 @@ struct store_driver simple_store = {
 	.close = simple_store_close,
 	.get_objlist = simple_store_get_objlist,
 	.link = simple_store_link,
-	.atomic_put = simple_store_atomic_put,
-	.format = simple_store_format,
 };
 
-add_store_driver(simple_store);
+void register_store_driver(struct store_driver *driver)
+{
+	store = *driver;
+	eprintf("Register %s store driver\n", store.driver_name);
+}
--- sheepdog-0.3.0.orig/sheep/vdi.c
+++ sheepdog-0.3.0/sheep/vdi.c
@@ -21,17 +21,17 @@ static int create_vdi_obj(uint32_t epoch
 			  uint32_t base_vid, uint32_t cur_vid, uint32_t copies,
 			  uint32_t snapid, int is_snapshot)
 {
-	struct vnode_info *vnode_info;
+	struct sheepdog_vnode_list_entry *entries = NULL;
 	/* we are not called concurrently */
 	struct sheepdog_inode *new = NULL, *base = NULL, *cur = NULL;
 	struct timeval tv;
-	int ret = SD_RES_NO_MEM;
+	int ret, nr_vnodes, nr_zones;
 	unsigned long block_size = SD_DATA_OBJ_SIZE;
-	int nr_copies;
 
 	new = zalloc(sizeof(*new));
 	if (!new) {
 		eprintf("failed to allocate memory\n");
+		ret = SD_RES_NO_MEM;
 		goto out;
 	}
 
@@ -39,6 +39,7 @@ static int create_vdi_obj(uint32_t epoch
 		base = zalloc(sizeof(*base));
 		if (!base) {
 			eprintf("failed to allocate memory\n");
+			ret = SD_RES_NO_MEM;
 			goto out;
 		}
 	}
@@ -47,23 +48,22 @@ static int create_vdi_obj(uint32_t epoch
 		cur = zalloc(SD_INODE_HEADER_SIZE);
 		if (!cur) {
 			eprintf("failed to allocate memory\n");
+			ret = SD_RES_NO_MEM;
 			goto out;
 		}
 	}
 
-	vnode_info = get_vnode_info();
-
-	nr_copies = get_nr_copies(vnode_info);
-	if (nr_copies > copies)
-		nr_copies = copies;
+	ret = get_ordered_sd_vnode_list(&entries, &nr_vnodes, &nr_zones);
+	if (ret != SD_RES_SUCCESS)
+		goto out;
 
 	if (base_vid) {
-		ret = read_object(vnode_info, epoch,
+		ret = read_object(entries, nr_vnodes, nr_zones, epoch,
 				  vid_to_vdi_oid(base_vid), (char *)base,
-				  sizeof(*base), 0, nr_copies);
+				  sizeof(*base), 0, copies);
 		if (ret != SD_RES_SUCCESS) {
 			ret = SD_RES_BASE_VDI_READ;
-			goto out_put_vnode_info;
+			goto out;
 		}
 	}
 
@@ -74,13 +74,13 @@ static int create_vdi_obj(uint32_t epoch
 			vprintf(SDOG_INFO, "tree snapshot %s %" PRIx32 " %" PRIx32 "\n",
 				name, cur_vid, base_vid);
 
-			ret = read_object(vnode_info, epoch,
+			ret = read_object(entries, nr_vnodes, nr_zones, epoch,
 					  vid_to_vdi_oid(cur_vid), (char *)cur,
-					  SD_INODE_HEADER_SIZE, 0, nr_copies);
+					  SD_INODE_HEADER_SIZE, 0, copies);
 			if (ret != SD_RES_SUCCESS) {
 				vprintf(SDOG_ERR, "failed\n");
 				ret = SD_RES_BASE_VDI_READ;
-				goto out_put_vnode_info;
+				goto out;
 			}
 
 			cur->snap_ctime = (uint64_t) tv.tv_sec << 32 | tv.tv_usec * 1000;
@@ -112,41 +112,39 @@ static int create_vdi_obj(uint32_t epoch
 
 		if (i == ARRAY_SIZE(base->child_vdi_id)) {
 			ret = SD_RES_NO_BASE_VDI;
-			goto out_put_vnode_info;
+			goto out;
 		}
 	}
 
 	if (is_snapshot && cur_vid != base_vid) {
-		ret = write_object(vnode_info, epoch,
+		ret = write_object(entries, nr_vnodes, nr_zones, epoch,
 				   vid_to_vdi_oid(cur_vid), (char *)cur,
-				   SD_INODE_HEADER_SIZE, 0, 0, nr_copies, 0);
+				   SD_INODE_HEADER_SIZE, 0, 0, copies, 0);
 		if (ret != 0) {
 			vprintf(SDOG_ERR, "failed\n");
 			ret = SD_RES_BASE_VDI_READ;
-			goto out_put_vnode_info;
+			goto out;
 		}
 	}
 
 	if (base_vid) {
-		ret = write_object(vnode_info, epoch,
+		ret = write_object(entries, nr_vnodes, nr_zones, epoch,
 				   vid_to_vdi_oid(base_vid), (char *)base,
-				   SD_INODE_HEADER_SIZE, 0, 0, nr_copies, 0);
+				   SD_INODE_HEADER_SIZE, 0, 0, copies, 0);
 		if (ret != 0) {
 			vprintf(SDOG_ERR, "failed\n");
 			ret = SD_RES_BASE_VDI_WRITE;
-			goto out_put_vnode_info;
+			goto out;
 		}
 	}
 
-	ret = write_object(vnode_info, epoch,
+	ret = write_object(entries, nr_vnodes, nr_zones, epoch,
 			   vid_to_vdi_oid(new_vid), (char *)new, sizeof(*new),
-			   0, 0, nr_copies, 1);
+			   0, 0, copies, 1);
 	if (ret != 0)
 		ret = SD_RES_VDI_WRITE;
-
-out_put_vnode_info:
-	put_vnode_info(vnode_info);
 out:
+	free_ordered_sd_vnode_list(entries);
 	free(new);
 	free(cur);
 	free(base);
@@ -156,31 +154,36 @@ out:
 static int find_first_vdi(uint32_t epoch, unsigned long start, unsigned long end,
 			  char *name, char *tag, uint32_t snapid, uint32_t *vid,
 			  unsigned long *deleted_nr, uint32_t *next_snap,
-			  unsigned int *inode_nr_copies, uint64_t *ctime)
+			  unsigned int *nr_copies, uint64_t *ctime)
 {
-	struct vnode_info *vnode_info;
+	struct sheepdog_vnode_list_entry *entries = NULL;
 	struct sheepdog_inode *inode = NULL;
 	unsigned long i;
-	int nr_copies;
-	int ret = SD_RES_NO_MEM;
-	int vdi_found = 0;
+	int nr_vnodes, nr_zones, nr_reqs;
+	int ret, vdi_found = 0;
 
 	inode = malloc(SD_INODE_HEADER_SIZE);
 	if (!inode) {
 		eprintf("failed to allocate memory\n");
+		ret = SD_RES_NO_MEM;
 		goto out;
 	}
 
-	vnode_info = get_vnode_info();
-	nr_copies = get_nr_copies(vnode_info);
+	ret = get_ordered_sd_vnode_list(&entries, &nr_vnodes, &nr_zones);
+	if (ret != SD_RES_SUCCESS)
+		goto out;
+
+	nr_reqs = sys->nr_sobjs;
+	if (nr_reqs > nr_zones)
+		nr_reqs = nr_zones;
 
 	for (i = start; i >= end; i--) {
-		ret = read_object(vnode_info, epoch,
+		ret = read_object(entries, nr_vnodes, nr_zones, epoch,
 				  vid_to_vdi_oid(i), (char *)inode,
-				  SD_INODE_HEADER_SIZE, 0, nr_copies);
+				  SD_INODE_HEADER_SIZE, 0, nr_reqs);
 		if (ret != SD_RES_SUCCESS) {
 			ret = SD_RES_EIO;
-			goto out_put_vnode_info;
+			goto out;
 		}
 
 		if (inode->name[0] == '\0') {
@@ -198,11 +201,11 @@ static int find_first_vdi(uint32_t epoch
 
 			*next_snap = inode->snap_id + 1;
 			*vid = inode->vdi_id;
-			*inode_nr_copies = inode->nr_copies;
+			*nr_copies = inode->nr_copies;
 			if (ctime)
 				*ctime = inode->ctime;
 			ret = SD_RES_SUCCESS;
-			goto out_put_vnode_info;
+			goto out;
 		}
 	}
 
@@ -210,14 +213,14 @@ static int find_first_vdi(uint32_t epoch
 		ret = SD_RES_NO_TAG;
 	else
 		ret = SD_RES_NO_VDI;
-
-out_put_vnode_info:
-	put_vnode_info(vnode_info);
-	free(inode);
 out:
+	free(inode);
+	free_ordered_sd_vnode_list(entries);
+
 	return ret;
 }
 
+
 static int do_lookup_vdi(uint32_t epoch, char *name, int namelen, uint32_t *vid,
 			 char *tag, uint32_t snapid, uint32_t *next_snapid,
 			 unsigned long *right_nr,  unsigned long *deleted_nr,
@@ -323,8 +326,8 @@ int add_vdi(uint32_t epoch, char *data,
 	if (!copies) {
 		vprintf(SDOG_WARNING,
 			"using default replication level of %d copies\n",
-			sys->nr_copies);
-		copies = sys->nr_copies;
+			sys->nr_sobjs);
+		copies = sys->nr_sobjs;
 	}
 
 	ret = create_vdi_obj(epoch, name, *new_vid, size, base_vid, cur_vid, copies,
@@ -342,6 +345,16 @@ int del_vdi(uint32_t epoch, char *data,
 	uint32_t dummy0;
 	unsigned long dummy1, dummy2;
 	int ret;
+	struct sheepdog_vnode_list_entry *entries = NULL;
+	int nr_vnodes, nr_zones, nr_reqs;
+	struct sheepdog_inode *inode = NULL;
+
+	inode = malloc(SD_INODE_HEADER_SIZE);
+	if (!inode) {
+		eprintf("failed to allocate memory\n");
+		ret = SD_RES_NO_MEM;
+		goto out;
+	}
 
 	if (data_len == SD_MAX_VDI_LEN + SD_MAX_VDI_TAG_LEN)
 		tag = data + SD_MAX_VDI_LEN;
@@ -357,8 +370,37 @@ int del_vdi(uint32_t epoch, char *data,
 	if (ret != SD_RES_SUCCESS)
 		goto out;
 
+	ret = get_ordered_sd_vnode_list(&entries, &nr_vnodes, &nr_zones);
+	if (ret != SD_RES_SUCCESS)
+		goto out;
+
+	nr_reqs = sys->nr_sobjs;
+	if (nr_reqs > nr_zones)
+		nr_reqs = nr_zones;
+
+	ret = read_object(entries, nr_vnodes, nr_zones, epoch,
+			  vid_to_vdi_oid(*vid), (char *)inode,
+			  SD_INODE_HEADER_SIZE, 0, nr_reqs);
+	if (ret != SD_RES_SUCCESS) {
+		ret = SD_RES_EIO;
+		goto out;
+	}
+
+	memset(inode->name, 0, sizeof(inode->name));
+
+	ret = write_object(entries, nr_vnodes, nr_zones, epoch,
+			   vid_to_vdi_oid(*vid), (char *)inode,
+			   SD_INODE_HEADER_SIZE, 0, 0, nr_reqs, 0);
+	if (ret != 0) {
+		ret = SD_RES_EIO;
+		goto out;
+	}
+
 	ret = start_deletion(*vid, epoch);
 out:
+	free(inode);
+	free_ordered_sd_vnode_list(entries);
+
 	return ret;
 }
 
@@ -383,61 +425,19 @@ struct deletion_work {
 	uint32_t vid;
 
 	int count;
-	uint32_t *buf;
-
-	struct vnode_info *vnodes;
-	int delete_error;
+	char *buf;
 };
 
 static LIST_HEAD(deletion_work_list);
 
-static int delete_inode(struct deletion_work *dw)
-{
-	struct sheepdog_inode *inode = NULL;
-	int ret = SD_RES_SUCCESS;
-	int nr_copies;
-
-	inode = zalloc(sizeof(*inode));
-	if (!inode) {
-		eprintf("no memory to allocate inode.\n");
-		goto out;
-	}
-
-	nr_copies = get_nr_copies(dw->vnodes);
-
-	ret = read_object(dw->vnodes, dw->epoch, vid_to_vdi_oid(dw->vid),
-			  (char *)inode, SD_INODE_HEADER_SIZE, 0, nr_copies);
-	if (ret != SD_RES_SUCCESS) {
-		ret = SD_RES_EIO;
-		goto out;
-	}
-
-	if (dw->delete_error)
-		inode->vdi_size = 0;
-	else
-		memset(inode->name, 0, sizeof(inode->name));
-
-	ret = write_object(dw->vnodes, dw->epoch, vid_to_vdi_oid(dw->vid),
-			   (char *)inode, SD_INODE_HEADER_SIZE, 0, 0,
-			   nr_copies, 0);
-	if (ret != 0) {
-		ret = SD_RES_EIO;
-		goto out;
-	}
-
-out:
-	free(inode);
-	return ret;
-}
-
-
 static void delete_one(struct work *work)
 {
 	struct deletion_work *dw = container_of(work, struct deletion_work, work);
-	uint32_t vdi_id = *(dw->buf + dw->count - dw->done - 1);
+	uint32_t vdi_id = *(((uint32_t *)dw->buf) + dw->count - dw->done - 1);
+	struct sheepdog_vnode_list_entry *entries = NULL;
+	int nr_vnodes, nr_zones;
 	int ret, i;
 	struct sheepdog_inode *inode = NULL;
-	int nr_copies;
 
 	eprintf("%d %d, %16x\n", dw->done, dw->count, vdi_id);
 
@@ -447,11 +447,18 @@ static void delete_one(struct work *work
 		goto out;
 	}
 
-	nr_copies = get_nr_copies(dw->vnodes);
+	/*
+	 * FIXME: can't use get_ordered_sd_node_list() here since this
+	 * is called in threads and not serialized with cpg_event so
+	 * we can't access to epoch and sd_node_list safely.
+	 */
+	ret = get_ordered_sd_vnode_list(&entries, &nr_vnodes, &nr_zones);
+	if (ret != SD_RES_SUCCESS)
+		goto out;
 
-	ret = read_object(dw->vnodes, dw->epoch, vid_to_vdi_oid(vdi_id),
-			  (void *)inode, sizeof(*inode),
-			  0, nr_copies);
+	ret = read_object(entries, nr_vnodes, nr_zones, dw->epoch,
+			  vid_to_vdi_oid(vdi_id), (void *)inode, sizeof(*inode),
+			  0, sys->nr_sobjs);
 
 	if (ret != SD_RES_SUCCESS) {
 		eprintf("cannot find VDI object\n");
@@ -462,28 +469,12 @@ static void delete_one(struct work *work
 		if (!inode->data_vdi_id[i])
 			continue;
 
-		if (inode->data_vdi_id[i] != inode->vdi_id) {
-			dprintf("object %" PRIx64 " is base's data, would not be deleted.\n",
-					vid_to_data_oid(inode->data_vdi_id[i], i));
-			continue;
-		}
-
-		ret = remove_object(dw->vnodes, dw->epoch,
+		remove_object(entries, nr_vnodes, nr_zones, dw->epoch,
 			      vid_to_data_oid(inode->data_vdi_id[i], i),
-			      nr_copies);
-
-		if (ret != SD_RES_SUCCESS)
-			dw->delete_error = 1;
-		else
-			inode->data_vdi_id[i] = 0;
-	}
-
-	if (dw->delete_error) {
-		write_object(dw->vnodes, dw->epoch, vid_to_vdi_oid(vdi_id),
-			     (void *)inode, sizeof(*inode), 0, 0, nr_copies, 0);
+			      inode->nr_copies);
 	}
-
 out:
+	free_ordered_sd_vnode_list(entries);
 	free(inode);
 }
 
@@ -497,11 +488,8 @@ static void delete_one_done(struct work
 		return;
 	}
 
-	delete_inode(dw);
-
 	list_del(&dw->dw_siblings);
 
-	put_vnode_info(dw->vnodes);
 	free(dw->buf);
 	free(dw);
 
@@ -513,15 +501,14 @@ static void delete_one_done(struct work
 	}
 }
 
-static int fill_vdi_list(struct deletion_work *dw, uint32_t root_vid)
+static int fill_vdi_list(struct deletion_work *dw,
+			 struct sheepdog_vnode_list_entry *entries,
+			 int nr_vnodes, int nr_zones, uint32_t root_vid)
 {
 	int ret, i;
 	struct sheepdog_inode *inode = NULL;
 	int done = dw->count;
 	uint32_t vid;
-	int nr_copies;
-
-	nr_copies = get_nr_copies(dw->vnodes);
 
 	inode = malloc(SD_INODE_HEADER_SIZE);
 	if (!inode) {
@@ -529,29 +516,29 @@ static int fill_vdi_list(struct deletion
 		goto err;
 	}
 
-	dw->buf[dw->count++] = root_vid;
+	((uint32_t *)dw->buf)[dw->count++] = root_vid;
 again:
-	vid = dw->buf[done++];
-	ret = read_object(dw->vnodes, dw->epoch, vid_to_vdi_oid(vid),
-			  (char *)inode, SD_INODE_HEADER_SIZE, 0,
-			  nr_copies);
+	vid = ((uint32_t *)dw->buf)[done++];
+	ret = read_object(entries, nr_vnodes, nr_zones, dw->epoch,
+			  vid_to_vdi_oid(vid), (char *)inode,
+			  SD_INODE_HEADER_SIZE, 0, sys->nr_sobjs);
 
 	if (ret != SD_RES_SUCCESS) {
 		eprintf("cannot find VDI object\n");
 		goto err;
 	}
 
-	if (inode->name[0] != '\0' && vid != dw->vid)
+	if (inode->name[0] != '\0')
 		goto out;
 
 	for (i = 0; i < ARRAY_SIZE(inode->child_vdi_id); i++) {
 		if (!inode->child_vdi_id[i])
 			continue;
 
-		dw->buf[dw->count++] = inode->child_vdi_id[i];
+		((uint32_t *)dw->buf)[dw->count++] = inode->child_vdi_id[i];
 	}
 
-	if (dw->buf[done])
+	if (((uint32_t *)dw->buf)[done])
 		goto again;
 err:
 	free(inode);
@@ -561,12 +548,12 @@ out:
 	return 1;
 }
 
-static uint64_t get_vdi_root(struct vnode_info *vnode_info, uint32_t epoch,
-		uint32_t vid)
+static uint64_t get_vdi_root(struct sheepdog_vnode_list_entry *entries,
+			     int nr_vnodes, int nr_zones, uint32_t epoch,
+			     uint32_t vid)
 {
 	int ret;
 	struct sheepdog_inode *inode = NULL;
-	int nr_copies = get_nr_copies(vnode_info);
 
 	inode = malloc(SD_INODE_HEADER_SIZE);
 	if (!inode) {
@@ -575,16 +562,9 @@ static uint64_t get_vdi_root(struct vnod
 		goto out;
 	}
 next:
-	ret = read_object(vnode_info, epoch, vid_to_vdi_oid(vid), (char *)inode,
-			  SD_INODE_HEADER_SIZE, 0, nr_copies);
-
-	if (vid == inode->vdi_id && inode->snap_id == 1
-			&& inode->parent_vdi_id != 0
-			&& !inode->snap_ctime) {
-		dprintf("vdi %" PRIx32 " is a cloned vdi.\n", vid);
-		/* current vdi is a cloned vdi */
-		goto out;
-	}
+	ret = read_object(entries, nr_vnodes, nr_zones, epoch,
+			  vid_to_vdi_oid(vid), (char *)inode,
+			  SD_INODE_HEADER_SIZE, 0, sys->nr_sobjs);
 
 	if (ret != SD_RES_SUCCESS) {
 		eprintf("cannot find VDI object\n");
@@ -607,17 +587,21 @@ out:
 int start_deletion(uint32_t vid, uint32_t epoch)
 {
 	struct deletion_work *dw = NULL;
-	int ret = SD_RES_NO_MEM;
+	struct sheepdog_vnode_list_entry *entries = NULL;
+	int nr_vnodes, nr_zones, ret;
 	uint32_t root_vid;
 
 	dw = zalloc(sizeof(struct deletion_work));
-	if (!dw)
+	if (!dw) {
+		ret = SD_RES_NO_MEM;
 		goto err;
+	}
 
-	/* buf is to store vdi id of every object */
-	dw->buf = zalloc(SD_INODE_SIZE - SD_INODE_HEADER_SIZE);
-	if (!dw->buf)
+	dw->buf = zalloc(1 << 20); /* FIXME: handle larger buffer */
+	if (!dw->buf) {
+		ret = SD_RES_NO_MEM;
 		goto err;
+	}
 
 	dw->count = 0;
 	dw->vid = vid;
@@ -626,21 +610,19 @@ int start_deletion(uint32_t vid, uint32_
 	dw->work.fn = delete_one;
 	dw->work.done = delete_one_done;
 
-	dw->vnodes = get_vnode_info();
+	ret = get_ordered_sd_vnode_list(&entries, &nr_vnodes, &nr_zones);
+	if (ret != SD_RES_SUCCESS)
+		goto err;
 
-	root_vid = get_vdi_root(dw->vnodes, dw->epoch, dw->vid);
+	root_vid = get_vdi_root(entries, nr_vnodes, nr_zones, dw->epoch, dw->vid);
 	if (!root_vid) {
 		ret = SD_RES_EIO;
 		goto err;
 	}
 
-	ret = fill_vdi_list(dw, root_vid);
-	if (ret) {
-		dprintf("snapshot chain has valid vdi, "
-				"just mark vdi %" PRIx32 " as deleted.\n", dw->vid);
-		delete_inode(dw);
+	ret = fill_vdi_list(dw, entries, nr_vnodes, nr_zones, root_vid);
+	if (ret)
 		return SD_RES_SUCCESS;
-	}
 
 	dprintf("%d\n", dw->count);
 
@@ -655,8 +637,11 @@ int start_deletion(uint32_t vid, uint32_
 	list_add_tail(&dw->dw_siblings, &deletion_work_list);
 	queue_work(sys->deletion_wqueue, &dw->work);
 out:
+	free_ordered_sd_vnode_list(entries);
+
 	return SD_RES_SUCCESS;
 err:
+	free_ordered_sd_vnode_list(entries);
 	if (dw)
 		free(dw->buf);
 	free(dw);
@@ -666,22 +651,19 @@ err:
 
 int get_vdi_attr(uint32_t epoch, struct sheepdog_vdi_attr *vattr, int data_len,
 		 uint32_t vid, uint32_t *attrid, int copies, uint64_t ctime,
-		 int wr, int excl, int delete)
+		 int write, int excl, int delete)
 {
-	struct vnode_info *vnode_info = NULL;
+	struct sheepdog_vnode_list_entry *entries = NULL;
 	struct sheepdog_vdi_attr tmp_attr;
 	uint64_t oid, hval;
 	uint32_t end;
-	int nr_copies;
-	int ret;
+	int ret, nr_zones, nr_vnodes;
 
 	vattr->ctime = ctime;
 
-	vnode_info = get_vnode_info();
-
-	nr_copies = get_nr_copies(vnode_info);
-	if (nr_copies > copies)
-		nr_copies = copies;
+	ret = get_ordered_sd_vnode_list(&entries, &nr_vnodes, &nr_zones);
+	if (ret != SD_RES_SUCCESS)
+		goto out;
 
 	/* we cannot include value_len for calculating the hash value */
 	hval = fnv_64a_buf(vattr->name, sizeof(vattr->name), FNV1A_64_INIT);
@@ -693,22 +675,21 @@ int get_vdi_attr(uint32_t epoch, struct
 	end = *attrid - 1;
 	while (*attrid != end) {
 		oid = vid_to_attr_oid(vid, *attrid);
-		ret = read_object(vnode_info, epoch, oid, (char *)&tmp_attr,
-				  sizeof(tmp_attr), 0, nr_copies);
+		ret = read_object(entries, nr_vnodes, nr_zones, epoch, oid, (char *)&tmp_attr,
+				  sizeof(tmp_attr), 0, copies);
 
-		if (ret == SD_RES_NO_OBJ && wr) {
-			ret = write_object(vnode_info, epoch, oid,
-					   (char *)vattr, data_len, 0, 0,
-					   nr_copies, 1);
+		if (ret == SD_RES_NO_OBJ && write) {
+			ret = write_object(entries, nr_vnodes, nr_zones, epoch, oid,
+					   (char *)vattr, data_len, 0, 0, copies, 1);
 			if (ret)
 				ret = SD_RES_EIO;
 			else
 				ret = SD_RES_SUCCESS;
-			goto out_put_vnode_info;
+			goto out;
 		}
 
 		if (ret != SD_RES_SUCCESS)
-			goto out_put_vnode_info;
+			return ret;
 
 		/* compare attribute header */
 		if (strcmp(tmp_attr.name, vattr->name) == 0 &&
@@ -718,19 +699,18 @@ int get_vdi_attr(uint32_t epoch, struct
 			if (excl)
 				ret = SD_RES_VDI_EXIST;
 			else if (delete) {
-				ret = write_object(vnode_info,
+				ret = write_object(entries, nr_vnodes, nr_zones,
 						   epoch, oid, (char *)"", 1,
 						   offsetof(struct sheepdog_vdi_attr, name),
-						   0, nr_copies, 0);
+						   0, copies, 0);
 				if (ret)
 					ret = SD_RES_EIO;
 				else
 					ret = SD_RES_SUCCESS;
-			} else if (wr) {
-				ret = write_object(vnode_info,
+			} else if (write) {
+				ret = write_object(entries, nr_vnodes, nr_zones,
 						   epoch, oid, (char *)vattr,
-						   SD_ATTR_OBJ_SIZE, 0, 0,
-						   nr_copies, 0);
+						   SD_ATTR_OBJ_SIZE, 0, 0, copies, 0);
 
 				if (ret)
 					ret = SD_RES_EIO;
@@ -738,7 +718,7 @@ int get_vdi_attr(uint32_t epoch, struct
 					ret = SD_RES_SUCCESS;
 			} else
 				ret = SD_RES_SUCCESS;
-			goto out_put_vnode_info;
+			goto out;
 		}
 
 		(*attrid)++;
@@ -746,8 +726,8 @@ int get_vdi_attr(uint32_t epoch, struct
 
 	dprintf("there is no space for new VDIs\n");
 	ret = SD_RES_FULL_VDI;
+out:
+	free_ordered_sd_vnode_list(entries);
 
-out_put_vnode_info:
-	put_vnode_info(vnode_info);
 	return ret;
 }
--- sheepdog-0.3.0.orig/sheep/group.c
+++ sheepdog-0.3.0/sheep/group.c
@@ -8,7 +8,6 @@
  * You should have received a copy of the GNU General Public License
  * along with this program. If not, see <http://www.gnu.org/licenses/>.
  */
-#include <assert.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <unistd.h>
@@ -24,24 +23,19 @@
 #include "logger.h"
 #include "work.h"
 #include "cluster.h"
+#include "coroutine.h"
 
 static int cdrv_fd;
+static struct coroutine *cdrv_co;
 
 struct node {
-	struct sd_node ent;
+	struct sheepdog_node_list_entry ent;
 	struct list_head list;
 };
 
-struct vnode_info {
-	struct sd_vnode entries[SD_MAX_VNODES];
-	int nr_vnodes;
-	int nr_zones;
-	int refcnt;
-};
-
 struct join_message {
 	uint8_t proto_ver;
-	uint8_t nr_copies;
+	uint8_t nr_sobjs;
 	uint16_t nr_nodes;
 	uint16_t nr_leave_nodes;
 	uint16_t cluster_flags;
@@ -50,10 +44,10 @@ struct join_message {
 	uint64_t ctime;
 	uint32_t result;
 	uint8_t inc_epoch; /* set non-zero when we increment epoch of all nodes */
-	uint8_t store[STORE_LEN];
+	uint8_t pad[3];
 	union {
-		struct sd_node nodes[0];
-		struct sd_node leave_nodes[0];
+		struct sheepdog_node_list_entry nodes[0];
+		struct sheepdog_node_list_entry leave_nodes[0];
 	};
 };
 
@@ -64,30 +58,30 @@ struct vdi_op_message {
 };
 
 struct work_notify {
-	struct event_struct cev;
+	struct cpg_event cev;
 
-	struct sd_node sender;
+	struct sheepdog_node_list_entry sender;
 
 	struct request *req;
 	void *msg;
 };
 
 struct work_join {
-	struct event_struct cev;
+	struct cpg_event cev;
 
-	struct sd_node *member_list;
+	struct sheepdog_node_list_entry *member_list;
 	size_t member_list_entries;
-	struct sd_node joined;
+	struct sheepdog_node_list_entry joined;
 
 	struct join_message *jm;
 };
 
 struct work_leave {
-	struct event_struct cev;
+	struct cpg_event cev;
 
-	struct sd_node *member_list;
+	struct sheepdog_node_list_entry *member_list;
 	size_t member_list_entries;
-	struct sd_node left;
+	struct sheepdog_node_list_entry left;
 };
 
 #define print_node_list(nodes, nr_nodes)			\
@@ -103,8 +97,7 @@ struct work_leave {
 	}							\
 })
 
-static int event_running;
-static struct vnode_info *current_vnode_info;
+static int cpg_event_running;
 
 static size_t get_join_message_size(struct join_message *jm)
 {
@@ -113,97 +106,100 @@ static size_t get_join_message_size(stru
 	return sizeof(*jm) + jm->nr_nodes * sizeof(jm->nodes[0]);
 }
 
-int get_zones_nr_from(struct sd_node *nodes, int nr_nodes)
+int get_zones_nr_from(struct sheepdog_node_list_entry *nodes, int nr_nodes)
 {
 	int nr_zones = 0, i, j;
 	uint32_t zones[SD_MAX_REDUNDANCY];
 
 	for (i = 0; i < nr_nodes; i++) {
-		/*
-		 * Only count zones that actually store data, pure gateways
-		 * don't contribute to the redundancy level.
-		 */
-		if (!nodes[i].nr_vnodes)
-			continue;
-
 		for (j = 0; j < nr_zones; j++) {
 			if (nodes[i].zone == zones[j])
 				break;
 		}
+		if (j == nr_zones)
+			zones[nr_zones++] = nodes[i].zone;
 
-		if (j == nr_zones) {
-			zones[nr_zones] = nodes[i].zone;
-			if (++nr_zones == ARRAY_SIZE(zones))
-				break;
-		}
+		if (nr_zones == ARRAY_SIZE(zones))
+			break;
 	}
 
 	return nr_zones;
 }
 
-/*
- * If we have less zones available than the desired redundancy we have to do
- * with nr_zones copies, sorry.
- *
- * Note that you generally want to use get_nr_copies below, as it uses the
- * current vnode state snapshot instead of global data.
- */
-int get_max_nr_copies_from(struct sd_node *nodes, int nr_nodes)
-{
-	return min((int)sys->nr_copies, get_zones_nr_from(nodes, nr_nodes));
-}
-
-struct vnode_info *get_vnode_info(void)
-{
-	assert(current_vnode_info);
-	current_vnode_info->refcnt++;
-	return current_vnode_info;
-}
+struct vnodes_cache {
+	struct sheepdog_vnode_list_entry vnodes[SD_MAX_VNODES];
+	int nr_vnodes;
+	int nr_zones;
+	uint32_t epoch;
 
-void put_vnode_info(struct vnode_info *vnodes)
-{
-	if (vnodes && --vnodes->refcnt == 0)
-		free(vnodes);
-}
+	int refcnt;
+	struct list_head list;
+};
 
-struct sd_vnode *oid_to_vnode(struct vnode_info *vnode_info, uint64_t oid,
-		int copy_idx)
+int get_ordered_sd_vnode_list(struct sheepdog_vnode_list_entry **entries,
+			      int *nr_vnodes, int *nr_zones)
 {
-	int n;
-
-	n = obj_to_sheep(vnode_info->entries, vnode_info->nr_vnodes,
-			 oid, copy_idx);
-	return &vnode_info->entries[n];
-}
+	static LIST_HEAD(vnodes_list);
+	struct vnodes_cache *cache;
 
+	list_for_each_entry(cache, &vnodes_list, list) {
+		if (cache->epoch == sys->epoch) {
+			*entries = cache->vnodes;
+			*nr_vnodes = cache->nr_vnodes;
+			*nr_zones = cache->nr_zones;
+			cache->refcnt++;
 
-static int update_vnode_info(void)
-{
-	struct vnode_info *vnode_info;
+			return SD_RES_SUCCESS;
+		}
+	}
 
-	vnode_info = zalloc(sizeof(*vnode_info));
-	if (!vnode_info) {
+	cache = zalloc(sizeof(*cache));
+	if (!cache) {
 		eprintf("failed to allocate memory\n");
-		return 1;
+		*entries = NULL;
+		return SD_RES_NO_MEM;
 	}
 
-	vnode_info->nr_vnodes = nodes_to_vnodes(sys->nodes, sys->nr_nodes,
-						vnode_info->entries);
-	vnode_info->nr_zones = get_zones_nr_from(sys->nodes, sys->nr_nodes);
-	vnode_info->refcnt = 1;
+	cache->nr_zones = get_zones_nr_from(sys->nodes, sys->nr_nodes);
+	memcpy(cache->vnodes, sys->vnodes, sizeof(sys->vnodes[0]) * sys->nr_vnodes);
+	cache->nr_vnodes = sys->nr_vnodes;
+	cache->epoch = sys->epoch;
+	cache->refcnt++;
 
-	put_vnode_info(current_vnode_info);
-	current_vnode_info = vnode_info;
-	return 0;
+	*entries = cache->vnodes;
+	*nr_vnodes = cache->nr_vnodes;
+	*nr_zones = cache->nr_zones;
+
+	list_add(&cache->list, &vnodes_list);
+
+	return SD_RES_SUCCESS;
 }
 
-/*
- * If we have less zones available than the desired redundancy we have to do
- * with nr_zones copies, sorry.
- */
-int get_nr_copies(struct vnode_info *vnode_info)
+void free_ordered_sd_vnode_list(struct sheepdog_vnode_list_entry *entries)
 {
-	return min(vnode_info->nr_zones, sys->nr_copies);
+	struct vnodes_cache *cache;
+
+	if (!entries)
+		return;
+
+	cache = container_of(entries, struct vnodes_cache, vnodes[0]);
+	if (--cache->refcnt == 0) {
+		list_del(&cache->list);
+		free(cache);
+	}
+}
+
+void setup_ordered_sd_vnode_list(struct request *req)
+{
+	int res;
+
+	if (req->entry)
+		free_ordered_sd_vnode_list(req->entry);
+
+	res = get_ordered_sd_vnode_list(&req->entry, &req->nr_vnodes,
+					&req->nr_zones);
+	if (res != SD_RES_SUCCESS)
+		panic("unrecoverable error\n");
 }
 
 static void do_cluster_op(void *arg)
@@ -211,16 +207,10 @@ static void do_cluster_op(void *arg)
 	struct vdi_op_message *msg = arg;
 	int ret;
 	struct request *req;
-	void *data;
 
 	req = list_first_entry(&sys->pending_list, struct request, pending_list);
-
-	if (has_process_main(req->op))
-		data = msg->data;
-	else
-		data = req->data;
 	ret = do_process_work(req->op, (const struct sd_req *)&msg->req,
-			      (struct sd_rsp *)&msg->rsp, data);
+			      (struct sd_rsp *)&msg->rsp, req->data);
 
 	msg->rsp.result = ret;
 }
@@ -234,10 +224,10 @@ void do_cluster_request(struct work *wor
 
 	eprintf("%p %x\n", req, hdr->opcode);
 
-	if (has_process_main(req->op))
-		size = sizeof(*msg) + hdr->data_length;
-	else
+	if (hdr->flags & SD_FLAG_CMD_WRITE)
 		size = sizeof(*msg);
+	else
+		size = sizeof(*msg) + hdr->data_length;
 
 	msg = zalloc(size);
 	if (!msg) {
@@ -247,8 +237,6 @@ void do_cluster_request(struct work *wor
 
 	msg->req = *((struct sd_vdi_req *)&req->rq);
 	msg->rsp = *((struct sd_vdi_rsp *)&req->rp);
-	if (has_process_main(req->op))
-		memcpy(msg->data, req->data, hdr->data_length);
 
 	list_add_tail(&req->pending_list, &sys->pending_list);
 
@@ -262,22 +250,21 @@ void do_cluster_request(struct work *wor
 	free(msg);
 }
 
+static void group_handler(int listen_fd, int events, void *data);
+
+static void cluster_dispatch(void *opaque)
+{
+	if (sys->cdrv->dispatch() != 0)
+		panic("oops... an error occurred inside corosync\n");
+}
+
 static void group_handler(int listen_fd, int events, void *data)
 {
-	int ret;
-	if (events & EPOLLHUP) {
-		eprintf("received EPOLLHUP event: has corosync exited?\n");
-		goto out;
-	}
+	if (events & EPOLLHUP)
+		panic("received EPOLLHUP event: has corosync exited?\n");
 
-	ret = sys->cdrv->dispatch();
-	if (ret == 0)
-		return;
-	else
-		eprintf("oops... an error occurred inside corosync\n");
-out:
-	log_close();
-	exit(1);
+	cdrv_co = coroutine_create(cluster_dispatch);
+	coroutine_enter(cdrv_co, NULL);
 }
 
 static inline int get_nodes_nr_from(struct list_head *l)
@@ -290,9 +277,9 @@ static inline int get_nodes_nr_from(stru
 	return nr;
 }
 
-static int get_nodes_nr_epoch(uint32_t epoch)
+static int get_nodes_nr_epoch(int epoch)
 {
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	int nr;
 
 	nr = epoch_log_read(epoch, (char *)nodes, sizeof(nodes));
@@ -300,8 +287,8 @@ static int get_nodes_nr_epoch(uint32_t e
 	return nr;
 }
 
-static struct sd_node *find_entry_list(struct sd_node *entry,
-					struct list_head *head)
+static struct sheepdog_node_list_entry *find_entry_list(struct sheepdog_node_list_entry *entry,
+							struct list_head *head)
 {
 	struct node *n;
 	list_for_each_entry(n, head, list)
@@ -312,10 +299,10 @@ static struct sd_node *find_entry_list(s
 
 }
 
-static struct sd_node *find_entry_epoch(struct sd_node *entry,
-					uint32_t epoch)
+static struct sheepdog_node_list_entry *find_entry_epoch(struct sheepdog_node_list_entry *entry,
+							 int epoch)
 {
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	int nr, i;
 
 	nr = epoch_log_read_nr(epoch, (char *)nodes, sizeof(nodes));
@@ -327,11 +314,11 @@ static struct sd_node *find_entry_epoch(
 	return NULL;
 }
 
-static int cluster_sanity_check(struct sd_node *entries,
+static int cluster_sanity_check(struct sheepdog_node_list_entry *entries,
 			     int nr_entries, uint64_t ctime, uint32_t epoch)
 {
 	int ret = SD_RES_SUCCESS, nr_local_entries;
-	struct sd_node local_entries[SD_MAX_NODES];
+	struct sheepdog_node_list_entry local_entries[SD_MAX_NODES];
 	uint32_t lepoch;
 
 	if (sys_stat_wait_format() || sys_stat_shutdown())
@@ -372,14 +359,14 @@ out:
 	return ret;
 }
 
-static int get_cluster_status(struct sd_node *from,
-			      struct sd_node *entries,
+static int get_cluster_status(struct sheepdog_node_list_entry *from,
+			      struct sheepdog_node_list_entry *entries,
 			      int nr_entries, uint64_t ctime, uint32_t epoch,
 			      uint32_t *status, uint8_t *inc_epoch)
 {
 	int i, j, ret = SD_RES_SUCCESS;
 	int nr, nr_local_entries, nr_leave_entries;
-	struct sd_node local_entries[SD_MAX_NODES];
+	struct sheepdog_node_list_entry local_entries[SD_MAX_NODES];
 	char str[256];
 	uint32_t sys_stat = sys_stat_get();
 
@@ -447,7 +434,7 @@ out:
 	return ret;
 }
 
-static void join(struct sd_node *joining, struct join_message *msg)
+static void join(struct sheepdog_node_list_entry *joining, struct join_message *msg)
 {
 	if (msg->proto_ver != SD_SHEEP_PROTO_VER) {
 		eprintf("joining node sent a message with the wrong protocol version\n");
@@ -458,14 +445,12 @@ static void join(struct sd_node *joining
 	msg->result = get_cluster_status(joining, msg->nodes, msg->nr_nodes,
 					 msg->ctime, msg->epoch,
 					 &msg->cluster_status, &msg->inc_epoch);
-	msg->nr_copies = sys->nr_copies;
+	msg->nr_sobjs = sys->nr_sobjs;
 	msg->cluster_flags = sys->flags;
 	msg->ctime = get_cluster_ctime();
-	if (sd_store)
-		strcpy((char *)msg->store, sd_store->name);
 }
 
-static int get_vdi_bitmap_from(struct sd_node *node)
+static int get_vdi_bitmap_from(struct sheepdog_node_list_entry *node)
 {
 	struct sd_req hdr;
 	struct sd_rsp *rsp = (struct sd_rsp *)&hdr;
@@ -521,12 +506,24 @@ static void get_vdi_bitmap_from_sd_list(
 		get_vdi_bitmap_from(sys->nodes + i);
 }
 
-static void finish_join(struct join_message *msg, struct sd_node *joined,
-		struct sd_node *nodes, size_t nr_nodes)
+static void update_cluster_info(struct join_message *msg,
+				struct sheepdog_node_list_entry *joined,
+				struct sheepdog_node_list_entry *nodes,
+				size_t nr_nodes)
 {
-	int i;
+	int i, le;
+	int nr_leave_nodes;
+	struct node *n;
+
+	eprintf("status = %d, epoch = %d, %x, %d\n", msg->cluster_status, msg->epoch, msg->result, sys->join_finished);
+
+	if (sys_stat_join_failed())
+		return;
+
+	if (sys->join_finished)
+		goto join_finished;
 
-	sys->nr_copies = msg->nr_copies;
+	sys->nr_sobjs = msg->nr_sobjs;
 	sys->epoch = msg->epoch;
 
 	/* add nodes execept for newly joined one */
@@ -539,59 +536,36 @@ static void finish_join(struct join_mess
 	qsort(sys->nodes, sys->nr_nodes, sizeof(*sys->nodes), node_cmp);
 
 	if (msg->cluster_status != SD_STATUS_OK) {
-		int nr_leave_nodes;
-		uint32_t le;
-
 		nr_leave_nodes = msg->nr_leave_nodes;
 		le = get_latest_epoch();
 		for (i = 0; i < nr_leave_nodes; i++) {
-			struct node *n;
+			n = zalloc(sizeof(*n));
+			if (!n)
+				panic("failed to allocate memory\n");
 
-			if (find_entry_list(&msg->leave_nodes[i], &sys->leave_list) ||
-			    !find_entry_epoch(&msg->leave_nodes[i], le)) {
+			if (find_entry_list(&msg->leave_nodes[i], &sys->leave_list)
+			    || !find_entry_epoch(&msg->leave_nodes[i], le)) {
+				free(n);
 				continue;
 			}
 
-			n = zalloc(sizeof(*n));
-			if (!n)
-				panic("failed to allocate memory\n");
 			n->ent = msg->leave_nodes[i];
+
 			list_add_tail(&n->list, &sys->leave_list);
 		}
 	}
 
 	sys->join_finished = 1;
 
-	if ((msg->cluster_status == SD_STATUS_OK ||
-	     msg->cluster_status == SD_STATUS_HALT) && msg->inc_epoch)
+	if ((msg->cluster_status == SD_STATUS_OK || msg->cluster_status == SD_STATUS_HALT)
+	     && msg->inc_epoch)
 		update_epoch_log(sys->epoch);
 
-	if (!sd_store && strlen((char *)msg->store)) {
-		sd_store = find_store_driver((char *)msg->store);
-		if (sd_store) {
-			sd_store->init(obj_path);
-			if (set_cluster_store(sd_store->name) != SD_RES_SUCCESS)
-				panic("failed to store into config file\n");
-		} else
-				panic("backend store %s not supported\n", msg->store);
-	}
-}
-
-static void update_cluster_info(struct join_message *msg,
-		struct sd_node *joined, struct sd_node *nodes, size_t nr_nodes)
-{
-	eprintf("status = %d, epoch = %d, %x, %d\n", msg->cluster_status,
-		msg->epoch, msg->result, sys->join_finished);
-
-	if (sys_stat_join_failed())
-		return;
-
-	if (!sys->join_finished)
-		finish_join(msg, joined, nodes, nr_nodes);
-
+join_finished:
 	sys->nodes[sys->nr_nodes++] = *joined;
 	qsort(sys->nodes, sys->nr_nodes, sizeof(*sys->nodes), node_cmp);
-
+	sys->nr_vnodes = nodes_to_vnodes(sys->nodes, sys->nr_nodes,
+					 sys->vnodes);
 	if (msg->cluster_status == SD_STATUS_OK ||
 	    msg->cluster_status == SD_STATUS_HALT) {
 		if (msg->inc_epoch) {
@@ -601,22 +575,23 @@ static void update_cluster_info(struct j
 		}
 		/* Fresh node */
 		if (!sys_stat_ok() && !sys_stat_halt()) {
-			set_cluster_copies(sys->nr_copies);
+			set_cluster_copies(sys->nr_sobjs);
 			set_cluster_flags(sys->flags);
 			set_cluster_ctime(msg->ctime);
 		}
 	}
-	update_vnode_info();
-	sys_stat_set(msg->cluster_status);
 
 	print_node_list(sys->nodes, sys->nr_nodes);
+
+	sys_stat_set(msg->cluster_status);
+	return;
 }
 
-static void __sd_notify(struct event_struct *cevent)
+static void __sd_notify(struct cpg_event *cevent)
 {
 }
 
-static void __sd_notify_done(struct event_struct *cevent)
+static void __sd_notify_done(struct cpg_event *cevent)
 {
 	struct work_notify *w = container_of(cevent, struct work_notify, cev);
 	struct vdi_op_message *msg = w->msg;
@@ -632,15 +607,15 @@ static void __sd_notify_done(struct even
 		return;
 
 	msg->rsp.result = ret;
-	if (has_process_main(req->op))
-		memcpy(req->data, msg->data, msg->rsp.data_length);
+	memcpy(req->data, msg->data, msg->rsp.data_length);
 	memcpy(&req->rp, &msg->rsp, sizeof(req->rp));
 	req->done(req);
 }
 
-void sd_notify_handler(struct sd_node *sender, void *msg, size_t msg_len)
+static void sd_notify_handler(struct sheepdog_node_list_entry *sender,
+			      void *msg, size_t msg_len)
 {
-	struct event_struct *cevent;
+	struct cpg_event *cevent;
 	struct work_notify *w;
 
 	dprintf("size: %zd, from: %s\n", msg_len, node_to_str(sender));
@@ -650,7 +625,7 @@ void sd_notify_handler(struct sd_node *s
 		return;
 
 	cevent = &w->cev;
-	cevent->ctype = EVENT_NOTIFY;
+	cevent->ctype = CPG_EVENT_NOTIFY;
 
 	vprintf(SDOG_DEBUG, "allow new deliver %p\n", cevent);
 
@@ -669,15 +644,19 @@ void sd_notify_handler(struct sd_node *s
 		list_del(&w->req->pending_list);
 	}
 
-	list_add_tail(&cevent->event_list, &sys->event_queue);
+	list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
+
+	start_cpg_event_work();
 
-	process_request_event_queues();
+	unregister_event(cdrv_fd);
+	coroutine_yield();
+	register_event(cdrv_fd, group_handler, NULL);
 }
 
 /*
  * Check whether the majority of Sheepdog nodes are still alive or not
  */
-static int check_majority(struct sd_node *nodes, int nr_nodes)
+static int check_majority(struct sheepdog_node_list_entry *nodes, int nr_nodes)
 {
 	int nr_majority, nr_reachable = 0, fd, i;
 	char name[INET6_ADDRSTRLEN];
@@ -707,7 +686,7 @@ static int check_majority(struct sd_node
 	return 0;
 }
 
-static void __sd_join(struct event_struct *cevent)
+static void __sd_join(struct cpg_event *cevent)
 {
 	struct work_join *w = container_of(cevent, struct work_join, cev);
 	struct join_message *msg = w->jm;
@@ -725,7 +704,7 @@ static void __sd_join(struct event_struc
 		get_vdi_bitmap_from(w->member_list + i);
 }
 
-static void __sd_leave(struct event_struct *cevent)
+static void __sd_leave(struct cpg_event *cevent)
 {
 	struct work_leave *w = container_of(cevent, struct work_leave, cev);
 
@@ -735,13 +714,14 @@ static void __sd_leave(struct event_stru
 	}
 }
 
-enum cluster_join_result sd_check_join_cb(struct sd_node *joining, void *opaque)
+static enum cluster_join_result sd_check_join_cb(
+	struct sheepdog_node_list_entry *joining, void *opaque)
 {
 	struct join_message *jm = opaque;
 	struct node *node;
 
 	if (node_cmp(joining, &sys->this_node) == 0) {
-		struct sd_node entries[SD_MAX_NODES];
+		struct sheepdog_node_list_entry entries[SD_MAX_NODES];
 		int nr_entries;
 		uint64_t ctime;
 		uint32_t epoch;
@@ -793,7 +773,7 @@ enum cluster_join_result sd_check_join_c
 		return CJ_RES_FAIL;
 }
 
-static int send_join_request(struct sd_node *ent)
+static int send_join_request(struct sheepdog_node_list_entry *ent)
 {
 	struct join_message *msg;
 	int nr_entries, ret;
@@ -803,7 +783,7 @@ static int send_join_request(struct sd_n
 		panic("failed to allocate memory\n");
 	msg->proto_ver = SD_SHEEP_PROTO_VER;
 
-	get_cluster_copies(&msg->nr_copies);
+	get_cluster_copies(&msg->nr_sobjs);
 	get_cluster_flags(&msg->cluster_flags);
 
 	nr_entries = SD_MAX_NODES;
@@ -811,7 +791,8 @@ static int send_join_request(struct sd_n
 	if (ret == SD_RES_SUCCESS)
 		msg->nr_nodes = nr_entries;
 
-	ret = sys->cdrv->join(ent, msg, get_join_message_size(msg));
+	ret = sys->cdrv->join(ent, sd_check_join_cb, msg,
+			      get_join_message_size(msg));
 
 	vprintf(SDOG_INFO, "%s\n", node_to_str(&sys->this_node));
 
@@ -820,7 +801,7 @@ static int send_join_request(struct sd_n
 	return ret;
 }
 
-static void __sd_join_done(struct event_struct *cevent)
+static void __sd_join_done(struct cpg_event *cevent)
 {
 	struct work_join *w = container_of(cevent, struct work_join, cev);
 	struct join_message *jm = w->jm;
@@ -828,12 +809,9 @@ static void __sd_join_done(struct event_
 
 	print_node_list(sys->nodes, sys->nr_nodes);
 
-	if (!sys_stat_join_failed()) {
-		update_cluster_info(jm, &w->joined, w->member_list,
-				    w->member_list_entries);
-	}
+	update_cluster_info(jm, &w->joined, w->member_list, w->member_list_entries);
 
-	if (sys_can_recover() && jm->inc_epoch) {
+	if (sys_can_recover()) {
 		list_for_each_entry_safe(node, t, &sys->leave_list, list) {
 			list_del(&node->list);
 		}
@@ -841,7 +819,9 @@ static void __sd_join_done(struct event_
 	}
 
 	if (sys_stat_halt()) {
-		if (current_vnode_info->nr_zones >= sys->nr_copies)
+		int nr_zones = get_zones_nr_from(sys->nodes, sys->nr_nodes);
+
+		if (nr_zones >= sys->nr_sobjs)
 			sys_stat_set(SD_STATUS_OK);
 	}
 
@@ -850,20 +830,20 @@ static void __sd_join_done(struct event_
 		vprintf(SDOG_DEBUG, "join Sheepdog cluster\n");
 }
 
-static void __sd_leave_done(struct event_struct *cevent)
+static void __sd_leave_done(struct cpg_event *cevent)
 {
 	struct work_leave *w = container_of(cevent, struct work_leave, cev);
 
 	sys->nr_nodes = w->member_list_entries;
 	memcpy(sys->nodes, w->member_list, sizeof(*sys->nodes) * sys->nr_nodes);
 	qsort(sys->nodes, sys->nr_nodes, sizeof(*sys->nodes), node_cmp);
-
+	sys->nr_vnodes = nodes_to_vnodes(sys->nodes, sys->nr_nodes,
+					 sys->vnodes);
 	if (sys_can_recover()) {
 		sys->epoch++;
 		update_epoch_store(sys->epoch);
 		update_epoch_log(sys->epoch);
 	}
-	update_vnode_info();
 
 	print_node_list(sys->nodes, sys->nr_nodes);
 
@@ -871,27 +851,29 @@ static void __sd_leave_done(struct event
 		start_recovery(sys->epoch);
 
 	if (sys_can_halt()) {
-		if (current_vnode_info->nr_zones < sys->nr_copies)
+		int nr_zones = get_zones_nr_from(sys->nodes, sys->nr_nodes);
+
+		if (nr_zones < sys->nr_sobjs)
 			sys_stat_set(SD_STATUS_HALT);
 	}
 }
 
-static void event_free(struct event_struct *cevent)
+static void cpg_event_free(struct cpg_event *cevent)
 {
 	switch (cevent->ctype) {
-	case EVENT_JOIN: {
+	case CPG_EVENT_JOIN: {
 		struct work_join *w = container_of(cevent, struct work_join, cev);
 		free(w->member_list);
 		free(w);
 		break;
 	}
-	case EVENT_LEAVE: {
+	case CPG_EVENT_LEAVE: {
 		struct work_leave *w = container_of(cevent, struct work_leave, cev);
 		free(w->member_list);
 		free(w);
 		break;
 	}
-	case EVENT_NOTIFY: {
+	case CPG_EVENT_NOTIFY: {
 		struct work_notify *w = container_of(cevent, struct work_notify, cev);
 		free(w->msg);
 		free(w);
@@ -902,28 +884,28 @@ static void event_free(struct event_stru
 	}
 }
 
-static struct work event_work;
+static struct work cpg_event_work;
 
-static void event_fn(struct work *work)
+static void cpg_event_fn(struct work *work)
 {
-	struct event_struct *cevent = sys->cur_cevent;
+	struct cpg_event *cevent = sys->cur_cevent;
 
 	/*
-	 * we can't touch sys->event_queue because of a race
+	 * we can't touch sys->cpg_event_siblings because of a race
 	 * with sd_deliver() and sd_confchg()...
 	 */
 
 	switch (cevent->ctype) {
-	case EVENT_JOIN:
+	case CPG_EVENT_JOIN:
 		__sd_join(cevent);
 		break;
-	case EVENT_LEAVE:
+	case CPG_EVENT_LEAVE:
 		__sd_leave(cevent);
 		break;
-	case EVENT_NOTIFY:
+	case CPG_EVENT_NOTIFY:
 		__sd_notify(cevent);
 		break;
-	case EVENT_REQUEST:
+	case CPG_EVENT_REQUEST:
 		vprintf(SDOG_ERR, "should not happen\n");
 		break;
 	default:
@@ -931,10 +913,9 @@ static void event_fn(struct work *work)
 	}
 }
 
-static void event_done(struct work *work)
+static void cpg_event_done(struct work *work)
 {
-	struct event_struct *cevent;
-	int ret;
+	struct cpg_event *cevent;
 
 	if (!sys->cur_cevent)
 		vprintf(SDOG_ERR, "bug\n");
@@ -945,16 +926,16 @@ static void event_done(struct work *work
 	vprintf(SDOG_DEBUG, "%p\n", cevent);
 
 	switch (cevent->ctype) {
-	case EVENT_JOIN:
+	case CPG_EVENT_JOIN:
 		__sd_join_done(cevent);
 		break;
-	case EVENT_LEAVE:
+	case CPG_EVENT_LEAVE:
 		__sd_leave_done(cevent);
 		break;
-	case EVENT_NOTIFY:
+	case CPG_EVENT_NOTIFY:
 		__sd_notify_done(cevent);
 		break;
-	case EVENT_REQUEST:
+	case CPG_EVENT_REQUEST:
 		vprintf(SDOG_ERR, "should not happen\n");
 		break;
 	default:
@@ -962,23 +943,77 @@ static void event_done(struct work *work
 	}
 
 	vprintf(SDOG_DEBUG, "free %p\n", cevent);
-	event_free(cevent);
-	event_running = 0;
-	ret = register_event(cdrv_fd, group_handler, NULL);
-	if (ret)
-		panic("failed to register event fd");
+	cpg_event_free(cevent);
+	cpg_event_running = 0;
+
+	coroutine_enter(cdrv_co, NULL);
 
-	process_request_event_queues();
+	if (!list_empty(&sys->cpg_event_siblings))
+		start_cpg_event_work();
+}
+
+static int check_epoch(struct request *req)
+{
+	uint32_t req_epoch = req->rq.epoch;
+	uint32_t opcode = req->rq.opcode;
+	int ret = SD_RES_SUCCESS;
+
+	if (before(req_epoch, sys->epoch)) {
+		ret = SD_RES_OLD_NODE_VER;
+		eprintf("old node version %u, %u, %x\n",
+			sys->epoch, req_epoch, opcode);
+	} else if (after(req_epoch, sys->epoch)) {
+		ret = SD_RES_NEW_NODE_VER;
+			eprintf("new node version %u, %u, %x\n",
+				sys->epoch, req_epoch, opcode);
+	}
+	return ret;
 }
 
 int is_access_to_busy_objects(uint64_t oid)
 {
 	struct request *req;
 
+	if (!oid)
+		return 0;
+
 	list_for_each_entry(req, &sys->outstanding_req_list, r_wlist) {
+		if (req->rq.flags & SD_FLAG_CMD_RECOVERY) {
+			if (req->rq.opcode != SD_OP_READ_OBJ)
+				eprintf("bug\n");
+			continue;
+		}
 		if (oid == req->local_oid)
-			return 1;
+				return 1;
+	}
+	return 0;
+}
+
+static int __is_access_to_recoverying_objects(struct request *req)
+{
+	if (req->rq.flags & SD_FLAG_CMD_RECOVERY) {
+		if (req->rq.opcode != SD_OP_READ_OBJ)
+			eprintf("bug\n");
+		return 0;
 	}
+
+	if (is_recoverying_oid(req->local_oid))
+		return 1;
+
+	return 0;
+}
+
+static int __is_access_to_busy_objects(struct request *req)
+{
+	if (req->rq.flags & SD_FLAG_CMD_RECOVERY) {
+		if (req->rq.opcode != SD_OP_READ_OBJ)
+			eprintf("bug\n");
+		return 0;
+	}
+
+	if (is_access_to_busy_objects(req->local_oid))
+		return 1;
+
 	return 0;
 }
 
@@ -999,116 +1034,153 @@ static int need_consistency_check(uint8_
 	return 1;
 }
 
-static inline void set_consistency_check(struct request *req, uint64_t oid)
+/* can be called only by the main process */
+void start_cpg_event_work(void)
 {
-	uint32_t vdi_id = oid_to_vid(oid);
-	struct data_object_bmap *bmap;
-
-	if (is_vdi_obj(oid))
-		return;
+	struct cpg_event *cevent, *n;
+	LIST_HEAD(failed_req_list);
+	int retry;
 
-	req->check_consistency = 1;
-	list_for_each_entry(bmap, &sys->consistent_obj_list, list) {
-		if (bmap->vdi_id == vdi_id) {
-			if (test_bit(data_oid_to_idx(oid), bmap->dobjs))
-				req->check_consistency = 0;
-			break;
-		}
-	}
-}
+	if (list_empty(&sys->cpg_event_siblings))
+		vprintf(SDOG_ERR, "bug\n");
 
-static void process_request_queue(void)
-{
-	struct event_struct *cevent, *n;
+	cevent = list_first_entry(&sys->cpg_event_siblings,
+				  struct cpg_event, cpg_event_list);
+	/*
+	 * we need to serialize cpg events so we don't call queue_work
+	 * if a thread is still running for a cpg event; executing
+	 * cpg_event_fn() or cpg_event_done().
+	 */
+	if (cpg_event_running && is_membership_change_event(cevent->ctype))
+		return;
+do_retry:
+	retry = 0;
 
-	list_for_each_entry_safe(cevent, n, &sys->request_queue, event_list) {
+	list_for_each_entry_safe(cevent, n, &sys->cpg_event_siblings, cpg_event_list) {
 		struct request *req = container_of(cevent, struct request, cev);
-		struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
 
-		list_del(&cevent->event_list);
+		if (cevent->ctype == CPG_EVENT_NOTIFY)
+			continue;
+		if (is_membership_change_event(cevent->ctype))
+			break;
+
+		list_del(&cevent->cpg_event_list);
 
 		if (is_io_op(req->op)) {
-			int copies = sys->nr_copies;
+			int copies = sys->nr_sobjs;
 
-			if (copies > req->vnodes->nr_zones)
-				copies = req->vnodes->nr_zones;
+			if (copies > req->nr_zones)
+				copies = req->nr_zones;
 
-			if (!(req->rq.flags & SD_FLAG_CMD_IO_LOCAL) &&
-			    object_is_cached(hdr->oid)) {
-				/* If we have cache of it we are at its service. */
-				list_add_tail(&req->r_wlist, &sys->outstanding_req_list);
-				sys->nr_outstanding_io++;
-				queue_work(sys->gateway_wqueue, &req->work);
+			if (__is_access_to_recoverying_objects(req)) {
+				if (req->rq.flags & SD_FLAG_CMD_IO_LOCAL) {
+					req->rp.result = SD_RES_NEW_NODE_VER;
+					sys->nr_outstanding_io++; /* TODO: cleanup */
+					list_add_tail(&req->r_wlist, &failed_req_list);
+				} else
+					list_add_tail(&req->r_wlist, &sys->req_wait_for_obj_list);
+				continue;
+			}
+			if (__is_access_to_busy_objects(req)) {
+				list_add_tail(&req->r_wlist, &sys->req_wait_for_obj_list);
 				continue;
 			}
 
 			list_add_tail(&req->r_wlist, &sys->outstanding_req_list);
+
 			sys->nr_outstanding_io++;
 
-			if (need_consistency_check(req->rq.opcode, req->rq.flags))
-				set_consistency_check(req, hdr->oid);
+			if (is_access_local(req->entry, req->nr_vnodes,
+					    ((struct sd_obj_req *)&req->rq)->oid, copies) ||
+			    is_access_local(req->entry, req->nr_vnodes,
+					    ((struct sd_obj_req *)&req->rq)->cow_oid, copies)) {
+				int ret = check_epoch(req);
+				if (ret != SD_RES_SUCCESS) {
+					req->rp.result = ret;
+					list_del(&req->r_wlist);
+					list_add_tail(&req->r_wlist, &failed_req_list);
+					continue;
+				}
+			}
 
-			if (req->rq.flags & SD_FLAG_CMD_IO_LOCAL)
-				queue_work(sys->io_wqueue, &req->work);
-			else
-				queue_work(sys->gateway_wqueue, &req->work);
-		} else /* (is_cluster_op(req->op) || is_local_op(req->op)) */
+			if (need_consistency_check(req->rq.opcode, req->rq.flags)) {
+				struct sd_obj_req *hdr = (struct sd_obj_req *)&req->rq;
+				uint32_t vdi_id = oid_to_vid(hdr->oid);
+				struct data_object_bmap *bmap;
+
+				req->check_consistency = 1;
+				if (!is_vdi_obj(hdr->oid)) {
+					list_for_each_entry(bmap, &sys->consistent_obj_list, list) {
+						if (bmap->vdi_id == vdi_id) {
+							if (test_bit(data_oid_to_idx(hdr->oid), bmap->dobjs))
+								req->check_consistency = 0;
+							break;
+						}
+					}
+				}
+			}
+		}
+
+		if (is_cluster_op(req->op))
+			queue_work(sys->cpg_wqueue, &req->work);
+		else if (req->rq.flags & SD_FLAG_CMD_IO_LOCAL)
 			queue_work(sys->io_wqueue, &req->work);
+		else
+			queue_work(sys->gateway_wqueue, &req->work);
 	}
-}
 
-static inline void process_event_queue(void)
-{
-	struct event_struct *cevent;
-	/*
-	 * we need to serialize events so we don't call queue_work
-	 * if one event is running by executing event_fn() or event_done().
-	 */
-	if (event_running || sys->nr_outstanding_io)
+	while (!list_empty(&failed_req_list)) {
+		struct request *req = list_first_entry(&failed_req_list,
+						       struct request, r_wlist);
+		req->work.done(&req->work);
+
+		retry = 1;
+	}
+
+	if (retry)
+		goto do_retry;
+
+	if (cpg_event_running || list_empty(&sys->cpg_event_siblings))
 		return;
 
-	cevent = list_first_entry(&sys->event_queue,
-			struct event_struct, event_list);
-	list_del(&cevent->event_list);
-	sys->cur_cevent = cevent;
+	cevent = list_first_entry(&sys->cpg_event_siblings,
+				  struct cpg_event, cpg_event_list);
 
-	event_running = 1;
+	if (is_membership_change_event(cevent->ctype) && sys->nr_outstanding_io)
+		return;
 
-	event_work.fn = event_fn;
-	event_work.done = event_done;
+	list_del(&cevent->cpg_event_list);
+	sys->cur_cevent = cevent;
 
-	unregister_event(cdrv_fd);
-	queue_work(sys->event_wqueue, &event_work);
-}
+	cpg_event_running = 1;
 
-/* can be called only by the main process */
-void process_request_event_queues(void)
-{
-	if (!list_empty(&sys->event_queue))
-		process_event_queue();
-	else
-		process_request_queue();
+	INIT_LIST_HEAD(&cpg_event_work.w_list);
+	cpg_event_work.fn = cpg_event_fn;
+	cpg_event_work.done = cpg_event_done;
+
+	queue_work(sys->cpg_wqueue, &cpg_event_work);
 }
 
-void sd_join_handler(struct sd_node *joined, struct sd_node *members,
-		size_t nr_members, enum cluster_join_result result,
-		void *opaque)
+static void sd_join_handler(struct sheepdog_node_list_entry *joined,
+			    struct sheepdog_node_list_entry *members,
+			    size_t nr_members, enum cluster_join_result result,
+			    void *opaque)
 {
-	struct event_struct *cevent;
+	struct cpg_event *cevent;
 	struct work_join *w = NULL;
 	int i, size;
 	int nr, nr_local, nr_leave;
 	struct node *n;
 	struct join_message *jm;
-	uint32_t le = get_latest_epoch();
+	int le = get_latest_epoch();
 
 	if (node_cmp(joined, &sys->this_node) == 0) {
 		if (result == CJ_RES_FAIL) {
-			eprintf("Fail to join. The joining node has an invalid epoch.\n");
+			eprintf("failed to join sheepdog cluster\n");
 			sys->cdrv->leave();
 			exit(1);
 		} else if (result == CJ_RES_JOIN_LATER) {
-			eprintf("Fail to join. The joining node should be added after the cluster start working.\n");
+			eprintf("failed to join sheepdog cluster: please retry when master is up\n");
 			sys->cdrv->leave();
 			exit(1);
 		}
@@ -1128,11 +1200,11 @@ void sd_join_handler(struct sd_node *joi
 			panic("failed to allocate memory");
 
 		cevent = &w->cev;
-		cevent->ctype = EVENT_JOIN;
+		cevent->ctype = CPG_EVENT_JOIN;
 
 		vprintf(SDOG_DEBUG, "allow new confchg %p\n", cevent);
 
-		size = sizeof(struct sd_node) * nr_members;
+		size = sizeof(struct sheepdog_node_list_entry) * nr_members;
 		w->member_list = zalloc(size);
 		if (!w->member_list)
 			panic("failed to allocate memory");
@@ -1148,23 +1220,29 @@ void sd_join_handler(struct sd_node *joi
 			panic("failed to allocate memory\n");
 		memcpy(w->jm, opaque, size);
 
-		list_add_tail(&cevent->event_list, &sys->event_queue);
-		process_request_event_queues();
+		list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
+		start_cpg_event_work();
+
+		unregister_event(cdrv_fd);
+		coroutine_yield();
+		register_event(cdrv_fd, group_handler, NULL);
+
 		break;
 	case CJ_RES_FAIL:
 	case CJ_RES_JOIN_LATER:
 		if (!sys_stat_wait_join())
 			break;
 
+		n = zalloc(sizeof(*n));
+		if (!n)
+			panic("failed to allocate memory\n");
+
 		if (find_entry_list(joined, &sys->leave_list)
 		    || !find_entry_epoch(joined, le)) {
+			free(n);
 			break;
 		}
 
-		n = zalloc(sizeof(*n));
-		if (!n)
-			panic("failed to allocate memory\n");
-
 		n->ent = *joined;
 
 		list_add_tail(&n->list, &sys->leave_list);
@@ -1184,15 +1262,16 @@ void sd_join_handler(struct sd_node *joi
 		jm = (struct join_message *)opaque;
 		nr = jm->nr_leave_nodes;
 		for (i = 0; i < nr; i++) {
+			n = zalloc(sizeof(*n));
+			if (!n)
+				panic("failed to allocate memory\n");
+
 			if (find_entry_list(&jm->leave_nodes[i], &sys->leave_list)
 			    || !find_entry_epoch(&jm->leave_nodes[i], le)) {
+				free(n);
 				continue;
 			}
 
-			n = zalloc(sizeof(*n));
-			if (!n)
-				panic("failed to allocate memory\n");
-
 			n->ent = jm->leave_nodes[i];
 
 			list_add_tail(&n->list, &sys->leave_list);
@@ -1205,9 +1284,9 @@ void sd_join_handler(struct sd_node *joi
 			sys->join_finished = 1;
 			sys->nodes[sys->nr_nodes++] = sys->this_node;
 			qsort(sys->nodes, sys->nr_nodes, sizeof(*sys->nodes), node_cmp);
+			sys->nr_vnodes = nodes_to_vnodes(sys->nodes, sys->nr_nodes,
+							 sys->vnodes);
 			sys->epoch = get_latest_epoch();
-
-			update_vnode_info();
 		}
 
 		nr_local = get_nodes_nr_epoch(sys->epoch);
@@ -1228,10 +1307,11 @@ void sd_join_handler(struct sd_node *joi
 	}
 }
 
-void sd_leave_handler(struct sd_node *left, struct sd_node *members,
-		size_t nr_members)
+static void sd_leave_handler(struct sheepdog_node_list_entry *left,
+			     struct sheepdog_node_list_entry *members,
+			     size_t nr_members)
 {
-	struct event_struct *cevent;
+	struct cpg_event *cevent;
 	struct work_leave *w = NULL;
 	int i, size;
 
@@ -1247,12 +1327,12 @@ void sd_leave_handler(struct sd_node *le
 		goto oom;
 
 	cevent = &w->cev;
-	cevent->ctype = EVENT_LEAVE;
+	cevent->ctype = CPG_EVENT_LEAVE;
 
 
 	vprintf(SDOG_DEBUG, "allow new confchg %p\n", cevent);
 
-	size = sizeof(struct sd_node) * nr_members;
+	size = sizeof(struct sheepdog_node_list_entry) * nr_members;
 	w->member_list = zalloc(size);
 	if (!w->member_list)
 		goto oom;
@@ -1261,8 +1341,12 @@ void sd_leave_handler(struct sd_node *le
 
 	w->left = *left;
 
-	list_add_tail(&cevent->event_list, &sys->event_queue);
-	process_request_event_queues();
+	list_add_tail(&cevent->cpg_event_list, &sys->cpg_event_siblings);
+	start_cpg_event_work();
+
+	unregister_event(cdrv_fd);
+	coroutine_yield();
+	register_event(cdrv_fd, group_handler, NULL);
 
 	return;
 oom:
@@ -1274,9 +1358,14 @@ oom:
 	panic("failed to allocate memory for a confchg event\n");
 }
 
-int create_cluster(int port, int64_t zone, int nr_vnodes)
+int create_cluster(int port, int64_t zone)
 {
 	int ret;
+	struct cdrv_handlers handlers = {
+		.join_handler = sd_join_handler,
+		.leave_handler = sd_leave_handler,
+		.notify_handler = sd_notify_handler,
+	};
 
 	if (!sys->cdrv) {
 		sys->cdrv = find_cdrv("corosync");
@@ -1289,12 +1378,12 @@ int create_cluster(int port, int64_t zon
 		}
 	}
 
-	cdrv_fd = sys->cdrv->init(sys->cdrv_option, sys->this_node.addr);
+	cdrv_fd = sys->cdrv->init(&handlers, sys->cdrv_option, sys->this_node.addr);
 	if (cdrv_fd < 0)
 		return -1;
 
 	sys->this_node.port = port;
-	sys->this_node.nr_vnodes = nr_vnodes;
+	sys->this_node.nr_vnodes = SD_DEFAULT_VNODES;
 	if (zone == -1) {
 		/* use last 4 bytes as zone id */
 		uint8_t *b = sys->this_node.addr + 12;
@@ -1315,8 +1404,7 @@ int create_cluster(int port, int64_t zon
 	INIT_LIST_HEAD(&sys->consistent_obj_list);
 	INIT_LIST_HEAD(&sys->blocking_conn_list);
 
-	INIT_LIST_HEAD(&sys->request_queue);
-	INIT_LIST_HEAD(&sys->event_queue);
+	INIT_LIST_HEAD(&sys->cpg_event_siblings);
 
 	ret = register_event(cdrv_fd, group_handler, NULL);
 	if (ret) {
--- sheepdog-0.3.0.orig/sheep/cluster/corosync.c
+++ sheepdog-0.3.0/sheep/cluster/corosync.c
@@ -20,7 +20,7 @@ struct cpg_node {
 	uint32_t nodeid;
 	uint32_t pid;
 	uint32_t gone;
-	struct sd_node ent;
+	struct sheepdog_node_list_entry ent;
 };
 
 static cpg_handle_t cpg_handle;
@@ -31,6 +31,10 @@ static struct cpg_node this_node;
 
 static struct work_queue *corosync_block_wq;
 
+static struct cdrv_handlers corosync_handlers;
+static enum cluster_join_result (*corosync_check_join_cb)(
+	struct sheepdog_node_list_entry *joining, void *opaque);
+
 static LIST_HEAD(corosync_event_list);
 static LIST_HEAD(corosync_block_list);
 
@@ -126,7 +130,7 @@ static inline void del_cpg_node(struct c
 	}
 
 	nr_nodes--;
-	memmove(nodes + idx, nodes + idx + 1, sizeof(*nodes) * (nr_nodes - idx));
+	memmove(nodes + idx, nodes + idx + 1, sizeof(*nodes) * nr_nodes - idx);
 }
 
 static int nodeid_to_addr(uint32_t nodeid, uint8_t *addr)
@@ -261,7 +265,7 @@ static int is_master(struct cpg_node *no
 }
 
 static void build_node_list(struct cpg_node *nodes, size_t nr_nodes,
-			    struct sd_node *entries)
+			    struct sheepdog_node_list_entry *entries)
 {
 	int i;
 
@@ -278,7 +282,7 @@ static int __corosync_dispatch_one(struc
 {
 	struct corosync_block_msg *bm;
 	enum cluster_join_result res;
-	struct sd_node entries[SD_MAX_NODES];
+	struct sheepdog_node_list_entry entries[SD_MAX_NODES];
 	int idx;
 
 	switch (cevent->type) {
@@ -295,7 +299,7 @@ static int __corosync_dispatch_one(struc
 				/* check_join() must be called only once */
 				return 0;
 
-			res = sd_check_join_cb(&cevent->sender.ent,
+			res = corosync_check_join_cb(&cevent->sender.ent,
 						     cevent->msg);
 			if (res == CJ_RES_MASTER_TRANSFER)
 				nr_cpg_nodes = 0;
@@ -322,7 +326,7 @@ static int __corosync_dispatch_one(struc
 		case CJ_RES_FAIL:
 		case CJ_RES_JOIN_LATER:
 			build_node_list(cpg_nodes, nr_cpg_nodes, entries);
-			sd_join_handler(&cevent->sender.ent, entries,
+			corosync_handlers.join_handler(&cevent->sender.ent, entries,
 						       nr_cpg_nodes, cevent->result,
 						       cevent->msg);
 			break;
@@ -337,7 +341,8 @@ static int __corosync_dispatch_one(struc
 		del_cpg_node(cpg_nodes, nr_cpg_nodes, &cevent->sender);
 		nr_cpg_nodes--;
 		build_node_list(cpg_nodes, nr_cpg_nodes, entries);
-		sd_leave_handler(&cevent->sender.ent, entries, nr_cpg_nodes);
+		corosync_handlers.leave_handler(&cevent->sender.ent,
+						entries, nr_cpg_nodes);
 		break;
 	case COROSYNC_EVENT_TYPE_NOTIFY:
 		if (cevent->blocked) {
@@ -362,7 +367,7 @@ static int __corosync_dispatch_one(struc
 			return 0;
 		}
 
-		sd_notify_handler(&cevent->sender.ent, cevent->msg,
+		corosync_handlers.notify_handler(&cevent->sender.ent, cevent->msg,
 						 cevent->msg_len);
 		break;
 	}
@@ -614,7 +619,8 @@ static void cdrv_cpg_confchg(cpg_handle_
 	__corosync_dispatch();
 }
 
-static int corosync_init(const char *option, uint8_t *myaddr)
+static int corosync_init(struct cdrv_handlers *handlers, const char *option,
+			 uint8_t *myaddr)
 {
 	int ret, fd;
 	uint32_t nodeid;
@@ -623,6 +629,8 @@ static int corosync_init(const char *opt
 		.cpg_confchg_fn = cdrv_cpg_confchg
 	};
 
+	corosync_handlers = *handlers;
+
 	ret = cpg_initialize(&cpg_handle, &cb);
 	if (ret != CPG_OK) {
 		eprintf("failed to initialize cpg (%d) - is corosync running?\n", ret);
@@ -657,19 +665,19 @@ static int corosync_init(const char *opt
 	}
 
 	corosync_block_wq = init_work_queue(1);
-	if (!corosync_block_wq) {
-		eprintf("failed to create corosync workqueue: %m\n");
-		return -1;
-	}
 
 	return fd;
 }
 
-static int corosync_join(struct sd_node *myself,
+static int corosync_join(struct sheepdog_node_list_entry *myself,
+			 enum cluster_join_result (*check_join_cb)(
+				 struct sheepdog_node_list_entry *joining,
+				 void *opaque),
 			 void *opaque, size_t opaque_len)
 {
 	int ret;
 
+	corosync_check_join_cb = check_join_cb;
 retry:
 	ret = cpg_join(cpg_handle, &cpg_group);
 	switch (ret) {
--- sheepdog-0.3.0.orig/sheep/cluster/accord.c
+++ sheepdog-0.3.0/sheep/cluster/accord.c
@@ -35,13 +35,13 @@ enum acrd_event_type {
 
 struct acrd_event {
 	enum acrd_event_type type;
-	struct sd_node sender;
+	struct sheepdog_node_list_entry sender;
 
 	size_t buf_len;
 	uint8_t buf[MAX_EVENT_BUF_SIZE];
 
 	size_t nr_nodes; /* the number of sheep */
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	uint64_t ids[SD_MAX_NODES];
 
 	enum cluster_join_result join_result;
@@ -52,7 +52,7 @@ struct acrd_event {
 	int callbacked; /* set non-zero if sheep already called block_cb() */
 };
 
-static struct sd_node this_node;
+static struct sheepdog_node_list_entry this_node;
 static uint64_t this_id;
 
 
@@ -217,9 +217,13 @@ static int efd;
 
 static struct work_queue *acrd_wq;
 
+static struct cdrv_handlers acrd_hdlrs;
+static enum cluster_join_result (*acrd_check_join_cb)(
+	struct sheepdog_node_list_entry *joining, void *opaque);
+
 /* get node list from the last pushed data */
 static size_t get_nodes(struct acrd_handle *ah,
-			struct sd_node *nodes,
+			struct sheepdog_node_list_entry *nodes,
 			uint64_t *ids)
 {
 	int rc;
@@ -245,11 +249,11 @@ again:
 }
 
 static int add_event(struct acrd_handle *ah, enum acrd_event_type type,
-		     struct sd_node *node, void *buf,
+		     struct sheepdog_node_list_entry *node, void *buf,
 		     size_t buf_len, void (*block_cb)(void *arg))
 {
 	int idx;
-	struct sd_node *n;
+	struct sheepdog_node_list_entry *n;
 	uint64_t *i;
 	struct acrd_event ev;
 
@@ -394,7 +398,7 @@ static void __acrd_leave(struct work *wo
 	int i;
 	size_t nr_nodes;
 	uint64_t ids[SD_MAX_NODES];
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	struct acrd_tx *atx;
 
 	pthread_mutex_lock(&queue_lock);
@@ -463,8 +467,10 @@ static void acrd_watch_fn(struct acrd_ha
 	eventfd_write(efd, value);
 }
 
-static int accord_init(const char *option, uint8_t *myaddr)
+static int accord_init(struct cdrv_handlers *handlers, const char *option,
+		       uint8_t *myaddr)
 {
+	acrd_hdlrs = *handlers;
 	if (!option) {
 		eprintf("specify one of the accord servers.\n");
 		eprintf("e.g. sheep /store -c accord:127.0.0.1\n");
@@ -489,10 +495,6 @@ static int accord_init(const char *optio
 	}
 
 	acrd_wq = init_work_queue(1);
-	if (!acrd_wq)
-		eprintf("failed to create accord workqueue: %m\n");
-		return -1;
-	}
 
 	pthread_cond_wait(&start_cond, &start_lock);
 	pthread_mutex_unlock(&start_lock);
@@ -512,10 +514,14 @@ static int accord_init(const char *optio
 	return efd;
 }
 
-static int accord_join(struct sd_node *myself,
+static int accord_join(struct sheepdog_node_list_entry *myself,
+		       enum cluster_join_result (*check_join_cb)(
+			       struct sheepdog_node_list_entry *joining,
+			       void *opaque),
 		       void *opaque, size_t opaque_len)
 {
 	this_node = *myself;
+	acrd_check_join_cb = check_join_cb;
 
 	return add_event(ahandle, EVENT_JOIN, &this_node, opaque, opaque_len, NULL);
 }
@@ -576,7 +582,7 @@ static int accord_dispatch(void)
 	case EVENT_JOIN:
 		if (ev.blocked) {
 			if (node_cmp(&ev.nodes[0], &this_node) == 0) {
-				res = sd_check_join_cb(&ev.sender, ev.buf);
+				res = acrd_check_join_cb(&ev.sender, ev.buf);
 				ev.join_result = res;
 				ev.blocked = 0;
 
@@ -603,11 +609,11 @@ static int accord_dispatch(void)
 			acrd_queue_pop(ahandle, &ev);
 		}
 
-		sd_join_handler(&ev.sender, ev.nodes, ev.nr_nodes,
+		acrd_hdlrs.join_handler(&ev.sender, ev.nodes, ev.nr_nodes,
 				    ev.join_result, ev.buf);
 		break;
 	case EVENT_LEAVE:
-		sd_leave_handler(&ev.sender, ev.nodes, ev.nr_nodes);
+		acrd_hdlrs.leave_handler(&ev.sender, ev.nodes, ev.nr_nodes);
 		break;
 	case EVENT_NOTIFY:
 		if (ev.blocked) {
@@ -623,7 +629,7 @@ static int accord_dispatch(void)
 			goto out;
 		}
 
-		sd_notify_handler(&ev.sender, ev.buf, ev.buf_len);
+		acrd_hdlrs.notify_handler(&ev.sender, ev.buf, ev.buf_len);
 		break;
 	}
 out:
--- sheepdog-0.3.0.orig/sheep/cluster/local.c
+++ sheepdog-0.3.0/sheep/cluster/local.c
@@ -30,10 +30,14 @@ const char *shmfile = "/tmp/sheepdog_shm
 static int shmfd;
 static int sigfd;
 static int event_pos;
-static struct sd_node this_node;
+static struct sheepdog_node_list_entry this_node;
 
 static struct work_queue *local_block_wq;
 
+static struct cdrv_handlers lhdlrs;
+static enum cluster_join_result (*local_check_join_cb)(
+	struct sheepdog_node_list_entry *joining, void *opaque);
+
 enum local_event_type {
 	EVENT_JOIN = 1,
 	EVENT_LEAVE,
@@ -42,13 +46,13 @@ enum local_event_type {
 
 struct local_event {
 	enum local_event_type type;
-	struct sd_node sender;
+	struct sheepdog_node_list_entry sender;
 
 	size_t buf_len;
 	uint8_t buf[MAX_EVENT_BUF_SIZE];
 
 	size_t nr_nodes; /* the number of sheep processes */
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	pid_t pids[SD_MAX_NODES];
 
 	enum cluster_join_result join_result;
@@ -84,7 +88,7 @@ static int shm_queue_empty(void)
 	return event_pos == shm_queue->pos;
 }
 
-static size_t get_nodes(struct sd_node *n, pid_t *p)
+static size_t get_nodes(struct sheepdog_node_list_entry *n, pid_t *p)
 {
 	struct local_event *ev;
 
@@ -214,11 +218,11 @@ static void shm_queue_init(void)
 }
 
 static void add_event(enum local_event_type type,
-		      struct sd_node *node, void *buf,
+		      struct sheepdog_node_list_entry *node, void *buf,
 		      size_t buf_len, void (*block_cb)(void *arg))
 {
 	int idx;
-	struct sd_node *n;
+	struct sheepdog_node_list_entry *n;
 	pid_t *p;
 	struct local_event ev = {
 		.type = type,
@@ -264,7 +268,7 @@ static void check_pids(void *arg)
 {
 	int i;
 	size_t nr;
-	struct sd_node nodes[SD_MAX_NODES];
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 	pid_t pids[SD_MAX_NODES];
 
 	shm_queue_lock();
@@ -283,7 +287,8 @@ static void check_pids(void *arg)
 
 /* Local driver APIs */
 
-static int local_init(const char *option, uint8_t *myaddr)
+static int local_init(struct cdrv_handlers *handlers, const char *option,
+		      uint8_t *myaddr)
 {
 	sigset_t mask;
 	static struct timer t = {
@@ -291,6 +296,7 @@ static int local_init(const char *option
 		.data = &t,
 	};
 
+	lhdlrs = *handlers;
 	if (option)
 		shmfile = option;
 
@@ -314,18 +320,18 @@ static int local_init(const char *option
 	add_timer(&t, 1);
 
 	local_block_wq = init_work_queue(1);
-	if (!local_block_wq) {
-		eprintf("failed to create local workqueue: %m\n");
-		return -1;
-	}
 
 	return sigfd;
 }
 
-static int local_join(struct sd_node *myself,
+static int local_join(struct sheepdog_node_list_entry *myself,
+		      enum cluster_join_result (*check_join_cb)(
+			      struct sheepdog_node_list_entry *joining,
+			      void *opaque),
 		      void *opaque, size_t opaque_len)
 {
 	this_node = *myself;
+	local_check_join_cb = check_join_cb;
 
 	shm_queue_lock();
 
@@ -404,7 +410,7 @@ static int local_dispatch(void)
 	case EVENT_JOIN:
 		if (ev->blocked) {
 			if (node_cmp(&ev->nodes[0], &this_node) == 0) {
-				res = sd_check_join_cb(&ev->sender, ev->buf);
+				res = local_check_join_cb(&ev->sender, ev->buf);
 				ev->join_result = res;
 				ev->blocked = 0;
 				msync(ev, sizeof(*ev), MS_SYNC);
@@ -430,11 +436,11 @@ static int local_dispatch(void)
 			shm_queue_set_chksum();
 		}
 
-		sd_join_handler(&ev->sender, ev->nodes, ev->nr_nodes,
+		lhdlrs.join_handler(&ev->sender, ev->nodes, ev->nr_nodes,
 				    ev->join_result, ev->buf);
 		break;
 	case EVENT_LEAVE:
-		sd_leave_handler(&ev->sender, ev->nodes, ev->nr_nodes);
+		lhdlrs.leave_handler(&ev->sender, ev->nodes, ev->nr_nodes);
 		break;
 	case EVENT_NOTIFY:
 		if (ev->blocked) {
@@ -448,7 +454,7 @@ static int local_dispatch(void)
 			goto out;
 		}
 
-		sd_notify_handler(&ev->sender, ev->buf, ev->buf_len);
+		lhdlrs.notify_handler(&ev->sender, ev->buf, ev->buf_len);
 		break;
 	}
 
--- sheepdog-0.3.0.orig/sheep/cluster/zookeeper.c
+++ sheepdog-0.3.0/sheep/cluster/zookeeper.c
@@ -21,36 +21,15 @@
 #include "work.h"
 
 #define MAX_EVENT_BUF_SIZE (64 * 1024)
-#define SESSION_TIMEOUT 30000		/* millisecond */
-#define MEMBER_CREATE_TIMEOUT SESSION_TIMEOUT
-#define MEMBER_CREATE_INTERVAL 10	/* millisecond */
 
 #define BASE_ZNODE "/sheepdog"
+#define LOCK_ZNODE BASE_ZNODE "/lock"
 #define QUEUE_ZNODE BASE_ZNODE "/queue"
 #define MEMBER_ZNODE BASE_ZNODE "/member"
 
-
-/* zookeeper API wrapper prototypes */
-ZOOAPI int zk_create(zhandle_t *zh, const char *path, const char *value,
-	int valuelen, const struct ACL_vector *acl, int flags,
-	char *path_buffer, int path_buffer_len);
-
-ZOOAPI int zk_delete(zhandle_t *zh, const char *path, int version);
-
-ZOOAPI int zk_get(zhandle_t *zh, const char *path, int watch, char *buffer,
-		   int *buffer_len, struct Stat *stat);
-
-ZOOAPI int zk_set(zhandle_t *zh, const char *path, const char *buffer,
-		   int buflen, int version);
-
-ZOOAPI int zk_exists(zhandle_t *zh, const char *path, int watch, struct Stat *stat);
-
-ZOOAPI int zk_get_children(zhandle_t *zh, const char *path, int watch,
-			    struct String_vector *strings);
-
 /* iterate child znodes */
 #define FOR_EACH_ZNODE(zh, parent, path, strs)			       \
-	for (zk_get_children(zh, parent, 1, strs),		       \
+	for (zoo_get_children(zh, parent, 1, strs),		       \
 		     (strs)->data += (strs)->count;		       \
 	     (strs)->count-- ?					       \
 		     sprintf(path, "%s/%s", parent, *--(strs)->data) : \
@@ -63,15 +42,15 @@ enum zk_event_type {
 	EVENT_NOTIFY,
 };
 
-struct zk_node {
-	int joined;
-	clientid_t clientid;
-	struct sd_node node;
-};
-
 struct zk_event {
 	enum zk_event_type type;
-	struct zk_node sender;
+	struct sheepdog_node_list_entry sender;
+
+	size_t buf_len;
+	uint8_t buf[MAX_EVENT_BUF_SIZE];
+
+	size_t nr_nodes; /* the number of sheep */
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 
 	enum cluster_join_result join_result;
 
@@ -79,102 +58,40 @@ struct zk_event {
 
 	int blocked; /* set non-zero when sheep must block this event */
 	int callbacked; /* set non-zero if sheep already called block_cb() */
-
-	size_t buf_len;
-	uint8_t buf[MAX_EVENT_BUF_SIZE];
 };
 
-static int zk_notify_blocked;
-
-/* leave event circular array */
-static struct zk_event zk_levents[SD_MAX_NODES];
-static int nr_zk_levents;
-static unsigned zk_levent_head;
-static unsigned zk_levent_tail;
-
-static void *zk_node_btroot;
-static struct zk_node *zk_master;
-static struct sd_node sd_nodes[SD_MAX_NODES];
-static size_t nr_sd_nodes;
-static size_t nr_zk_nodes;
-
-/* zookeeper API wrapper */
-inline ZOOAPI int zk_create(zhandle_t *zh, const char *path, const char *value,
-	int valuelen, const struct ACL_vector *acl, int flags,
-	char *path_buffer, int path_buffer_len)
-{
-	int rc;
-	do {
-		rc = zoo_create(zh, path, value, valuelen, acl,
-				flags, path_buffer, path_buffer_len);
-		if (rc != ZOK)
-			dprintf("rc:%d\n", rc);
-	} while (rc == ZOPERATIONTIMEOUT || rc == ZCONNECTIONLOSS);
-	return rc;
-}
 
-inline ZOOAPI int zk_delete(zhandle_t *zh, const char *path, int version)
-{
-	int rc;
-	do {
-		rc = zoo_delete(zh, path, version);
-		if (rc != ZOK)
-			dprintf("rc:%d\n", rc);
-	} while (rc == ZOPERATIONTIMEOUT || rc == ZCONNECTIONLOSS);
-	return rc;
-}
+/* ZooKeeper-based lock */
 
-inline ZOOAPI int zk_get(zhandle_t *zh, const char *path, int watch, char *buffer,
-		   int *buffer_len, struct Stat *stat)
+static void zk_lock(zhandle_t *zh)
 {
 	int rc;
-	do {
-		rc = zoo_get(zh, path, watch, buffer, buffer_len, stat);
-		if (rc != ZOK)
-			dprintf("rc:%d\n", rc);
-	} while (rc == ZOPERATIONTIMEOUT || rc == ZCONNECTIONLOSS);
-	return rc;
+again:
+	rc = zoo_create(zh, LOCK_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE,
+			ZOO_EPHEMERAL, NULL, 0);
+	if (rc == ZOK)
+		return;
+	else if (rc == ZNODEEXISTS) {
+		dprintf("retry\n");
+		usleep(10000); /* FIXME: use watch notification */
+		goto again;
+	} else
+		panic("failed to create a lock znode\n");
 }
 
-inline ZOOAPI int zk_set(zhandle_t *zh, const char *path, const char *buffer,
-		   int buflen, int version)
+static void zk_unlock(zhandle_t *zh)
 {
 	int rc;
-	do {
-		rc = zoo_set(zh, path, buffer, buflen, version);
-		if (rc != ZOK)
-			dprintf("rc:%d\n", rc);
-	} while (rc == ZOPERATIONTIMEOUT || rc == ZCONNECTIONLOSS);
-	return rc;
-}
 
-inline ZOOAPI int zk_exists(zhandle_t *zh, const char *path, int watch, struct Stat *stat)
-{
-	int rc;
-	do {
-		rc = zoo_exists(zh, path, watch, stat);
-		if (rc != ZOK)
-			dprintf("rc:%d\n", rc);
-	} while (rc == ZOPERATIONTIMEOUT || rc == ZCONNECTIONLOSS);
-	return rc;
+	rc = zoo_delete(zh, LOCK_ZNODE, -1);
+	if (rc != ZOK)
+		panic("failed to release lock\n");
 }
 
-inline ZOOAPI int zk_get_children(zhandle_t *zh, const char *path, int watch,
-			    struct String_vector *strings)
-{
-	int rc;
-	do {
-		rc = zoo_get_children(zh, path, watch, strings);
-		if (rc != ZOK)
-			dprintf("rc:%d\n", rc);
-	} while (rc == ZOPERATIONTIMEOUT || rc == ZCONNECTIONLOSS);
-	return rc;
-}
 
 /* ZooKeeper-based queue */
 
-static int efd;
-static int32_t queue_pos;
+static int queue_pos;
 
 static int zk_queue_empty(zhandle_t *zh)
 {
@@ -183,63 +100,43 @@ static int zk_queue_empty(zhandle_t *zh)
 
 	sprintf(path, QUEUE_ZNODE "/%010d", queue_pos);
 
-	rc = zk_exists(zh, path, 1, NULL);
+	rc = zoo_exists(zh, path, 1, NULL);
 	if (rc == ZOK)
 		return 0;
 
 	return 1;
 }
 
-static int32_t zk_queue_push(zhandle_t *zh, struct zk_event *ev)
+static void zk_queue_push(zhandle_t *zh, struct zk_event *ev)
 {
-	static int first_push = 1;
-	int32_t seq;
-	int rc, len;
+	int rc;
 	char path[256], buf[256];
-	eventfd_t value = 1;
 
-	len = (char *)(ev->buf) - (char *)ev + ev->buf_len;
 	sprintf(path, "%s/", QUEUE_ZNODE);
-	rc = zk_create(zh, path, (char *)ev, len,
-		&ZOO_OPEN_ACL_UNSAFE, ZOO_SEQUENCE, buf, sizeof(buf));
-	dprintf("create path:%s, nr_nodes:%ld, queue_pos:%010d, len:%d, rc:%d\n", buf, nr_zk_nodes, queue_pos, len, rc);
-	if (rc != ZOK)
-		panic("failed to zk_create path:%s, rc:%d\n", path, rc);
-
-	sscanf(buf, QUEUE_ZNODE "/%d", &seq);
-	dprintf("path:%s, seq:%010d\n", buf, seq);
+	rc = zoo_create(zh, path, (char *)ev, sizeof(*ev),
+			&ZOO_OPEN_ACL_UNSAFE, ZOO_SEQUENCE, buf, sizeof(buf));
 
-	if (first_push) {
-		queue_pos = seq;
+	if (queue_pos < 0) {
+		/* the first pushed data should be EVENT_JOIN */
+		assert(ev->type == EVENT_JOIN);
+		sscanf(buf, QUEUE_ZNODE "/%010d", &queue_pos);
 
-		/* manual notify */
-		dprintf("write event to efd:%d\n", efd);
-		eventfd_write(efd, value);
-
-		first_push = 0;
+		/* watch */
+		zoo_exists(zh, buf, 1, NULL);
 	}
-
-	return seq;
-
 }
 
 static int zk_queue_push_back(zhandle_t *zh, struct zk_event *ev)
 {
-	int rc, len;
+	int rc;
 	char path[256];
 
 	queue_pos--;
 
-	dprintf("queue_pos:%010d\n", queue_pos);
-
 	if (ev) {
 		/* update the last popped data */
-		len = (char *)(ev->buf) - (char *)ev + ev->buf_len;
 		sprintf(path, QUEUE_ZNODE "/%010d", queue_pos);
-		rc = zk_set(zh, path, (char *)ev, len, -1);
-		dprintf("update path:%s, queue_pos:%010d, len:%d, rc:%d\n", path, queue_pos, len, rc);
-		if (rc != ZOK)
-			panic("failed to zk_set path:%s, rc:%d\n", path, rc);
+		rc = zoo_set(zh, path, (char *)ev, sizeof(*ev), -1);
 	}
 
 	return 0;
@@ -248,292 +145,145 @@ static int zk_queue_push_back(zhandle_t
 static int zk_queue_pop(zhandle_t *zh, struct zk_event *ev)
 {
 	int rc, len;
-	int nr_levents;
 	char path[256];
-	struct zk_event *lev;
-	eventfd_t value = 1;
-
-	/* process leave event */
-	if (!__sync_add_and_fetch(&zk_notify_blocked, 0)
-		&& __sync_add_and_fetch(&nr_zk_levents, 0)) {
-		nr_levents = __sync_sub_and_fetch(&nr_zk_levents, 1) + 1;
-		dprintf("nr_zk_levents:%d, head:%u\n", nr_levents, zk_levent_head);
-
-		lev = &zk_levents[zk_levent_head%SD_MAX_NODES];
-
-		/* if the node pointed to by queue_pos was send by this leaver,
-		 * and it have blocked whole cluster, we should ignore it. */
-		len = sizeof(*ev);
-		sprintf(path, QUEUE_ZNODE "/%010d", queue_pos);
-		rc = zk_get(zh, path, 1, (char *)ev, &len, NULL);
-		if (rc == ZOK && node_cmp(&ev->sender.node, &lev->sender.node) == 0 && ev->blocked) {
-			dprintf("this queue_pos:%010d have blocked whole cluster, ignore it\n", queue_pos);
-			queue_pos++;
-
-			/* watch next data */
-			sprintf(path, QUEUE_ZNODE "/%010d", queue_pos);
-			rc = zk_exists(zh, path, 1, NULL);
-			dprintf("watch path:%s, exists:%d\n", path, (rc == ZOK));
-			if (rc == ZOK) {
-				/* we lost this message, manual notify */
-				dprintf("write event to efd:%d\n", efd);
-				eventfd_write(efd, value);
-			}
-		}
-
-		memcpy(ev, lev, sizeof(*ev));
-		zk_levent_head++;
-
-		if (__sync_add_and_fetch(&nr_zk_levents, 0) || rc == ZOK) {
-			/* we have pending leave events
-			 * or queue nodes, manual notify */
-			dprintf("write event to efd:%d\n", efd);
-			eventfd_write(efd, value);
-		}
-
-		return 0;
-	}
 
 	if (zk_queue_empty(zh))
 		return -1;
 
-	len = sizeof(*ev);
 	sprintf(path, QUEUE_ZNODE "/%010d", queue_pos);
-	rc = zk_get(zh, path, 1, (char *)ev, &len, NULL);
-	dprintf("read path:%s, nr_nodes:%ld, type:%d, len:%d, rc:%d\n", path, nr_zk_nodes, ev->type, len, rc);
-	if (rc != ZOK)
-		panic("failed to zk_set path:%s, rc:%d\n", path, rc);
-
-	queue_pos++;
-
-	/* this event will be pushed back to the queue,
-	 * we just wait for the arrival of its updated,
-	 * not need to watch next data. */
-	if (ev->blocked)
-		goto out;
+	len = sizeof(*ev);
+	rc = zoo_get(zh, path, 1, (char *)ev, &len, NULL);
 
 	/* watch next data */
+	queue_pos++;
 	sprintf(path, QUEUE_ZNODE "/%010d", queue_pos);
-	rc = zk_exists(zh, path, 1, NULL);
-	dprintf("watch path:%s, exists:%d\n", path, (rc == ZOK));
-	if (rc == ZOK) {
-		/* we lost this message, manual notify */
-		dprintf("write event to efd:%d\n", efd);
-		eventfd_write(efd, value);
-	}
+	zoo_exists(zh, path, 1, NULL);
 
-out:
 	return 0;
 }
 
-static int zk_member_empty(zhandle_t *zh)
+static int is_zk_queue_valid(zhandle_t *zh)
 {
-	int rc;
+	int rc, len;
 	struct String_vector strs;
+	uint64_t joined;
+	char path[256];
 
-	rc = zk_get_children(zh, MEMBER_ZNODE, 1, &strs);
-	if (rc != ZOK)
-		panic("failed to zk_get_children path:%s, rc:%d\n", MEMBER_ZNODE, rc);
-
-	return (strs.count == 0);
-}
-
-static inline int zk_node_cmp(const void *a, const void *b)
-{
-	const struct zk_node *znode1 = a;
-	const struct zk_node *znode2 = b;
-	return node_cmp(&znode1->node, &znode2->node);
-}
-
-static void node_btree_add(void **btroot, struct zk_node *znode)
-{
-	struct zk_node *n, **p;
-
-	n = (struct zk_node *)malloc(sizeof(struct zk_node));
-	if (n == NULL)
-		panic("malloc, oom\n");
-
-	*n = *znode;
+	FOR_EACH_ZNODE(zh, MEMBER_ZNODE, path, &strs) {
+		len = sizeof(joined);
+		rc = zoo_get(zh, path, 1, (char *)&joined, &len, NULL);
+		assert(rc == ZOK);
 
-	p = (struct zk_node **)tsearch((void *)n, btroot, zk_node_cmp);
-	if (p == NULL)
-		panic("tsearch, oom\n");
-	else if (*p != n) {
-		**p = *n;
-		free(n);
+		if (joined)
+			return 1;
 	}
-	nr_zk_nodes++;
-}
 
-static inline void node_btree_del(void **btroot, struct zk_node *znode)
-{
-	tdelete((void *)znode, btroot, zk_node_cmp);
-	free(znode);
-	nr_zk_nodes--;
+	return 0;
 }
 
-static inline void node_btree_clear(void **btroot)
+static void zk_queue_init(zhandle_t *zh)
 {
-	tdestroy(*btroot, free);
-	*btroot = NULL;
-}
+	int rc;
+	struct String_vector strs;
+	char path[256];
 
-static struct zk_node *node_btree_find(void **btroot, struct zk_node *znode)
-{
-	struct zk_node **p;
+	zoo_create(zh, BASE_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);
+	zoo_create(zh, QUEUE_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);
+	zoo_create(zh, MEMBER_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);
 
-	p = (struct zk_node **)tfind((void *)znode, btroot, zk_node_cmp);
-	if (p)
-		return *p;
+	zk_lock(zh);
 
-	return NULL;
-}
+	queue_pos = -1;
 
-static void node_btree_build_list_fn(const void *nodep,
-		const VISIT which, const int depth)
-{
-	struct zk_node *znode;
+	if (!is_zk_queue_valid(zh)) {
+		dprintf("clean zookeeper store\n");
 
-	switch (which) {
-	case preorder:
-		break;
-	case postorder:
-	case leaf:
-		znode = *(struct zk_node **) nodep;
-		sd_nodes[nr_sd_nodes++] = znode->node;
-		break;
-	case endorder:
-		break;
+		FOR_EACH_ZNODE(zh, MEMBER_ZNODE, path, &strs) {
+			rc = zoo_delete(zh, path, -1);
+			assert(rc == ZOK);
+		}
+
+		FOR_EACH_ZNODE(zh, QUEUE_ZNODE, path, &strs) {
+			rc = zoo_delete(zh, path, -1);
+			assert(rc == ZOK);
+		}
 	}
-}
 
-static inline void build_node_list(void *btroot)
-{
-	nr_sd_nodes = 0;
-	twalk(btroot, node_btree_build_list_fn);
-	assert(nr_sd_nodes == nr_zk_nodes);
-	dprintf("nr_sd_nodes:%lu\n", nr_sd_nodes);
+	zk_unlock(zh);
 }
 
-static void node_btree_find_master_fn(const void *nodep,
-		const VISIT which, const int depth)
-{
-	switch (which) {
-	case preorder:
-		break;
-	case postorder:
-	case leaf:
-		if (zk_master)
-			break;
-		zk_master = *(struct zk_node **) nodep;
-		dprintf("master:%s\n", node_to_str(&zk_master->node));
-		break;
-	case endorder:
-		break;
-	}
-}
 
-static int is_master(zhandle_t *zh, struct zk_node *znode)
-{
-	zk_master = NULL;
+/* ZooKeeper driver APIs */
 
-	if (!zk_node_btroot) {
-		if (zk_member_empty(zh))
-			return 1;
-		else
-			return 0;
-	}
+static zhandle_t *zhandle;
+static int efd;
 
-	twalk(zk_node_btroot, node_btree_find_master_fn);
-	if (node_cmp(&zk_master->node, &znode->node) == 0)
-		return 1;
+static struct work_queue *zk_block_wq;
 
-	return 0;
-}
+static struct sheepdog_node_list_entry this_node;
 
-static void zk_queue_init(zhandle_t *zh)
-{
-	zk_create(zh, BASE_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);
-	zk_create(zh, QUEUE_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);
-	zk_create(zh, MEMBER_ZNODE, "", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);
-}
+static struct cdrv_handlers zk_hdlrs;
+static enum cluster_join_result (*zk_check_join_cb)(
+	struct sheepdog_node_list_entry *joining, void *opaque);
 
-static void zk_member_init(zhandle_t *zh)
+/* get node list from the last pushed data */
+static size_t get_nodes(zhandle_t *zh, struct sheepdog_node_list_entry *nodes)
 {
-	static int finished;
 	int rc, len;
+	struct zk_event ev;
 	struct String_vector strs;
-	struct zk_node znode;
-	char path[256];
-
-	if (finished)
-		return;
-
-	finished = 1;
+	char path[256], max[256] = "";
 
-	if (!zk_member_empty(zh)) {
-		FOR_EACH_ZNODE(zh, MEMBER_ZNODE, path, &strs) {
-			len = sizeof(znode);
-			rc = zk_get(zh, path, 1, (char *)&znode, &len, NULL);
-			if (rc != ZOK)
-				continue;
-
-			switch (rc) {
-			case ZOK:
-				node_btree_add(&zk_node_btroot, &znode);
-			case ZNONODE:
-				break;
-			default:
-				panic("failed to zk_get path:%s, rc:%d\n", path, rc);
-			}
-		}
+	FOR_EACH_ZNODE(zh, QUEUE_ZNODE, path, &strs) {
+		if (strcmp(max, path) < 0)
+			strcpy(max, path);
 	}
-	dprintf("nr_nodes:%ld\n", nr_zk_nodes);
-}
-
 
-/* ZooKeeper driver APIs */
+	if (max[0] == '\0')
+		return 0;
 
-static zhandle_t *zhandle;
+	len = sizeof(ev);
+	rc = zoo_get(zh, max, 1, (char *)&ev, &len, NULL);
+	assert(rc == ZOK);
 
-static struct work_queue *zk_block_wq;
+	memcpy(nodes, ev.nodes, sizeof(ev.nodes));
 
-static struct zk_node this_node;
+	return ev.nr_nodes;
+}
 
 static int add_event(zhandle_t *zh, enum zk_event_type type,
-		     struct zk_node *znode, void *buf,
+		     struct sheepdog_node_list_entry *node, void *buf,
 		     size_t buf_len, void (*block_cb)(void *arg))
 {
-	int nr_levents;
-	struct zk_event ev, *lev;
-	eventfd_t value = 1;
+	int idx;
+	struct sheepdog_node_list_entry *n;
+	struct zk_event ev;
+
+	zk_lock(zh);
 
 	ev.type = type;
-	ev.sender = *znode;
+	ev.sender = *node;
 	ev.buf_len = buf_len;
-	ev.callbacked = 0;
-	ev.blocked = 0;
 	if (buf)
 		memcpy(ev.buf, buf, buf_len);
 
+	ev.nr_nodes = get_nodes(zh, ev.nodes);
+
 	switch (type) {
 	case EVENT_JOIN:
 		ev.blocked = 1;
+		ev.nodes[ev.nr_nodes] = *node;
+		ev.nr_nodes++;
 		break;
 	case EVENT_LEAVE:
-		lev = &zk_levents[zk_levent_tail%SD_MAX_NODES];
-
-		memcpy(lev, &ev, sizeof(ev));
-
-		nr_levents = __sync_add_and_fetch(&nr_zk_levents, 1);
-		dprintf("nr_zk_levents:%d, tail:%u\n", nr_levents, zk_levent_tail);
-
-		zk_levent_tail++;
+		n = lfind(node, ev.nodes, &ev.nr_nodes, sizeof(*n), node_cmp);
+		if (!n)
+			goto out;
+		idx = n - ev.nodes;
 
-		/* manual notify */
-		dprintf("write event to efd:%d\n", efd);
-		eventfd_write(efd, value);
-		goto out;
+		ev.nr_nodes--;
+		memmove(n, n + 1, sizeof(*n) * (ev.nr_nodes - idx));
+		break;
 	case EVENT_NOTIFY:
 		ev.blocked = !!block_cb;
 		ev.block_cb = block_cb;
@@ -542,52 +292,35 @@ static int add_event(zhandle_t *zh, enum
 
 	zk_queue_push(zh, &ev);
 out:
+	zk_unlock(zh);
+
 	return 0;
 }
 
 static void watcher(zhandle_t *zh, int type, int state, const char *path, void* ctx)
 {
 	eventfd_t value = 1;
-	const clientid_t *cid;
-	char str[256], *p;
-	int ret, rc;
-	struct zk_node znode;
-
-	dprintf("path:%s, type:%d\n", path, type);
-
-	if (type == -1) {
-		cid = zoo_client_id(zh);
-		assert(cid != NULL);
-		dprintf("session change, clientid:%ld\n", cid->client_id);
-	}
-
-	/* discard useless event */
-	if (type < 0 || type == ZOO_CHILD_EVENT)
-		return;
-
-	if (type == ZOO_CREATED_EVENT || type == ZOO_CHANGED_EVENT) {
-		ret = sscanf(path, MEMBER_ZNODE "/%s", str);
-		if (ret == 1) {
-			rc = zk_exists(zh, path, 1, NULL);
-			dprintf("watch path:%s, exists:%d\n", path, (rc == ZOK));
-		}
-	}
+	char str[256];
+	int ret, i;
+	size_t nr_nodes;
+	struct sheepdog_node_list_entry nodes[SD_MAX_NODES];
 
 	if (type == ZOO_DELETED_EVENT) {
-		ret = sscanf(path, MEMBER_ZNODE "/%s", str);
+		ret = sscanf(path, MEMBER_ZNODE "/%[^\n]", str);
 		if (ret != 1)
-			return;
-		p = strrchr(path, '/');
-		p++;
-
-		str_to_node(p, &znode.node);
-		dprintf("zk_nodes leave:%s\n", node_to_str(&znode.node));
+			goto out;
 
-		add_event(zh, EVENT_LEAVE, &znode, NULL, 0, NULL);
-		return;
+		/* check the failed node */
+		nr_nodes = get_nodes(zh, nodes);
+		for (i = 0; i < nr_nodes; i++) {
+			if (strcmp(str, node_to_str(nodes + i)) == 0) {
+				add_event(zh, EVENT_LEAVE, nodes + i, NULL, 0,
+					  NULL);
+				goto out;
+			}
+		}
 	}
-
-	dprintf("write event to efd:%d\n", efd);
+out:
 	eventfd_write(efd, value);
 }
 
@@ -601,7 +334,6 @@ static int get_addr(uint8_t *bytes)
 
 	memset(&hints, 0, sizeof(hints));
 
-	hints.ai_family = AF_INET;
 	hints.ai_socktype = SOCK_STREAM;
 	ret = getaddrinfo(name, NULL, &hints, &res0);
 	if (ret)
@@ -644,21 +376,21 @@ static int get_addr(uint8_t *bytes)
 	return 0;
 }
 
-static int zk_init(const char *option, uint8_t *myaddr)
+static int zk_init(struct cdrv_handlers *handlers, const char *option,
+		   uint8_t *myaddr)
 {
+	zk_hdlrs = *handlers;
 	if (!option) {
 		eprintf("specify comma separated host:port pairs, each corresponding to a zk server.\n");
 		eprintf("e.g. sheep /store -c zookeeper:127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\n");
 		return -1;
 	}
 
-	zhandle = zookeeper_init(option, watcher, SESSION_TIMEOUT, 0, NULL, 0);
+	zhandle = zookeeper_init(option, watcher, 10000, 0, NULL, 0);
 	if (!zhandle) {
 		eprintf("failed to connect to zk server %s\n", option);
 		return -1;
 	}
-	dprintf("request session timeout:%dms, negotiated session timeout:%dms\n",
-			SESSION_TIMEOUT, zoo_recv_timeout(zhandle));
 
 	if (get_addr(myaddr) < 0)
 		return -1;
@@ -672,46 +404,36 @@ static int zk_init(const char *option, u
 	}
 
 	zk_block_wq = init_work_queue(1);
-	if (!zk_block_wq) {
-		eprintf("failed to create zookeeper workqueue: %m\n");
-		return -1;
-	}
 
 	return efd;
 }
 
-static int zk_join(struct sd_node *myself,
+static int zk_join(struct sheepdog_node_list_entry *myself,
+		   enum cluster_join_result (*check_join_cb)(
+			   struct sheepdog_node_list_entry *joining,
+			   void *opaque),
 		   void *opaque, size_t opaque_len)
 {
 	int rc;
+	uint64_t joined;
 	char path[256];
-	const clientid_t *cid;
 
-	this_node.node = *myself;
+	this_node = *myself;
+	zk_check_join_cb = check_join_cb;
 
 	sprintf(path, MEMBER_ZNODE "/%s", node_to_str(myself));
-	rc = zk_exists(zhandle, path, 1, NULL);
-	if (rc == ZOK)
-		panic("previous zookeeper session exist, shutdown\n");
-
-	this_node.joined = 0;
-	cid = zoo_client_id(zhandle);
-	assert(cid != NULL);
-	this_node.clientid = *cid;
-
-	dprintf("clientid:%ld\n", cid->client_id);
-
-	rc = add_event(zhandle, EVENT_JOIN, &this_node, opaque, opaque_len, NULL);
+	joined = 0;
+	rc = zoo_create(zhandle, path, (char *)&joined, sizeof(joined),
+			&ZOO_OPEN_ACL_UNSAFE, ZOO_EPHEMERAL, NULL, 0);
+	if (rc != ZOK)
+		panic("failed to create an ephemeral znode\n");
 
-	return rc;
+	return add_event(zhandle, EVENT_JOIN, &this_node, opaque, opaque_len, NULL);
 }
 
 static int zk_leave(void)
 {
-	char path[256];
-	sprintf(path, MEMBER_ZNODE "/%s", node_to_str(&this_node.node));
-	dprintf("try to delete member path:%s\n", path);
-	return zk_delete(zhandle, path, -1);
+	return add_event(zhandle, EVENT_LEAVE, &this_node, NULL, 0, NULL);
 }
 
 static int zk_notify(void *msg, size_t msg_len, void (*block_cb)(void *arg))
@@ -721,23 +443,14 @@ static int zk_notify(void *msg, size_t m
 
 static void zk_block(struct work *work)
 {
-	int rc;
 	struct zk_event ev;
-	eventfd_t value = 1;
 
-	rc = zk_queue_pop(zhandle, &ev);
-	assert(rc == 0);
+	zk_queue_pop(zhandle, &ev);
 
 	ev.block_cb(ev.buf);
 	ev.blocked = 0;
 
 	zk_queue_push_back(zhandle, &ev);
-
-	__sync_sub_and_fetch(&zk_notify_blocked, 1);
-
-	/* this notify is necessary */
-	dprintf("write event to efd:%d\n", efd);
-	eventfd_write(efd, value);
 }
 
 static void zk_block_done(struct work *work)
@@ -746,11 +459,11 @@ static void zk_block_done(struct work *w
 
 static int zk_dispatch(void)
 {
-	int ret, rc, retry;
+	int ret, rc;
 	char path[256];
+	uint64_t joined;
 	eventfd_t value;
 	struct zk_event ev;
-	struct zk_node *n;
 	enum cluster_join_result res;
 	static struct work work = {
 		.fn = zk_block,
@@ -762,26 +475,23 @@ static int zk_dispatch(void)
 	if (ret < 0)
 		return 0;
 
-	if (__sync_add_and_fetch(&zk_notify_blocked, 0))
-		return 0;
-
 	ret = zk_queue_pop(zhandle, &ev);
 	if (ret < 0)
 		goto out;
 
 	switch (ev.type) {
 	case EVENT_JOIN:
-		dprintf("JOIN EVENT, blocked:%d\n", ev.blocked);
 		if (ev.blocked) {
-			dprintf("one sheep joined[up], nr_nodes:%ld, sender:%s, joined:%d\n",
-					nr_zk_nodes, node_to_str(&ev.sender.node), ev.sender.joined);
-			if (is_master(zhandle, &this_node)) {
-				res = sd_check_join_cb(&ev.sender.node, ev.buf);
+			if (node_cmp(&ev.nodes[0], &this_node) == 0) {
+				res = zk_check_join_cb(&ev.sender, ev.buf);
 				ev.join_result = res;
 				ev.blocked = 0;
-				ev.sender.joined = 1;
 
-				dprintf("I'm master, push back join event\n");
+				sprintf(path, MEMBER_ZNODE "/%s", node_to_str(&ev.sender));
+				joined = 1;
+				rc = zoo_set(zhandle, path, (char *)&joined, sizeof(joined), -1);
+				assert(rc == ZOK);
+
 				zk_queue_push_back(zhandle, &ev);
 
 				if (res == CJ_RES_MASTER_TRANSFER) {
@@ -793,89 +503,41 @@ static int zk_dispatch(void)
 				zk_queue_push_back(zhandle, NULL);
 
 			goto out;
-		} else if (is_master(zhandle, &this_node)
-			&& node_cmp(&ev.sender.node, &this_node.node) != 0) {
-			/* wait util member have been created */
-			sprintf(path, MEMBER_ZNODE "/%s", node_to_str(&ev.sender.node));
-			retry = MEMBER_CREATE_TIMEOUT/MEMBER_CREATE_INTERVAL;
-			while (retry && zk_exists(zhandle, path, 1, NULL) == ZNONODE) {
-				usleep(MEMBER_CREATE_INTERVAL*1000);
-				retry--;
-			}
-			if (retry <= 0) {
-				dprintf("Sender:%s failed to create member, ignore it\n",
-						node_to_str(&ev.sender.node));
-				goto out;
-			}
 		}
 
-		if (node_cmp(&ev.sender.node, &this_node.node) == 0)
-			zk_member_init(zhandle);
-
 		if (ev.join_result == CJ_RES_MASTER_TRANSFER) {
-			/* FIXME: This code is tricky, but Sheepdog assumes that
-			 * nr_nodes = 1 when join_result = MASTER_TRANSFER... */
-			node_btree_clear(&zk_node_btroot);
-			node_btree_add(&zk_node_btroot, &this_node);
-
+			/* FIXME: This code is tricky, but Sheepdog assumes that */
+			/* nr_nodes = 1 when join_result = MASTER_TRANSFER... */
+			ev.nr_nodes = 1;
+			ev.nodes[0] = this_node;
 			zk_queue_push_back(zhandle, &ev);
 			zk_queue_pop(zhandle, &ev);
 		}
 
-		node_btree_add(&zk_node_btroot, &ev.sender);
-		dprintf("one sheep joined[down], nr_nodes:%ld, sender:%s, joined:%d\n",
-				nr_zk_nodes, node_to_str(&ev.sender.node), ev.sender.joined);
-
-		if (ev.join_result == CJ_RES_SUCCESS) {
-			sprintf(path, MEMBER_ZNODE "/%s", node_to_str(&ev.sender.node));
-			if (node_cmp(&ev.sender.node, &this_node.node) == 0) {
-				dprintf("create path:%s\n", path);
-				rc = zk_create(zhandle, path, (char *)&ev.sender, sizeof(ev.sender),
-					&ZOO_OPEN_ACL_UNSAFE, ZOO_EPHEMERAL, NULL, 0);
-				if (rc != ZOK)
-					panic("failed to create an ephemeral znode, rc:%d\n", rc);
-			} else {
-				rc = zk_exists(zhandle, path, 1, NULL);
-				dprintf("watch path:%s, exists:%d\n", path, (rc == ZOK));
-			}
-		}
+		sprintf(path, MEMBER_ZNODE "/%s", node_to_str(&ev.sender));
+		zoo_exists(zhandle, path, 1, NULL);
 
-		build_node_list(zk_node_btroot);
-		sd_join_handler(&ev.sender.node, sd_nodes, nr_sd_nodes,
+		zk_hdlrs.join_handler(&ev.sender, ev.nodes, ev.nr_nodes,
 				    ev.join_result, ev.buf);
 		break;
 	case EVENT_LEAVE:
-		dprintf("LEAVE EVENT, blocked:%d\n", ev.blocked);
-		n = node_btree_find(&zk_node_btroot, &ev.sender);
-		if (!n) {
-			dprintf("can't find this leave node:%s, ignore it.\n", node_to_str(&ev.sender.node));
-			goto out;
-		}
-
-		node_btree_del(&zk_node_btroot, n);
-		dprintf("one sheep left, nr_nodes:%ld\n", nr_zk_nodes);
-
-		build_node_list(zk_node_btroot);
-		sd_leave_handler(&ev.sender.node, sd_nodes, nr_sd_nodes);
+		zk_hdlrs.leave_handler(&ev.sender, ev.nodes, ev.nr_nodes);
 		break;
 	case EVENT_NOTIFY:
-		dprintf("NOTIFY, blocked:%d\n", ev.blocked);
 		if (ev.blocked) {
-			if (node_cmp(&ev.sender.node, &this_node.node) == 0 && !ev.callbacked) {
-				ev.callbacked = 1;
+			if (node_cmp(&ev.sender, &this_node) == 0 && !ev.callbacked) {
+				queue_work(zk_block_wq, &work);
 
-				__sync_add_and_fetch(&zk_notify_blocked, 1);
+				ev.callbacked = 1;
 
 				zk_queue_push_back(zhandle, &ev);
-
-				queue_work(zk_block_wq, &work);
 			} else
 				zk_queue_push_back(zhandle, NULL);
 
 			goto out;
 		}
 
-		sd_notify_handler(&ev.sender.node, ev.buf, ev.buf_len);
+		zk_hdlrs.notify_handler(&ev.sender, ev.buf, ev.buf_len);
 		break;
 	}
 out:
--- sheepdog-0.3.0.orig/lib/Makefile.am
+++ sheepdog-0.3.0/lib/Makefile.am
@@ -4,4 +4,4 @@ INCLUDES                = -I$(top_buildd
 
 noinst_LIBRARIES	= libsheepdog.a
 
-libsheepdog_a_SOURCES	= event.c logger.c net.c util.c rbtree.c ring_buffer.c
+libsheepdog_a_SOURCES	= event.c logger.c net.c util.c coroutine.c
--- sheepdog-0.3.0.orig/lib/net.c
+++ sheepdog-0.3.0/lib/net.c
@@ -70,12 +70,7 @@ int rx(struct connection *conn, enum con
 	int ret;
 
 	ret = read(conn->fd, conn->rx_buf, conn->rx_length);
-	if (!ret) {
-		conn->c_rx_state = C_IO_CLOSED;
-		return 0;
-	}
-
-	if (ret < 0) {
+	if (!ret || ret < 0) {
 		if (errno != EAGAIN)
 			conn->c_rx_state = C_IO_CLOSED;
 		return 0;
@@ -153,7 +148,7 @@ int create_listen_ports(int port, int (*
 
 		ret = bind(fd, res->ai_addr, res->ai_addrlen);
 		if (ret) {
-			eprintf("failed to bind server socket: %m\n");
+			fprintf(stderr, "failed to bind server socket: %m\n");
 			close(fd);
 			continue;
 		}
@@ -203,7 +198,7 @@ int connect_to(const char *name, int por
 
 	ret = getaddrinfo(name, buf, &hints, &res0);
 	if (ret) {
-		eprintf("failed to get address info: %m\n");
+		fprintf(stderr, "failed to get address info: %m\n");
 		return -1;
 	}
 
@@ -228,7 +223,7 @@ int connect_to(const char *name, int por
 
 		ret = connect(fd, res->ai_addr, res->ai_addrlen);
 		if (ret)
-			eprintf("failed to connect to %s:%d: %m\n",
+			fprintf(stderr, "failed to connect to %s:%d: %m\n",
 				name, port);
 		else
 			goto success;
@@ -249,7 +244,7 @@ reread:
 	if (ret < 0 || !ret) {
 		if (errno == EINTR)
 			goto reread;
-		eprintf("failed to read from socket: %m\n");
+		fprintf(stderr, "failed to read from socket: %m\n");
 		return 1;
 	}
 
@@ -282,7 +277,7 @@ rewrite:
 	if (ret < 0) {
 		if (errno == EINTR)
 			goto rewrite;
-		eprintf("failed to write to socket: %m\n");
+		fprintf(stderr, "failed to write to socket: %m\n");
 		return 1;
 	}
 
@@ -336,7 +331,7 @@ int exec_req(int sockfd, struct sd_req *
 
 	ret = do_read(sockfd, rsp, sizeof(*rsp));
 	if (ret) {
-		eprintf("failed to read a response: %m\n");
+		fprintf(stderr, "failed to read a response: %m\n");
 		return 1;
 	}
 
@@ -346,7 +341,7 @@ int exec_req(int sockfd, struct sd_req *
 	if (*rlen) {
 		ret = do_read(sockfd, data, *rlen);
 		if (ret) {
-			eprintf("failed to read the response data: %m\n");
+			fprintf(stderr, "failed to read the response data: %m\n");
 			return 1;
 		}
 	}
@@ -377,20 +372,6 @@ char *addr_to_str(char *str, int size, u
 	return str;
 }
 
-uint8_t *str_to_addr(int af, const char *ipstr, uint8_t *addr)
-{
-	int addr_start_idx = 0;
-
-	if (af == AF_INET)
-		addr_start_idx = 12;
-
-	memset(addr, 0, addr_start_idx);
-	if (!inet_pton(af, ipstr, addr + addr_start_idx))
-		return NULL;
-
-	return addr;
-}
-
 int set_nonblocking(int fd)
 {
 	int ret;
--- sheepdog-0.3.0.orig/lib/logger.c
+++ sheepdog-0.3.0/lib/logger.c
@@ -28,7 +28,6 @@
 #include <sys/types.h>
 #include <sys/wait.h>
 #include <sys/prctl.h>
-#include <pthread.h>
 
 #include "logger.h"
 #include "util.h"
@@ -48,17 +47,11 @@ static void dolog(int prio, const char *
 
 static struct logarea *la;
 static char *log_name;
-static char *log_nowname;
 static int log_level = SDOG_INFO;
-static pid_t sheep_pid;
-static pid_t logger_pid;
+static pid_t pid;
 static key_t semkey;
 
-static int64_t max_logsize = 500 * 1024 * 1024;  /*500MB*/
-
-pthread_mutex_t logsize_lock = PTHREAD_MUTEX_INITIALIZER;
-
-static notrace int logarea_init(int size)
+static int logarea_init(int size)
 {
 	int shmid;
 
@@ -140,7 +133,7 @@ static notrace int logarea_init(int size
 	return 0;
 }
 
-static void notrace free_logarea(void)
+static void free_logarea(void)
 {
 	if (la->fd >= 0)
 		close(la->fd);
@@ -171,7 +164,7 @@ static void dump_logarea(void)
 }
 #endif
 
-static notrace int log_enqueue(int prio, const char *func, int line, const char *fmt,
+static int log_enqueue(int prio, const char *func, int line, const char *fmt,
 		       va_list ap)
 {
 	int len, fwd;
@@ -243,7 +236,7 @@ static notrace int log_enqueue(int prio,
 	return 0;
 }
 
-static notrace int log_dequeue(void *buff)
+static int log_dequeue(void *buff)
 {
 	struct logmsg * src = (struct logmsg *)la->head;
 	struct logmsg * dst = (struct logmsg *)buff;
@@ -276,7 +269,7 @@ static notrace int log_dequeue(void *buf
 /*
  * this one can block under memory pressure
  */
-static notrace void log_syslog(void *buff)
+static void log_syslog(void * buff)
 {
 	struct logmsg * msg = (struct logmsg *)buff;
 
@@ -286,11 +279,14 @@ static notrace void log_syslog(void *buf
 		syslog(msg->prio, "%s", (char *)&msg->str);
 }
 
-static notrace void dolog(int prio, const char *func, int line,
-		const char *fmt, va_list ap)
+static void dolog(int prio, const char *func, int line, const char *fmt, va_list ap)
 {
+	struct timespec ts;
+	struct sembuf ops;
+
 	if (la) {
-		struct sembuf ops;
+		ts.tv_sec = 0;
+		ts.tv_nsec = 10000;
 
 		ops.sem_num = 0;
 		ops.sem_flg = SEM_UNDO;
@@ -321,30 +317,7 @@ static notrace void dolog(int prio, cons
 	}
 }
 
-static notrace void rotate_log(void)
-{
-	int new_fd;
-
-	if (access(log_nowname, R_OK) == 0) {
-		char old_logfile[256];
-		time_t t;
-		struct tm tm;
-		time(&t);
-		localtime_r((const time_t *)&t, &tm);
-		sprintf(old_logfile, "%s.%04d-%02d-%02d-%02d-%02d",
-				log_nowname, tm.tm_year + 1900, tm.tm_mon + 1,
-				tm.tm_mday, tm.tm_hour, tm.tm_min);
-		rename(log_nowname, old_logfile);
-	}
-	new_fd = open(log_nowname, O_RDWR | O_CREAT | O_APPEND, 0644);
-	if (new_fd < 0)
-		syslog(LOG_ERR, "fail to create new log file\n");
-
-	dup2(new_fd, la->fd);
-	la->fd = new_fd;
-}
-
-notrace void log_write(int prio, const char *func, int line, const char *fmt, ...)
+void log_write(int prio, const char *func, int line, const char *fmt, ...)
 {
 	va_list ap;
 
@@ -356,7 +329,7 @@ notrace void log_write(int prio, const c
 	va_end(ap);
 }
 
-static notrace void log_flush(void)
+static void log_flush(void)
 {
 	struct sembuf ops;
 
@@ -380,40 +353,25 @@ static notrace void log_flush(void)
 	}
 }
 
-static notrace void crash_handler(int signo)
+static void log_sigsegv(void)
 {
-	if (signo == SIGSEGV) {
-		vprintf(SDOG_ERR, "logger pid %d segfaulted.\n",
-			getpid());
-	} else if (signo == SIGHUP) {
-		vprintf(SDOG_ERR, "sheep pid %d exited unexpectedly.\n",
-			sheep_pid);
-	} else {
-		vprintf(SDOG_ERR, "logger pid %d got unexpected signal %d.\n",
-			getpid(), signo);
-	}
-
+	vprintf(SDOG_ERR, "logger pid %d exiting abnormally\n", getpid());
 	log_flush();
 	closelog();
 	free_logarea();
 	exit(1);
 }
 
-notrace int log_init(char *program_name, int size, int to_stdout, int level,
-		char *outfile)
+int log_init(char *program_name, int size, int is_daemon, int level, char *outfile)
 {
-	off_t offset;
-	size_t log_size;
-
 	log_level = level;
 
 	logdbg(stderr, "entering log_init\n");
 	log_name = program_name;
-	log_nowname = outfile;
 
 	semkey = random();
 
-	if (!to_stdout) {
+	if (is_daemon) {
 		struct sigaction sa_old;
 		struct sigaction sa_new;
 		int fd;
@@ -437,21 +395,12 @@ notrace int log_init(char *program_name,
 
 		la->active = 1;
 		la->fd = fd;
-
-		/*
-		 * Store the pid of the sheep process for use by the death
-		 * signal handler.  By the time the child is notified of
-		 * the parents death the parent has been reparanted to init
-		 * and getppid() will always return 1.
-		 */
-		sheep_pid = getpid();
-
-		logger_pid = fork();
-		if (logger_pid < 0) {
+		pid = fork();
+		if (pid < 0) {
 			syslog(LOG_ERR, "failed to fork the logger process: %m\n");
 			return 1;
-		} else if (logger_pid) {
-			syslog(LOG_WARNING, "logger pid %d starting\n", logger_pid);
+		} else if (pid) {
+			syslog(LOG_WARNING, "logger pid %d starting\n", pid);
 			return 0;
 		}
 
@@ -470,32 +419,16 @@ notrace int log_init(char *program_name,
 			exit(1);
 		}
 
-		/* flush when either the logger or its parent dies */
-		sa_new.sa_handler = crash_handler;
-		sa_new.sa_flags = 0;
+		/* flush on daemon's crash */
+		sa_new.sa_handler = (void*)log_sigsegv;
 		sigemptyset(&sa_new.sa_mask);
+		sa_new.sa_flags = 0;
+		sigaction(SIGSEGV, &sa_new, &sa_old );
 
-		sigaction(SIGSEGV, &sa_new, &sa_old);
-		sigaction(SIGHUP, &sa_new, &sa_old);
-
-		prctl(PR_SET_PDEATHSIG, SIGHUP);
+		prctl(PR_SET_PDEATHSIG, SIGSEGV);
 
 		while (la->active) {
 			log_flush();
-
-			if (max_logsize) {
-				pthread_mutex_lock(&logsize_lock);
-				offset = lseek(la->fd, 0, SEEK_END);
-				if (offset < 0) {
-					syslog(LOG_ERR, "sheep log error\n");
-				} else {
-					log_size = (size_t)offset;
-					if (log_size >= max_logsize)
-						rotate_log();
-				}
-				pthread_mutex_unlock(&logsize_lock);
-			}
-
 			sleep(1);
 		}
 
@@ -505,13 +438,13 @@ notrace int log_init(char *program_name,
 	return 0;
 }
 
-notrace void log_close(void)
+void log_close(void)
 {
 	if (la) {
 		la->active = 0;
-		waitpid(logger_pid, NULL, 0);
+		waitpid(pid, NULL, 0);
 
-		vprintf(SDOG_WARNING, "logger pid %d stopped\n", logger_pid);
+		vprintf(SDOG_WARNING, "logger pid %d stopped\n", pid);
 		log_flush();
 		closelog();
 		free_logarea();
--- /dev/null
+++ sheepdog-0.3.0/lib/coroutine.c
@@ -0,0 +1,330 @@
+/*
+ * Copyright (C) 2011 MORITA Kazutaka <morita.kazutaka@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.0 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, see <http://www.gnu.org/licenses/>.
+ *
+ * This code is based on coroutine-ucontext.c and qemu-coroutine.c from QEMU:
+ *   Copyright (C) 2006 Anthony Liguori <anthony@codemonkey.ws>
+ *   Copyright (C) 2011 Stefan Hajnoczi <stefanha@linux.vnet.ibm.com>
+ *   Copyright (C) 2011 Kevin Wolf <kwolf@redhat.com>
+ */
+
+/* disable glibc's stack check for longjmp which doesn't work well
+ * with our code */
+#ifdef _FORTIFY_SOURCE
+#undef _FORTIFY_SOURCE
+#endif
+
+#include <stdlib.h>
+#include <setjmp.h>
+#include <stdint.h>
+#include <ucontext.h>
+#include <errno.h>
+#include <assert.h>
+#include <arpa/inet.h>
+#include <netinet/in.h>
+#include <netinet/tcp.h>
+#include <sys/socket.h>
+
+#include "util.h"
+#include "coroutine.h"
+
+enum co_action {
+	COROUTINE_YIELD = 1,
+	COROUTINE_TERMINATE = 2,
+};
+
+/* Maximum free pool size prevents holding too many freed coroutines */
+#ifdef COROUTINE_DEBUG
+#define POOL_MAX_SIZE   1
+#else
+#define POOL_MAX_SIZE   64
+#endif
+
+#define STACK_MAX_SIZE (1 << 20)  /* 1 MB */
+
+struct coroutine {
+	coroutine_entry_func_t *entry;
+	void *entry_arg;
+	struct coroutine *caller;
+	struct list_head pool_next;
+	struct list_head co_queue_next;
+};
+
+struct co_ucontext {
+	struct coroutine base;
+	void *stack;
+	jmp_buf env;
+};
+
+/**
+ * Per-thread coroutine bookkeeping
+ */
+__thread struct co_thread_state{
+	/** Currently executing coroutine */
+	struct coroutine *current;
+
+	/** Free list to speed up creation */
+	struct list_head pool;
+	unsigned int pool_size;
+
+	/** The default coroutine */
+	struct co_ucontext leader;
+} co_ts;
+
+static enum co_action coroutine_switch(struct coroutine *from,
+				       struct coroutine *to,
+				       enum co_action action);
+
+/*
+ * va_args to makecontext() must be type 'int', so passing
+ * the pointer we need may require several int args. This
+ * union is a quick hack to let us do that
+ */
+union cc_arg {
+	void *p;
+	int i[2];
+};
+
+static struct co_thread_state *coroutine_get_thread_state(void)
+{
+	struct co_thread_state *s = &co_ts;
+
+	if (!s->current) {
+		s->current = &s->leader.base;
+		INIT_LIST_HEAD(&s->pool);
+	}
+	return s;
+}
+
+static void coroutine_trampoline(int i0, int i1)
+{
+	union cc_arg arg;
+	struct co_ucontext *self;
+	struct coroutine *co;
+
+	arg.i[0] = i0;
+	arg.i[1] = i1;
+	self = arg.p;
+	co = &self->base;
+
+	/* Initialize longjmp environment and switch back the caller */
+	if (!setjmp(self->env))
+		longjmp(*(jmp_buf *)co->entry_arg, 1);
+
+	for (;;) {
+		co->entry(co->entry_arg);
+		coroutine_switch(co, co->caller, COROUTINE_TERMINATE);
+	}
+}
+
+#ifdef COROUTINE_DEBUG
+
+#define MAGIC_NUMBER 0x1234567890123456
+
+static void init_stack(struct co_ucontext *co)
+{
+	uint64_t *stack = co->stack;
+	int i;
+
+	for (i = 0; i < STACK_MAX_SIZE / sizeof(stack[0]); i++)
+		stack[i] = MAGIC_NUMBER;
+}
+
+static int get_stack_size(struct co_ucontext *co)
+{
+	uint64_t *stack = co->stack;
+	int i;
+
+	for (i = 0; i < STACK_MAX_SIZE / sizeof(stack[0]); i++)
+		if (stack[i] != MAGIC_NUMBER)
+			break;
+
+	if (i == 0) {
+		fprintf(stderr, "stack overflow\n");
+		fflush(stderr);
+		abort();
+	}
+
+	return STACK_MAX_SIZE - i * sizeof(stack[0]);
+}
+
+#endif
+
+static struct coroutine *__coroutine_new(void)
+{
+	const size_t stack_size = STACK_MAX_SIZE;
+	struct co_ucontext *co;
+	ucontext_t old_uc, uc;
+	jmp_buf old_env;
+	union cc_arg arg = {0};
+
+	/* The ucontext functions preserve signal masks which incurs a
+	 * system call overhead.  setjmp()/longjmp() does not preserve
+	 * signal masks but only works on the current stack.  Since we
+	 * need a way to create and switch to a new stack, use the
+	 * ucontext functions for that but setjmp()/longjmp() for
+	 * everything else.
+	 */
+
+	if (getcontext(&uc) == -1)
+		abort();
+
+	co = zalloc(sizeof(*co));
+	if (!co)
+		abort();
+	co->stack = zalloc(stack_size);
+	if (!co->stack)
+		abort();
+#ifdef COROUTINE_DEBUG
+	init_stack(co);
+#endif
+	co->base.entry_arg = &old_env; /* stash away our jmp_buf */
+
+	uc.uc_link = &old_uc;
+	uc.uc_stack.ss_sp = co->stack;
+	uc.uc_stack.ss_size = stack_size;
+	uc.uc_stack.ss_flags = 0;
+
+	arg.p = co;
+
+	makecontext(&uc, (void (*)(void))coroutine_trampoline,
+		    2, arg.i[0], arg.i[1]);
+
+	/* swapcontext() in, longjmp() back out */
+	if (!setjmp(old_env))
+		swapcontext(&old_uc, &uc);
+
+	return &co->base;
+}
+
+static struct coroutine *coroutine_new(void)
+{
+	struct co_thread_state *s = coroutine_get_thread_state();
+	struct coroutine *co;
+
+	if (!list_empty(&s->pool)) {
+		co = list_first_entry(&s->pool, struct coroutine, pool_next);
+		list_del(&co->pool_next);
+		s->pool_size--;
+	} else
+		co = __coroutine_new();
+
+	return co;
+}
+
+static void coroutine_delete(struct coroutine *co_)
+{
+	struct co_thread_state *s = coroutine_get_thread_state();
+	struct co_ucontext *co = container_of(co_, struct co_ucontext, base);
+
+#ifdef COROUTINE_DEBUG
+	fprintf(stdout, "%d bytes are consumed\n", get_stack_size(co));
+#endif
+
+	if (s->pool_size < POOL_MAX_SIZE) {
+		list_add(&co->base.pool_next, &s->pool);
+		co->base.caller = NULL;
+		s->pool_size++;
+		return;
+	}
+
+	free(co->stack);
+	free(co);
+}
+
+static enum co_action coroutine_switch(struct coroutine *from_,
+				       struct coroutine *to_,
+				       enum co_action action)
+{
+	struct co_ucontext *from = container_of(from_, struct co_ucontext, base);
+	struct co_ucontext *to = container_of(to_, struct co_ucontext, base);
+	struct co_thread_state *s = coroutine_get_thread_state();
+	int ret;
+
+	s->current = to_;
+
+	ret = setjmp(from->env);
+	if (ret == 0)
+		longjmp(to->env, action);
+
+	return ret;
+}
+
+struct coroutine *coroutine_self(void)
+{
+	struct co_thread_state *s = coroutine_get_thread_state();
+
+	return s->current;
+}
+
+int in_coroutine(void)
+{
+	struct co_thread_state *s = &co_ts;
+
+	return s->current && s->current->caller;
+}
+
+
+struct coroutine *coroutine_create(coroutine_entry_func_t *entry)
+{
+	struct coroutine *co = coroutine_new();
+	co->entry = entry;
+	return co;
+}
+
+static void coroutine_swap(struct coroutine *from, struct coroutine *to)
+{
+	enum co_action ret;
+
+	ret = coroutine_switch(from, to, COROUTINE_YIELD);
+
+	switch (ret) {
+	case COROUTINE_YIELD:
+		return;
+	case COROUTINE_TERMINATE:
+		coroutine_delete(to);
+		return;
+	default:
+		abort();
+	}
+}
+
+void coroutine_enter(struct coroutine *co, void *opaque)
+{
+	struct coroutine *self = coroutine_self();
+
+	if (co->caller) {
+		fprintf(stderr, "Co-routine re-entered recursively\n");
+		abort();
+	}
+
+	co->caller = self;
+	co->entry_arg = opaque;
+	coroutine_swap(self, co);
+}
+
+void coroutine_yield(void)
+{
+	struct coroutine *self = coroutine_self();
+	struct coroutine *to = self->caller;
+
+	if (!to) {
+		fprintf(stderr, "Co-routine is yielding to no one\n");
+		abort();
+	}
+
+	self->caller = NULL;
+	coroutine_swap(self, to);
+}
--- sheepdog-0.3.0.orig/tests/test_membership.py
+++ sheepdog-0.3.0/tests/test_membership.py
@@ -54,6 +54,9 @@ def test_mastership():
         n.start()
         n.wait()
 
+    # FIXME: should be smarter than this
+    time.sleep(0.5)
+
     # only nodes[2] should be in the cluster
     p = sdog.nodes[2].run_collie('node list -r')
     (out, _) = p.communicate()
@@ -63,6 +66,8 @@ def test_mastership():
     sdog.nodes[0].wait()
     sdog.nodes[1].start()
     sdog.nodes[1].wait()
+    # FIXME: should be smarter than this
+    time.sleep(0.5)
 
     for n in sdog.nodes:
         p = n.run_collie('node list -r')
--- /dev/null
+++ sheepdog-0.3.0/script/check-dog.pl
@@ -0,0 +1,135 @@
+#!/usr/bin/perl
+
+use strict;
+
+my ($store, $min_node, $max_node) = @ARGV;
+
+$store = "/tmp/".rand(100)  unless $store;
+$min_node = 3  unless $min_node;
+$max_node = 5  unless $max_node;
+
+sub command {
+    my ($cmd) = @_;
+    print "$cmd\n";
+    system "$cmd";
+}
+
+sub start_sdog {
+    my ($n) = @_;
+    my $port = 7000 + $n;
+    &command("./collie/collie --port $port $store/$n/ -d");
+}
+
+sub stop_sdog {
+    my ($n) = @_;
+    &command("./script/stop-sheepdog $n");
+}
+
+sub shuffle {
+    my @list =@_;
+
+    for my $i ( 0..$#list ) {
+        my $rand=int(rand(@list));
+        my $tmp=$list[$i];
+        $list[$i]=$list[$rand];
+        $list[$rand]=$tmp;
+    }
+    @list
+}
+
+print("** setup **");
+&command("make clean");
+&command("make");
+
+print("kill all sheeps and dogs\n");
+foreach my $n (0..10) {
+    &stop_sdog($n);
+}
+
+print("clean up $store\n");
+&command("rm $store/[0-9]/*");
+
+print("start up sdogs\n");
+my $node = int(($min_node + $max_node) / 2);
+foreach my $n (shuffle(0..$node - 1)) {
+    &start_sdog($n);
+}
+
+my @join_node = (0..$node-1);
+my @leave_node = ($node..$max_node-1);
+
+sleep(8);
+print("make fs\n");
+&command("shepherd mkfs --copies=3");
+
+my $min_epoch = 1;
+my $max_epoch = 1;
+my $vdi = 0;
+for (;;) {
+    my $op = int(rand(9));
+    print("op: $op\n");
+    if ($op == 0) { # join
+	next;
+    } elsif ($op == 1) { # leave
+	next;
+    } elsif ($op == 2) { # create
+	next if (!grep(/0/, @join_node));
+
+	printf("** create test **\n");
+
+	&command("qemu-img create -f sheepdog test$vdi ".int(rand(256))."G", 1);
+	$vdi++;
+	&command("shepherd info -t vdi -p ".(7000+$join_node[0]), 1);
+    } elsif ($op == 3) { # snapshot
+	next if ($vdi == 0);
+	next if (!grep(/0/, @join_node));
+
+	printf("** snapshot test **\n");
+
+	&command("qemu-img snapshot -c name sheepdog:test".int(rand($vdi)), 1);
+	&command("shepherd info -t vdi -p ".(7000+$join_node[0]), 1);
+    } elsif ($op == 4) { # clone
+	next if (!grep(/0/, @join_node));
+	my $target_vdi;
+	my $tag;
+	my $list=`shepherd info -t vdi | tail -n 3`;
+	if ($list=~/ : test(\d+)[^g]+g:\s+(\w+), not current/) {
+	    $target_vdi = $1;
+	    $tag = $2;
+	} else {
+	    next
+	}
+
+	printf("** clone test **\n");
+
+	&command("qemu-img create -b sheepdog:test$target_vdi:$tag -f sheepdog test$vdi", 1);
+	$vdi++;
+	&command("shepherd info -t vdi -p ".(7000+$join_node[0]), 1);
+    } elsif ($op == 5) { # lock
+	next if ($vdi == 0);
+
+	printf("** lock test **\n");
+
+	&command("shepherd info -t vm -p ".(7000+$join_node[0]), 1);
+	&command("shepherd debug -o lock_vdi test".int(rand($vdi)));
+	&command("shepherd info -t vm -p ".(7000+$join_node[1]), 1);
+    } elsif ($op == 6) { # release
+	next if ($vdi == 0);
+
+	printf("** release test **\n");
+
+	&command("shepherd info -t vm -p ".(7000+$join_node[0]), 1);
+	&command("shepherd debug -o release_vdi test".int(rand($vdi)));
+	&command("shepherd info -t vm -p ".(7000+$join_node[1]), 1);
+    } elsif ($op == 7) { # update_epoch
+	next;
+    } elsif ($op == 8) { # get_node_list
+
+	printf("** get node list test **\n");
+
+	my $epoch = $min_epoch + int(rand($max_epoch - $min_epoch + 1));
+	&command("shepherd info -t dog -e $epoch -p ".(7000+$join_node[0]));
+    } elsif ($op == 9) { # make fs
+	next;
+    }
+}
--- sheepdog-0.3.0.orig/script/Makefile.am
+++ sheepdog-0.3.0/script/Makefile.am
@@ -2,7 +2,7 @@ MAINTAINERCLEANFILES    = Makefile.in
 
 EXTRA_DIST		= generic.in
 
-noinst_HEADERS		= bash_completion_collie checkarch.sh start-sheepdog stop-sheepdog vditest
+noinst_HEADERS		= bash_completion_collie checkarch.sh check-dog.pl start-sheepdog stop-sheepdog vditest
 
 target_INIT             = generic
 
